# Image distortion correction system for electro optic sensors

## Claims
Ein Bildkorrektursystem zur Schaffung einer Ansicht einer Szene 13 , die durch einen elektro optischen Rahmensensor 30 abgetastet wird,

## Description
This invention relates to an image correction system for use with electro optics framing sensors. Electro optic framing sensors may take a number of forms, the most common being television cameras and thermal imagers. These may be used in a wide variety of applications. One particular application in which problems occur is when generating images of a large area. It is possible to use a sensor having a wide field of view, but then the definition within that field of view is frequently not good enough for many purposes. The alternative therefore is to provide a sensor having a narrow field of view, and hence higher definition. The area to be viewed may then be covered by moving the sensor so as to produce an image of a number of overlapping areas in succession. This situation may be met, for example, if the sensor is mounted in an aircraft and moved in a direction perpendicular to the direction of flight. Those areas viewed at a more oblique angle will be distorted relative to those viewed less obliquely, and it will not be possible to simply combine the images generated. A certain amount of image distortion correction will be necessary. It is an object of the invention to provide an image correction system for use with an electro optic sensor. The invention is set out in claims 1 and 7. T.R. Berry, in an article entitled Image Generation and Display , pages 4 1 to 4 25 of Image Processing Techniques , AGARD lecture series no. 119, June 1982, discloses a variety of types of sensing systems including frame sensors and also line by line sensors. However there is no indication that a framing sensor could be used in the way proposed by the invention. In the same publication, Klaus A. Ulbricht on pages 6 1 to 6 12 in an article entitled DFLR s DIBIAS, Design and Implementation of a Digital Interactive Image Processing System discloses the mosaicing of digital satellite images in order to obtain coverage of a wide area. However, due to the height at which satellites operate there is no need for any distortion correction since the view produced is inherently a plan view. On pages 147 156 of AFIPS conference proceedings 1979 national computer conference, New York 4th 7th June 1979 volume 48 in an article entitled a generalised zooming technique for pictorial data base system by S.K. Chang et al, the general use of frames and picture stores is disclosed, but not in the way proposed by the invention. The invention will now be described with reference to the accompanying drawings, in which Referring now to Figure 1, this is a schematic view of one application of the invention. This shows an aircraft 10 flying along a flight path 11 at a height h above the ground. The aircraft carries an electro optic sensor which is able to move in a direction perpendicular to the flight path 11 as shown by the arrow 12. The combination of the forward movement of the aircraft at a velocity V Figure 3 is a block schematic diagram of one form of the image correction system. The image sensor 30 provides an analogue output signal which is passed to a conditioning and digitising unit 31. Each successive frame of digitised information is stored in a separate one of a number of frame stores 32. Information is extracted from each frame store 32 in turn and passed to a transformation unit 33 which applies the appropriate corrections to the position of each pixel of information in that store. The transformed information is passed to a high resolution picture store 34 which holds a number of frames to make up a complete view. The contents of the picture store 34 are passed through a digital to analogue converter 35 to provide a video signal for display or other purposes. The transformation unit 33 may conveniently be a microprocessor which uses a number of algorithms to perform the pixel transformation. Information has to be supplied to a control unit 36 from pickoffs in the sensor drive and pickoff unit 37 indicating the elevation angle of the sensor, and from aircraft equipment 38 indicating the altitude, height and speed of the aircraft. The control unit applies the necessary control signals to the transformation unit 33, the sensor drive and pickoff unit 37 and other elements of the system. The determination of the transformation algorithms for one particular set of conditions will now be described. It is assumed that a plan view of an area of ground is to be displayed, in which case lines of equal length on the ground must be translated into lines of equal length on the display. For the purpose of this explanation a number of other assumptions will be made, and will be detailed as they arise. The first assumption is that the sensor has a field of view of 20 in azimuth and 15 in elevation, the elevation angle of the sensor having three preset values of 7.5 , 22.5 and 37.5 . Thus the area scanned is from a line vertically under the sensor to one at an elevation angle of 45 . If the sensor is at a height of 1000m above the ground, then the sensor covers an area 1 km wide. Figure 4 shows the three frames F1, F2 and F3 viewed in succession by the sensor, with the preset elevation angles shown by broken lines. Also shown in Figure 4 are the positions of some of the scan lines. Each will be separated from the next by an increment of elevation angle Δµ, and hence the image lines IL on the ground will be separated by different distances as shown. However, the output lines OL on the display must be equally spaced, line selection therefore involves selecting only those image lines IL which coincide with, or are nearest to, output lines OL. This may be done, for example, by determining one at a time the position of each output line. This may be defined by the depth of the frame multiplied by the output line number divided by the total number of output lines in the frame. The position of each image line is compared with the current output line position, and when the position of an image line crosses the output line position then that image line is selected. The output line position is then incremented and the procedure repeated for each successive output line. Assuming also, for the sake of simplicity, that the sensor is stationary, then the shape of the area viewed will be as shown in Figure 5, rather than as described previously with reference to Figure 2. The shaded areas in Figure 5 will be those used in the final display. It will be seen that whereas the line lo to be displayed from frame F1 directly under the path of the sensor is of the same length as the width of the area to be displayed, at the other extreme, the outer edge of frame F3, the line lo to be displayed in only a fraction of the width lm of the area scanned. The length L of a framing sensor line projected on the ground is given by Hence for the shortest line lo, whilst for the longest line lm Each of these lines, and all of those in between, contain the same number of pixels p. In the case of the shortest line all pixels are displayed. However, for the longest line lm, only those pixels on the central portion of the line of length lo are required. If the required number of pixels in any line is pc, then hence, for example, when α 37.5 then pc 0.793p The simplifying assumption of a stationary sensor made above does not necessarily hold in practice. Clearly, with the sensor moving over the ground the frames are not of the symmetrical shape shown in Figure 5, but are as illustrated in Figure 2. The techniques used to select scan lines and pixels still apply, though the geometry of such selection processes may vary. In operation, the scanning of the sensor and processing of the image data is a continuous process. The sensor is moved to the desired elevation angle by control means not shown in Figure 3. This involves moving the sensor rapidly between one position and the next, and controlling the direction of the frame scan information to the appropriate frame store. Figure 6 is a flow chart illustrating the sequence of events followed in processing the information stored in each frame store 32. After determining that image information is available in a frame store, the image update rate is determined from data including the height above the ground and the speed of the aircraft carrying the sensor. If information is available then the appropriate frame store is accessed by the processor. After initialising the line and pixel positions, the next required scan line is determined as explained previously. Once this line is identified each required pixel on that line is identified and passed to the picture store. At the end of the scan line the next line is identified and the pixel selection processor is repeated. This continues until all required image information from that frame store has been used. The next frame store is then identified and the process if repeated. As already stated the information in the picture store may be displayed or may be passed to some other location for display or further processing. Alternatively the basic sensor output may be transmitted, for example, to a ground station at which the processing may be performed. The description given above has concerned the transformation of the image information from an obliquely viewing sensor into a display representing a plan view of the area being scanned. Clearly the area may be viewed from other angles giving perspective effects. This may involve other processing techniques or modification of the techniques described above. It may be possible to use the scanner for other purposes during its operation, if time is available during normal scanning. For example it may be possible to study a particular area of ground in more detail than is possible during normal operation. The availability of all the original image information in stored form allows the ready application of a number of well known image processing techniques. Standard image transformation techniques may be used, such as Walsh Hadamard, to reduce the amount of storage required. As the basic selection process described above discards a significant proportion of the available information, group averaging or peak detection may be readily incorporated as examples of enhancing the final displayed image. Other modifications may be applied to the system without departing from the essential features of the invention.