# DIGITAL COMPUTING APPARATUS AND METHOD FOR OPERATING THE SAME

## Claims
Verfahren zum Betreiben einer digitalen Rechenvorrichtung zum Speichern und Zugreifen von und auf Datenaufzeichnungen aus einer Mehrzahl von Datenmengen auf zumindest einer Einzelspeichervorrichtung 20 mit einer Einzelzugriffsdichte, welches ein Aufteilen der Speichervorrichtung in zumindest eine Logische Vorrichtung Partition mit einem hohen Zugriff und einem mit einem niedrigen Zugriff und ein Zuordnen der Speichervorrichtungpartition mit einem hohen Zugriff den am häufigsten verwendeten Daten umfaßt, gekennzeichnet durch die folgenden Schritte

## Description
This invention relates to method and means for storing digital data. More specifically, it relates to storing and accessing data records from a plurality of data sets. A significant problem in the storage of digital data on storage devices such as direct access storage devices is characterized as device bottleneck. That is, when a storage device receives access requests from a processor at a faster rate than the device can sustain, the processor is forced to wait. This results, in many cases, in a catastrophic degradation of throughput the rate at which data records are stored on or retrieved from data sets on the device. One strategy implemented at some computer installations for managing device bottleneck is to have a person, usually a data base administrator, manually examine the device that is, scan the contents of the device , and select for removal to other devices sufficient data sets so that accesses to the data sets remaining on the device will not exceed the device capacity. Another strategy for managing device bottleneck implemented by some application programs is to allocate to a data set much more physical space on a device than is required. The space allocated in excess of requirements is, therefore, not written with data by this or other programs, with a resulting decrease in demand on the device from other applications which would except for the excess allocation, be accessing additional data on the device. It is recognized additionally, that by placing data on adjacent tracks of a direct access storage device a faster rate of access can be achieved due to the shorter seek times required. Thus, a data base administrator may allocate physical space on a device to a given data set or group of data sets at one time. However, this strategy for increasing the access rate to data is only effective if there is either no or little competition for access to data residing in other areas of the device. When a plurality of data storage devices are available, having different access characteristics such as disk and tape storage devices , it is known to allocate frequently used data to the disks, which are faster, and less frequently used data to the tapes, which are slower. A further approach to the problem of bottlenecks provides an interface unit, including buffer storage and a control processor, which queues data for transfer with respect to a central processor and a plurality of storage devices of varying characteristics. Generally, however, the storage of data is defined by the user of the system. He prescribes where the data will be placed. Unable to predict the use of data with sufficient precision, the user frequently places data in such a way that the storage device is unable to provide the required number of accesses during periods of peak demand by the central processor, resulting in excessive response times and overall system degradation. This results in considerable effort on the part of the user to tune his system or, in other words, to rearrange his stored data to relieve the excessive access burden on a particular device or set of devices. In the case where the user has several different kinds of storage devices that have different access rates and or storage capacities, he will attempt, on an intuitive basis, to place the data sets on devices that more nearly provide the performance required, and when using devices that are not well matched to this requirement, he will over allocate space in an attempt to assure a sufficient access rate to a particular data set. Thus, even while not effectively accomplished, a great deal of effort by highly skilled personnel is required to place data sets and to monitor system performance, data storage capacity is not used effectively resulting in wasted storage capacity and or access capability , the data storage system generally operates in a degraded mode with human intervention occurring when degradation becomes intolerable, and data sets frequently are not placed on devices that most nearly meet the access and storage characteristics of the data. Further, storage devices, which have a relatively narrow range of capability, are being called upon to meet a wide range of demands. In the case of direct access storage devices, there is little freedom to modify the storage capacity or to vary the number of accesses that can be sustained in a given period of time. This results in the storage of data in such a way that the access rates that are required cannot be met or the storage capacity that is available cannot be used if the data to be stored requires a sufficiently different rate of access per unit of capacity than the device is able to provide. In one case, for example, if the accesses per unit of time for each unit of capacity of the storage device exceeds the access rate for each unit of capacity of the data set to be stored the access capability of the device will be under utilized. In the other case, where the access rate per unit volume of data is greater than the access rate per unit volume of storage capacity of the storage device that will provide storage for that data, the device will either be unable to provide the accesses required or the storage capacity cannot be fully utilized. In either case, the cost effectiveness of the storage device is reduced and in the case where sufficient accesses cannot be provided, there is a degradation of the data processing system in terms of throughput and response time. The present invention is defined in the attached claims, and has been delimited against the prior art disclosed in IBM TDB, vol.24, no.4, September 1981, pages 1945 1946. In accordance with the invention, apparatus and method for operating the same are provided for partitioning a storage device, such as a direct access storage device, having a single access density into a plurality of logical devices having different access and storage characteristics matched to the required performance. Figure 1 is a schematic diagram of a data storage system showing a plurality of devices having different storage characteristics. Figure 2 is high level flow diagram illustrating the data placement procedure of the invention. Figure 3 is a schematic side view of a direct access storage device including two storage disks. Figure 4 is a top view thereof. Figure 5 is a logic flow diagram illustrating the procedure of the invention for determining the access density for two partitions. Figure 6 is a logic flow diagram illustrating the procedure of the invention for setting the access, capacity, and address offset of device partitions. Figure 7 is a logic flow diagram illustrating the address modification logic of the invention. Figure 8 is a logic flop diagram illustrating the data placement procedure steps of the invention executed at device attach and data set create times. Figure 9 is a logic flow diagram illustrating the data set placement steps executed at data set allocation time. Figure 10 is a logic flow diagram illustrating the data placement procedure steps of the invention executed at start I O time. Figure 11 is a logic flow diagram illustrating the data placement procedure steps of the invention executed at data set close time. Referring to Figure 1, an example is given of a multi processor system wherein data storage functions may be contained in a storage system including a controller 10 and a plurality of storage devices 20, 25, 27, 29, 31. Controller 10 comprises a control processor 37 and a plurality of host adapter modules 21, buffers 33, and device adapter modules 35 of buffer and direct, under the control of control lines 19, data on data busses 12 between processors 11, devices 20, 25, 27, 29, and 31, and control processor 37. Control processor 37 includes a main memory or storage module 13, a memory controller 14, and instruction cache 15 and data cache 16, and a central processor including a register stack 17 and arithmetic logic unit ALU 18. Control processor adapter 39 interfaces control processor 37 to data bus 12, memory controller 14 directs data to and from data bus 12, memory 13, instruction cache 15, data cache 16. Storage functions executed by control processor 37 may include device attachment, data set creation, data set placement, device partitioning, data storage, data retrieval, and table maintenance. Those functions specifically related to the invention will be further described hereafter. Alternatively, all or some of these functions may be performed in a host 11. Host 11 may be a stored program controlled digital computer of the type described in U. S. Patent 3400371 by G. M. Amdahl, et al, entitled Data Processing Systems , and in IBM Systems 370 Principles of Operation, IBM Publication GA22 7000, the teachings of which are incorporated herein by reference. The storage system of Figure 1 accommodates multiple devices having different access characteristics, and is best utilized in such an environment. Devices 20 comprise direct access storage devices, device 25 may comprise a bubble or charge coupled device CCD storage device, devices 27 may comprise a magnetic tape storage device, device 29 31 may comprise a mass storage subsystem MSS or library storage device. Referring to Figure 2, an overview flow diagram is presented of the data placement procedure of the invention. As will be more fully described hereafter in connection with Figures 8 11, the procedure includes device attach step 41 Figure 8 , create a data set step 43 Figure 8 , open a data set step 45 Figure 9 , start input output step 47 Figure 10 , close a data set step 49 Figure 11 , and delete a data set step 51. Referring to Figures 3 and 4, there is illustrated a disk storage device 20 including two disks 22 and 24. Each disk 22, in this example, is coated with an upper and lower magnetic recording surface, such as 26, in which data signals may be written and from which they may be read by read write transducer 30, mounted on actuator arm 32. The transducers 30 are positioned to a data track within bands of tracks, or partitions, 40, 42, 44 by actuator driver 34. One embodiment of this invention relates to the partitioning of device 20 data recording surfaces 26 into high access and low access partitions 40 and 42, 44, respectively, and to the allocation of data records to these partitions based upon the storage characteristics of the data. Other device types may be similarly partitioned based upon their unique physical storage characteristics. The storage characteristics of data are represented, herein by the access density of the data, which is determined by the applications which access the data. Access density is defined as the number of access per unit of time divided by storage capacity or data volume, where the time may be expressed as seconds and the capacity or volume as megabytes millions of bytes, where a byte is 8 binary bits. Thus, the access density of a data storage device is equal to the number of accesses per unit of time seconds the device can sustain, divided by the storage capacity of the device megabytes . And, the access density of an application is equal to the number of accesses per unit of time the application requires to data stored on external devices, divided by the volume of data which it may access. Typical access density values may be between 0. 001 and 10 for DASD devices 20, greater than 10 for CCD devices 25, and less than 0.001 for MSS devices 29,31. In accordance with the invention, device partitioning and data placement procedures are based upon storage characteristics of data, as characterized by access density. Device partitioning is accomplished by dividing the total storage capacity C Thus, the total capacity C And total accesses A By definition, the access density of a device D As a result, a single device 20 having a single access density can be utilized in a such a way as to appear as N devices having M different access densities where M is equal to or less than N. In the example herein illustrated as one practical implementation of the invention, M N 2. Referring now to Figure 5 in connection with Table 1, an explanation will be given of the procedure of the invention for determining access density for a two partition N 2 system. In Table 1 is set forth an example entry for one data set in a data set control block DSCB , which is an improvement on the DSCB described in OS VS2 System Programming Library Debugging Handbook Vol. 2, IBM Publication GC28 0709, pages 375 385. The DSCB and the UCB described hereafter may be stored in memory 13 of controller 10, or at host 11. A VTOC also described hereafter may be stored on each device, and copied into memory 13 when required. There is one such entry for each data set being managed, and includes the data set name, access density, and size. The access density field contains the access density of the data D Referring now to Figure 5, the partitioning of a device proceeds as follows. In step 50, the data sets to be allocated to stored on the device are selected, and their access densities D In step 54, from the group of data sets having access densities D Referring next to Figure 6, the total capacity C The capacity C A cylinder is the set of all recording tracks on recording surfaces 26 of all disks 22, 24 being scanned by transducers 30 for a given position of actuator 32. Thus, there are as many cylinders on device 20 as there are tracks on a single recording surface 26. To minimize the travel distance of the actuator 32, 34 to position transducer 30 over a desired track, the high access partition 40 comprising the T The two partitions are then defined to the system processor as two unique devices, each having a unique identifier, number of cylinders, cylinder address offset, and level of partition. In the embodiment herein described, the physical device 20 identity is preserved by the use of a binary unit address, as is illustrated in the Unit Control Block UCB of Table 2. The UCB of Table 2 is an improvement of the Unit Control Block described in OS VS2 System Programming Library Debugging Handbook Vol. 3, IBM Publication GC28 0710, pages 454 494, and OS VS2 MVS Overview, IBM Publication GC28 0984, page 4 11. Referring now to Figure 7, when a data record is to be stored in or retrieved from a partitioned space, its storage address is developed, as is shown in steps 70 and 72, according to standard access method techniques. However, before completing the address calculation, the device type is checked in step 74. If it is not a partitioned device, according to step 76, the actual address A If the unit type code or device code in the UCB indicate, as is tested in step 78, that the device to be accessed is a high access partition, the actual physical cylinder address A However, if the device code indicates the device to be referenced is a low access partition, as is illustrated by steps 82 and 76, the actual physical cylinder address A Having completed the address conversion to the actual physical device 20 address, the read write transducer 30 can be positioned over the proper track or cylinder, preserving the partition boundaries. Thus, two virtual device types are apparent to the system that more nearly match the storage characteristics volume and frequency of access of the data of the data to be stored. This results in more cost effective data storage. As above described, in connection with Figures 5 7, the device 20 is partitioned into two logical devices having different access characteristics at the time device 20 is defined to the system based upon the access density of the data sets which the two logical devices will be storing. By a further aspect of the invention, data is maintained on that logical device which substantially or most nearly meets the storage characteristics of the data, where those storage characteristics may vary with time. Thus, data will be placed on one or more devices 20 in such a way that heavy utilization of particular data sets is handled by the system without undue degradation i.e., without device bottleneck , and the cost of storage of data records will be held to a minimum by the more effective utilization of storage device s 20. As previously defined, the access density of a data set a collection of data records is equal to the number of accesses by the system to the data records in the data set divided by the volume for example, number of megabytes of data records in the data set. According to this aspect of the invention, at the time a data storage device is attached to a data storage system, the access density of the device is entered into a table which includes the device address, capacity, and access density. At the time a data set is created, an estimated access density for the data set, based on the application requiring that data, is entered into a table which includes the data set name, data set location, application identifier, capacity, and access density. Application identifier and data set access density appear for each application using the data set. Space is then reserved on the device that has available space most nearly or substantially matching the access density of the data set. At the time an application signals the use of a data set that is, at allocation time during opening of a data set , the data set table is referenced to determine the location of the data, the access density of the data set for the application, and the data set size. The device table is referenced to determine the access density of the device containing the data set. In the case of a multiprocessing or a multiple processor environment, the access density required for a data set will be the sum of the applications operating concurrently. The access density of the device is then compared to the access density of the data set. If the two fall within specified limits of each other, the data set is left on the device first addressed, and is ready for processing. If the limits are exceeded, the data set will be moved to a device that more nearly meets the characteristics of the data set. During the input output activity, the system collects a count of the references to the active data sets, and at specified intervals of time recalculates the actual access density of the data set by dividing the accumulated accesses count for a given data set by the capacity of the data set expressed in megabytes times the number of seconds in the specified interval . If the newly calculated access density for the data set does not fail within the specified limits of, or is substantially, different from, the current data set access density found in the data set table, the tabled value for access density is replaced by the new calculated value. When a data set is no longer required for processing that is, it is closed , the data set will remain on the device that most nearly matches its active characteristics until such time as space is required on that device by another data set having a comparable access density but found to reside on a device having a lower access density than required at the time it became active. The subject data set will then be moved to a device of lower access density to reside there until it becomes active again. Herein, the devices of different access density may be a plurality of physical devices of different characteristics, and may also include physical devices which have been partitioned into logical devices exhibiting different characteristics, as previously described. According to one particular implementation of this aspect of the invention using the IBM MVS operating system, the data set storage characteristics are continuously monitored by the system while in operation, and those characteristics are updated, such as by storage in the Data Set Control Block DSCB , Table 1. Referring to Figure 8, step 90, at the time a data storage device 20 is attached to the system, the device access density D Referring to Figure 9, steps 101 to 107 are completed by the system during open time, when the data set is being allocated. Logical step 101 obtains the data set access density D At start I O time, the system monitors the activity against a data set by collecting the activity count for the data set. If the specified time has elapsed, the actual access density of the data set is calculated. And if the newly calculated access density is beyond specified limits, the data set access density D Referring to Figure 10, steps 110 122 are executed by the system at start I O time. Beginning with completion of access to the data set at step 110, to collect an activity, or access, the count N In step 118, if the new access density value D The invention may be implemented in the MVS operating system, or in any operating system that utilizes data storage. Further, it may be implemented in the control of a self sufficient data storage system, where many operating system data management functions are performed in a data storage system rather than in the host processor.