# MAINTENANCE SUBSYSTEM FOR COMPUTER NETWORK

## Claims
In einem Computernetz mit einem Zentralrechner 30 32 und einem Eingabe Ausgabe Subsystem 500 s , das an abgesetzte periphere Einheiten über Daten Übertragungsprozessoren DLP angeschlossen ist und auch an ein Wartungs Subsystem zur Initialisierung, zu Testvorgängen und zu Diagnosevorgängen angeschlossen ist, wobei das Wartungs Subsystem Anschlüsse an ein abgesetztes Unterstützungs Dianosezentrum 50 r aufweist, umfaßt das genannte abgesetzte Unterstützungs Diagnosezentrum 50 r die folgenden Merkmale

## Description
The present invention relates to a computer network comprising a host computer and I O subsystem connected to remote peripheral units via data link processors DLP and also connected to a maintenance subsystem for initialization, testing and diagnostic operations, the maintenance subsystem having connections to a remote support diagnostic center, said remote support diagnostic center including This application is related to copending application entitled User Interface Processor For Computer Network , U.S.S.N In the design and development of computer system networks, there are many considerations and trade offs which must be balanced in order to provide an optimum system and to decide what limits must be drawn in terms of economic factors, size and space factors and versatility of control of the system. The presently described computer network system is designed not only to be used with a variety of peripheral type devices but also with data comm and telephone lines to remote terminals to provide rapid transference of data between the units and rapid data processing by a central processing unit in a fashion whereby reliability is maintained to a very high degree. The system is organized so that each of the various elements and units will, when initiated, provide its own self test routines and report the results and information to a maintenance processor called the User Interface Processor 100. This processor works in conjunction with the various remote terminals, and the various types of peripheral devices through an I O subsystem which is uniquely designed to handle units called data link processors . These types of data link processing units were described in their earlier versions in U.S. Patent Nos. 4,415,986 4,392,207 4,313,162 4,390,964 and 4,386,415. The maintenance subsystem involved herein is so interconnected to the various elements of the system that self test data may be collected and transported to a remote diagnostic unit which may be a central diagnostic unit for many, many computer networks in many different locations. The remote terminal will perform the basic diagnostic routines to any of the computer networks which have problems and will send messages which. pinpoint the specific cause or location of the trouble so that a local operator may correct the fault by changing a card, replacing a module or fixing any other designated fault or outness. From Hewlett Packard Journal, September 1979, pages 13 16, Hewlett Packard Co., Palo Alto, USA, D. L. NELSON A remote computer troubleshooting facility a computer network is known, comprising a host computer, described as HP 3000 33 mainframe and I O subsystems connected to remote peripheral units via data link processors. The system includes self test features that allow the user to start diagnosing problems before requiring external assistance. Therefore, there is a connection to a maintenance system for initialization, testing and diagnostic operation. The maintenance subsystem is connected to a remote support diagnostic center. The system maintenance display loads in the same way as the remote program. Usually a first program performs the diagnostic for the maintenance interface board, a second program is the cold load self test. The information after having run the two programs can be easily relayed to the customer engineer saving time and money for finding out the specific technical problem. Document US A 4,322,793 discloses an entire communication controller having diagnostic facilities, polling facilities and interrupting facilities. An ICC microcode in the host CPU further includes the diagnostic facility which in addition to the usual diagnostic tools, provides for dynamically displaying diagnostic and test information about one of the ICA lines on the host system s console display. At predetermined time intervals, control can be passed to a diagnostic facility module in the host CPU s control store. It is an object of the present invention to provide a maintenance subsystem for a computer network having a processor interface unit which connects a maintenance processor to a main host computer and to an external I O subsystem which supports non self testing data link processors and having a host dependent providing a data link interface to another I O subsystem having data link processors with self test capabilities. This object will be achieved with a computer network according to the preamble of claim 1 given in page 1 in a maintenance subsystem that further comprises A maintenance subsystem for a computer network provides a processor interface card unit which connects a maintenance processor to a main host computer and to an external I O subsystem which supports non self testing data link processors I O controllers . A host dependent port of the maintenance processor provides a data link interface to another I O subsystem having data link processors with self test capabilities. A power control card unit connects the maintenance processor User Interface Processor to a remote diagnostic center. The User Interface Processor or maintenance processor provides an interface to the central host processing unit and to various elements of the network such as the data link processors which connect to remote peripherals, to the operator display terminal which provides visual information and diagnostic information, to external cabinets and to the power control card which enables connection to a remote support center for comprehensive diagnostic and fault location services. The User Interface Processor connects to the central host processing unit through a processor interface card and to various peripherals and terminals through a data link interface host dependent port controller. The processor interface card unit provides means for detecting certain events and storing a history trace of a selected number of events for analysis purposes and for interfacing the main host computer. The power control card unit provides a communication interface to a remote support service diagnostic center in addition to permitting power on off control to the modules in the network. Each one of a series of local computer networks may be locally checked on self testing procedures and then connected to a remote support center for comprehensive diagnostics in order to locate specific problems within any given computer network system. Many differently located computer system networks may be connected to one remote support center which can service them all on a time shared basis. As seen in these drawings, the User Interface Processor is connected to all the various elements of the computer system network, that is to say, it connects to the processor interface card and the main host processor on the one hand and, on the other hand, it connects to the power control card, the maintenance card III, the operator display terminals and the various data link processors. FIG. 10 shows the maintenance subsystem connected to two different types of I O subsystems. The I O subsystem with self test capability is connected by the DLI data link interface bus to a data comm DLP data link processor to a printer tape DLP, and to storage module disk SMD DLP. The other I O subsystem involves non self testing DLPs which are used with the maintenance card. Thus, these combinations of elements connected to the User Interface Processor 100 provide the basic operational and maintenance functions for the computer network. For example, the User Interface Processor 100 will initialize and power up the entire computer network system. It will initiate self testing procedures, whereby each of the interconnected data link processors will do their own self test, do a check out routine and send the results back to the User Interface Processor. Additionally, the User Interface Processor will connect to the power control card in order to provide maintenance and diagnostic information and data to a remote unit which can then provide further diagnostics which will determine the location of any faulty areas in the system. Further, the User Interface Processor will initiate its own self testing routines to make sure that it itself is in proper operating condition and it will display the results on the operator display terminal. The PCC also monitors any air loss and cabinet over temperature in order to provide sensing signals to this effect. The power control card communicates with the User Interface Processor via an 8 bit parallel bus. It further communicates with any remote device using the RS 232C remote link interface. It can communicate with other power control cards on external basis by using two wire RS 422 direct connect data communication protocol. The power control card 50 also maintains a battery backup with the time of day function, in addition to providing 256 bytes of non volatile storage memory. It also provides an automatic restart option after failure of the AC power lines. FIG. 1A shows the User Interface Processor 100 as part of a network configuration. The output bus 100 In FIG. 1A the DRAM 150 provides output to the power control card 50 and the erasable PROMs 150 connect to the operator display terminal 100 The power control card 50 FIG. 1A functions to provide power up down sequencing to monitor for power failure, to initiate automatic restart after power failure to provide warning of over temperature to provide automatic power ON OFF operation to provide remote power control of external cabinets to maintain an internal time of day clock and to provide a communication path data link for a remote support and diagnostic service. The processor interface card 40 FIG. 1A functions to provide control and data acquisition for diagnostic testing of memory 34 FIG. 1B , memory control unit 32, host dependent port 500 and the main processor 30 the PIC 40 provides initialization functions such as microcode load, initialization state and clock control, and distribution. The PIC 40 provides a history file, FIG. 1A, for real time tracing of microcode addresses break points it provides 16 general purpose links for tracing of intermittent failures, and it permits performance monitoring so that a trap can be set to count the number of failure occurrences. The PIC 40 supplies a communication path AULF register, CSCP operator so that the main system processor 30 can communicate to the UIP 100 for maintenance information on power off, time of day, reload, etc. In FIG. 1B the memory bus 30 Also attached to memory bus 30 FIG. 1C shows, in greater detail, the UIP 100 connections to the HDP 500 and to the processor interface card PIC 40 which interconnect the main processor 30 and the HDP 500. FIG. 1D shows how the UIP 100 connects to the processor interface card 40 and main processor 30 on one side, and to the I O data link processor 100 The User Interface Processor 100, FIG. 1, is designated with the acronym UIP . The User Interface Processor consists of one logic board which can interface to a data link interface DLI backplane and also to four independent serial data communications interfaces. Under certain software instructions, the User Interface Processor 100 can operate as a data link processor DLP and in so doing will support a burst rate of up to eight megabytes per second. It can also be used as a host dependent port HDP where it will support a burst rate of 50 kilobytes per second. Thus, the same card of hardware can be made to assume different personalities and functions as required. The User Interface Processor 100 operates on a maintenance philosophy whereby cards in a computer system as FIG. 1A can be isolated and replaced. A combination of self test and peripheral test driver tests are used to isolate any failure to a replaceable module. This is done by indicating to the operator via operator display terminal, ODT, 100 Thus, the User Interface Processor 100 is basically a microcomputer system which is placed on a single printed circuit board. It includes a number of key components as follows The User Interface Processor 100 can communicate via the controller 180 and through the UIO universal input output backplane to a host computer using a standard UIO DLI backplane protocol which conforms to the Burroughs Message Level Interface as described in U.S. Patent No. 4,074,352 at FIG. 5E, this patent being entitled Modular Block Unit for Input Output Subsystem. The User Interface Processor is capable of simulating a DLI host dependent port, thus enabling it to communicate with data link processors in a common base that does not have a distribution card . It emulates the priorly used Distribution Card. The description of data link processors and use of the distribution card have been described in U.S. Patents 4,313,162 entitled I O Subsystem Using Data Link Processors, and 4,390,964 entitled Input Output Subsystem Using Card Reader Peripheral Controller. The User Interface Processor includes a backplane interface to a bus known as the backplane maintenance bus. These backplane lines can be used to initiate a data link processor self test routine and to read a result of that self test as it is driven on to the backplane from a given data link processor. In this disclosure, the two above mentioned user interface processor ports will be referred to as the DLP and the HDP respectively. The User Interface Processor 100, FIG. 1, is a microprocessor controlled system that contains The UIP 100 has certain communication restrictions in this regard. The host dependent port 500 is a DLI Data Link Interface controller 180 and as such does not provide a MLI Message Level Interface , but merely provides a backplane DLI interface. In this regard it cannot be used with a distribution card, path selection module, or base control card as was done in the organization of data link processors which were described in the cited U.S. Patents 4,313,162 and 4,390,964, since it provides these functions for itself in firmware. This particular host dependent port 180, FIG. 1, must be used in a base that provides an eight megahertz clock, such as that provided from the maintenance card, 100 The microcomputer subsystem includes both serial and parallel interfaces that are used to perform data communication operations. The microprocessor subsystem consists of certain elements as follows These elements are shown in FIG. 1 of the drawings. This processor is a high performance 16 bit CPU which is implemented in HMOS technology and packaged in a 40 pin dual in line package. This processor is capable of addressing up to one megabyte of memory, as well as 64k of I O addresses. The 8086 microprocessor is operated in a minimum mode since it is used only in a single processor environment, and as such it generates its own bus control signals. This chip provides all the necessary multiplexing of the row and column addresses, drivers, and the refresh logic. Since this chip is operated in its fastest mode, there is no wait state required. A refresh request is requested every 1.6 microseconds by a refresh counter which, in turn, requests a 8086 hold sequence in microprocessor 110 to occur. Once the sequence is granted, the RAM controller chip DP 8409 accesses one row of RAM 150, thus refreshing it. The duration of this access equals that of a microprocessor memory access cycle, thereby reducing the refresh overhead time to a minimum. With this type of configuration, the memory band width is 3.83 megabytes per second. The memory is refreshed also during a reset of the microprocessor 110, thus preventing destruction of the memory contents. Error detection in the RAM array 150 is accomplished by vertical byte parity via circuit 160, FIG. 1. Thus, each 16 bit word of RAM 150 has two parity bits, one for each byte. Whenever a word, or a byte, of a dynamic RAM is accessed, the parity is checked for each byte regardless of whether the operation is a word cycle or a byte memory cycle. When such an error occurs, the microprocessor 110 has its non maskable interrupt set to true , and the error logging can then be implemented to record the bad address when such an implementation has been provided in the UIP 100 firmware . The SCC chips 200 The SCC chip includes two receiver sections 232, 234, FIG. 3, each having a three byte FIFO first in first out register that allows buffering of four bytes including the receive data register of data in the receive mode . The transmitter section incorporates a single holding register as well as a transmitter data register. FIG. 2 shows the typical internal features of the Zilog Z8530 SCC serial communication controller 200. There are two channels, channel A 215 The control signals for these channels are designated as discrete control and status for channel A, 217 The internal bus 212 also connects the channel A registers 211 The serial communication controller 200 is an operable part of the User Interface Processor 100 for use as an interrupt control device . It is capable of driving a programmable interrupt vector in response to a microprocessor interrupt acknowledge signal. The use in FIG. 1 of the priority interrupt PRITC 800 controller s cascade output allows the SCC 200 to be operable as a slave interrupt controller. This usage allows implementation of the SCC 200 vectored interrupt capability. While the serial communication controller chip has an interrupt priority option , it is not used in the User Interface Processor, since this function is allowed for in the interrupt control logic device 222 of FIG. 2. By using two of the serial communication controller chips, this results in a total of four serial data communication lines shown in FIG. 1 as lines 1 and 2 and lines 3 and 4. These four lines are interfaced over to two external four plane connectors which allow the use of existing data communication paddle cards in order to provide the electrical interfaces for use with interfaces such as the RS 232C, or the TDI and so on. The serial communication controller 200 has certain capabilities which will be described hereinbelow. All the modes of communication used are established by the bit values of the Write registers 236, 238, FIG. 3B. As data is received or transmitted, the Read register 211 Referring to FIG. 2 of the serial communication controller 200 block diagram, the register set 211 The transmitter section of the SCC has an eight bit transmit data register 240 which is loaded from the internal data bus 212 FIGS. 2, 3 and also has a transmit shift register 244 which is loaded from either the sync character or the address register 238 WR6 , the sync character or the SDLC flag register 236 WR7 of FIG. 3 or the transmit data register 240. In the byte oriented modes, the registers WR6 238 and WR7 236 of FIG. 3B can be programmed with sync characters. In the monosync mode , an eight bit or a six bit sync character is used in WR6, whereas a 15 bit sync character is used in the bisync mode in registers WR6 and WR7. In the bit oriented modes, the flag contained in register WR7 236 is loaded into the transmit shift register 244, FIG. 3B, at the beginning and at the end of a message. If asynchronous data is being processed, then registers WR6 and WR7 of FIG. 3B are not used and the transmit shift register 244 is formatted with start and stop bits shifted out to the transmit multiplexor 252 at the selected clock rate. Synchronous data except SDLC HDLC is shifted to the CRC cyclic redundancy checker generator 250 as well as to the transmit multiplexor 252 at the Xl clock rate. It should be understood that SDLC means synchronous data link control while HDLC is the European version. The SDLC HDLC data is shifted out through the zero insertion logic 248 which is disabled while the flags are being sent. The address bit A0 is inserted in all address, control, information, and frame clock fields following the five contiguous 1 s in the data stream. The resultant of the CRC generator 250 for the SDLC data is also routed through the zero insertion logic 248. With each receipt of data in FIFO at 232, 234, an error FIFO 234 In FIG. 3 the incoming data is routed through one of several paths depending on the mode and the character length. In asynchronous mode, the serial data enters the three bit delay at element 280 if a character length of seven or eight bits is selected. If a character length of five or six bits is selected, then data enters the receive register 232, 234 directly. In synchronous modes, the data path is determined by the phase of the receive process currently in operation. A synchronous receive operation begins with a hunt phase in which a bit pattern that matches the programmed sync characters 6, 8 or 16 bits is searched. The incoming data then passes through the receive sync register 282 and is compared to a sync character stored in register WR6 238 or register WR7 236 , depending upon the mode being used. The monosync mode matches the sync characters programmed in register WR7 236 and the character assembled in the receive sync register 282 in order to establish synchronization. Synchronization is achieved differently in the bisync mode. Incoming data is shifted into the receive shift register 232, 234, while the next eight bits of the message are assembled in the receive sync register 282. If these two characters match the programmed characters in WR6 238 and in register WR7 236 , the synchronization is established. Incoming data can then bypass the receive sync register 282 and enter the three byte delay 280 directly. The SDLC mode of operation uses the receive sync register 282 to monitor the receive data stream and to perform zero deletion 278 when necessary, for example, when five continuous ones are received, the sixth bit is inspected and deleted from the data stream if it is a zero. The seventh bit is inspected only if the sixth bit equals one . If the seventh bit is a zero, a flag sequence has been received and the receiver is synchronized to that particular flag. If the seventh bit is a one , then an abort or an EOP end of poll is recognized, depending on the selection of either the normal SDLC mode or the SDLC loop mode. Thus, for both SDLC modes, the same path is taken by the incoming data. The reformatted data enters the 3 bit delay and is transferred to the receive shift register 232, 234 . The SDLC receive operation begins is the hunt phase by attempting to match the assembled character in the receive shift register 232 232 with the flag pattern in register WR7 236 . When the flag character is recognized, subsequent data is routed through the same path regardless of the character length. Either the CRC 16 or the CRG SDLC cyclic redundancy check polynomial can be used for both monosync and the bisync modes, but only the CRC SDLC polynomial is used for the SDLC operation. The data path taken for each mode is also different. Bisync protocol is a byte oriented operation that requires the central processing system host 30, FIG. 1B to decide whether or not a data character is to be included in the CRC calculation. An eight bit delay in all synchronous modes, except SDLC, is allowed for this process. In the SDLC mode, all bytes are included in the cyclic redundancy checker calculation. The User Interface Processor 100 can use the serial communication controller 200 in two different ways. These are i polled and ii interrupt. Both of these require register manipulation during initialization and data transfer. However, when used in the interrupt mode, the SCC 200 can be programmed to use its vectored interrupt protocol for faster and more efficient data transfers. This method of I O transfer avoids interrupts. All interrupt functions must be disabled in order for a device to operate correctly. With no interrupts enabled, this mode of operation must initiate a Read cycle of the Read register 0 to detect an incoming character before jumping to a data handler routine. The Read and Write registers of FIG. 2 211 Transmit, receive, and external status interrupts are the sources of these interrupts. Each interrupt source is enabled under program control with channel A of FIG. 2, having a higher priority than channel B, and with the receive, transmit, and external status interrupts being prioritized within each of the channels. The DPLL 271 of FIG. 3 is driven by a clock which is normally 32 times NRZI , or which is 16 times FM the data rate. The DPLL uses this clock, along with the data stream, to construct a receive clock from the data. This clock can then be used as the SCC receive or the SCC transmit clock, or both. This CIO or counter input output port 202 This CIO device also includes three 16 bit counter timers, each having three output duty cycles and up to four external access lines. These timers are programmable as being retriggerable or as being non retriggerable . The CIO 400 of FIG. 4 is capable of pattern recognition and generates an interrupt upon recognition of a specific pattern at a port. As seen in FIG. 4, there are three I O ports provided by the counter input output device Port A 407 and port B 408 are eight bit general purpose ports, while port C 409 is a four bit special purpose port. Two port configurations are available and are designated as i bit port and ii port with hand shake. All three of these ports can be programmed as bit ports however, only ports A and B are capable of operation as hand shake ports. Both ports A and B FIG. 5 include pattern recognition logic 412 which allows interrupt generation when a specific pattern is detected. The pattern recognition logic 412 can be programmed to make the port function like a priority interrupt controller . The ports A and B can also be linked to a 16 bit input output port with hand shake capability. Each of these ports has 12 control and status registers, which control these capabilities. The data path of each port is made of three internal registers, which are i the input data register 411 ii the output data register 410 iii and the buffer register 415. The output data register 410 is accessed by writing to the port data register, while the input data register is accessed by reading the port data register. Two registers the mode specification register and the hand shake specification register are used to define the mode of the port and to specify which type of hand shake, if any, is to be used. In ports A and B, the reference pattern for the pattern recognition logic is specified by the contents of three registers not shown which are designated as i the pattern polarity register ii the pattern transition register and iii the pattern mask register. The detailed characteristics of each bit path for example, the direction of data flow or whether a path is inverting or is non inverting are programmed using the data path polarity register, the data direction register and a special I O control register. Referring to FIG.5, there is seen a block diagram of certain details of each of the counter timer input output CIO ports A and B. In FIG. 5 there is seen an output data register 410 and an input data register 411 connected to the internal data bus 212. The output data register 410 connects to a data multiplexor 420 which feeds a buffer register 415 having an output which can be conveyed to pattern recognition logic 412 or to input data register 411 or to the output buffer inverters 418. The output buffer inverters 418 can provide an output to the input buffer inverters 422 which can provide their outputs to the data multiplexor 420 or to the counter timers 1 and 2 of port B 408, FIG. 4 . The port control logic 413 of FIG. 5 can provide internal port control or hand shake control while communicating with the internal data bus 212. For each port, the primary control and status bits are grouped in a single register called the command and status register . Once the port has been programmed, this is the only register that is accessed for the most part. To facilitate initialization, the port control logic 413 is designed so that registers associated with a non needed or unrequired capability are ignored and do not have to be programmed. The block diagram of FIG. 5 is illustrative of the port configuration which is used and it applies both to port A and port B 407 and 408, FIG. 4 . Since the port C s function is defined primarily by ports A and B in addition to the internal input data and output data registers, which are similarly accessed as in ports A and B , here only the three bit path registers are needed, that is the data path polarity register, the data direction register, and the special I O control register not shown . Up to four port pins counter input, gate input, trigger input, and counter timer output can be used as dedicated external access lines for each counter timer FIG. 4 . There are three different counter timer output duty cycles which are available. These are i pulse duty cycle ii one shot duty cycle and iii a squarewave duty cycle. The operation of the counter timers can be programmed as either retriggerable or as non retriggerable. As seen in FIG. 7, each counter timer connects to the internal data bus 212 and has two time constant registers, 710 and 711, which connect a 16 bit down counter 715, having outputs to the current count registers, 720 and 721. In addition, there is a counter timer control logic unit 712 which has input lines from a port and which connects to the internal bus 212. In addition, each port and counter timer command and status register includes three bits associated with the interrupt logic these are the interrupt pending , the interrupt under service and the interrupt enable . One interrupt per counter timer input output unit drives a priority interrupt controller 800, FIG. 1 input with the interrupt controller programmed to recognize the CIO 400 as a slave interrupt controller. Similar to operation of the SCC 200, this implementation allows the full use of the CIO 400 interrupt vector capabilities. The individual outputs of these two timers are also routed to the CIO 400, FIG. 4, so that the microprocessor 110 of FIG.1 1 can determine via a read from the CIO port which timer caused the interrupt. The other timer also directly drives the programmable priority interrupt controller, PRITC 800, via a different interrupt level. The PIT 700 FIG.1 1, programmable interval timer has six different modes of operation which may be described as follows The Programmable Priority Interrupt Controller is capable of handling eight possible interrupts and for generating a priority for each interrupt as well as an individual vector for each interrupt. Various components of the User Interface Processor 100 can provide an interrupt signal to the microprocessor 110. These various types of interrupts are as follows These interrupts are given a priority rating and the interrupt controller device 800 will output a vector pointing to a service routine in microprocessor 110 in response to its corresponding interrupt input. The priority is under programmed control and can be used to assign a level of priority to each input. The programmable priority interrupt controller PRITC 800 is shown in block diagram form in FIG.8. The block diagram of FIG. 8 shows the basic elements of the PRITC 800, that is to say, the priority interrupt controller of the User Interface Processor 100. Here, a data bus buffer 810 connects to the internal bus 212 which has a bidirectional connection to the interrupt mask register 822. The mask register 822 communicates to the in service register 824, to the priority resolver 826, and to the interrupt request register 828 to provide outputs to the internal bus 212, and also to the control logic 820. The control logic 820 provides outputs to the read write logic 812 and to the cascade buffer comparator 814. The counter timer input output unit, CIO 400, and the serial communication controller, SCC 200, require a separate interrupt acknowledge term for each of the units. Since the microprocessor 110 8086 drives a common interrupt acknowledge INTA , there was provided means to implement a method of decoding separate acknowledge signals. The PRITC 800 interrupt controller is programmed to see the CIO 400 and the SCC 200 interrupts as though they were interrupts from another interrupt controller device called cascade mode . This causes the PRITC 800 interrupt controller to output a three bit field CAS0 CAS2, FIG. 8 which is unique for each interrupt level programmed as a slave interrupt. These three outputs are decoded and are used as the separate interrupt acknowledge required by the SCC 200 and the CIO 400 units. This permits full utilization of the interrupt vectoring capabilities of the SCC and the CIO chips. The three mentioned cascade outputs CAS0, CAS1, CAS2, which exit from the cascade buffer 814 of FIG. 8 are also driven to the foreplane FP to allow for another external interrupt control chip to be used which can thus increase the amount of interrupts to fifteen types of interrupts. Each interrupt is received by the UIP s programmable priority interrupt controller PRITC 800. More interrupts can be provided by the addition of another controller that uses the UIP interrupt controller cascade outputs CAS0, 1, 2 of 814 of FIG. 8 . This can result in the expansion of up to eight interrupt signals. For devices with very slow access times, a ready input derived from the microprocessor 110 is brought to the foreplane FP 2 so that these slower components can meet the microprocessor timing constraints. The microprocessor 110 has an output signal HLDA which is present on the CTL bus of the foreplane FP 2 of FIG.1 2 however, the input signal HOLD is not present. This means that the application dependent logic connected to the foreplane FP 2 cannot, for example, perform direct memory access to the UIP RAM array 150. Further, the buffers which drive some signals on the foreplane are always enabled and they cannot be disabled by either the UIP microprocessor 110 or by the application dependent logic, wwhich may be attached to the foreplane FP 2, FIG.1 2 . There are a group of signals brought out to the foreplane connectors FP 2 of the User Interface Processor board. In the signals, the direction is indicated by B for bidirectional by I for input and by O for output. The list of signals on the foreplane connectors is as follows In FIG. 9 shown on two sheets as FIGS. 9A and 9B a block diagram is shown of the DLI HDP controller. The term DLI represents Data Link Interface while the term HDP represents Host Dependent Port . The DLI controller provides an interface which consists of the clear and self test initiation logic, the DLI send receive registers 922, a burst counter 916, a burst end logic 926, a longitudinal parity word LPW generator 923, vertical parity generation and routing, request and emergency request logic, and DLI microprocessor communication logic. A 24 bit state machine 925 and 910 with parity accepts the conditions from and controls these data elements. The microprocessor 110 also accepts status from, and provides control of, portions of these elements. FIG. 9 also shows a block diagram of the DLI HDP interface. A data bus 909 connects control store 910, HDP register 911, a DLP status send receive register 912, a DLP request address logic 913, data latches 914, host pointer 915 and burst counter 916. The control store 910 has outputs which provide signals to a condition selector 917 and to a parity check circuit 918. The data latches 914 have a data bus connection to the DLI send receive register 922. The host pointer 915 provides addresses to RAM 920 which is connected to a vertical parity generator checker 923. The microprocessor address bus 110a connects to an address buffer 919 and a device decoder 921. The Clear self test PAL 112 Incorporated into the clear self test PAL 112 This control signal CONNECT and IOSND is generated in the request logic 913. The combination of CONNECT and a DLP request generates an output enable for the DLI buffers 922, thus allowing data to be driven on to the DLI data bus FIGS. 1C and 9 from a connected data link processor DLP. The microprocessor 110 is also capable of sending DLP request as true as well as resetting it to false . The latch enable to receive data from the DLI into the receive register 922 is controlled by the signal AF synchronized STIOL . The clocking of data into the DLI send register is controlled by the DLI state machine 925 and 910 . The use of the term PAL will be meant to indicate Programmable Array Logic . The burst end logic 926 uses the signal TERM terminate , the signal BUFFUL carry out of the burst counter , and the signal STIOL strobe I O level . These signals are used to provide a condition input to the DLI state machine 925, 910 to halt the burst mode, as well as to reset the burst flip flop 926. The microprocessor 110 of FIG. 1 controls the clearing and also examines the NEQZERO status from the LPW generator 923 . The DLI state machine 910, 925 controls the accumulation and the reading of the longitudinal parity word LPW generator 923. The pipelining latch enable 923 is also controlled by the DLI state machine 910, 925 . Vertical parity is generated and written into the parity RAM 920 when writing into the dual port RAM 920 from the microprocessor system of 110. Vertical parity is checked when writing into the dual port RAM 920 from the DLI interface 922 and the actual DLI parity is written into the parity RAM 920. Vertical parity is read from the parity RAM when reading into the DLI send receive registers 922. A flip flop is used to store the parity checking result and used to produce the vertical parity error status signal VPERR to the microprocessor 110. VPERR is a status input which may be read by microprocessor 110. The signal IOSND input output send is also generated by the request PAL 913. The signal IOSND is set automatically when the UIP 100 is requesting service and the signal CONNECT is true . This situation occurs when the UIP 100 is returning a descriptor link to the host computer 30, FIG. 1B. The signal IOSND is also settable by the microprocessor 110. Reference to FIGS. 1A, 1B, 1C and 1D will indicate the system network ccnnections of the User Interface Processor UIP 100 and its relationship to the other units in the system network such as the processor interface card 40, the operator display terminal 100 In FIG. 1B there is seen further relationships of the User Interface Processor 100 to the host dependent port HDP 500 and the I O subsystem 500 FIG. 1C shows further interconnective relationships of the User Interface Processor 100 to the processor interface card 40, the main host processor 30, the memory control unit 32 and the host dependent port 500. FIG. 1D shows the interface relationships of the User Interface Processor 100 in relationship to the processor interface card 40 and the main host processor 30 and additionally the relationship to the group of data link processors 100 The User Interface Processor 100 plays a significant part in the operation and especially the initialization of the system network. The computer network system shown in FIGS. 1A, 1B, 1C, 1D will power on and initialize in approximately three minutes. When the hardware and software are properly installed in the system, then no operator intervention is required during the power on sequence. The operational functioning of this sequence and ways for handling exception conditions that may occur are discussed hereinbelow. After power is successfully established, the UIP maintenance subsystem will be in control of the system network in order to handle the next phase of the power up sequence. If there is no BOOT CODE file which is available, then one must be created for use. Normally, this file would be available and required software loaded in a few seconds, after which the operator can recognize that the BOOT CODE file has been found by observing the messages that will appear briefly on the console display. In addition, the status line at the bottom of the screen will indicate loading maintenance software . As a result of this, the operator will be instructed to specify a valid unit number. The operator must then make sure that the appropriate unit is powered up and ready to go, after which he can type in the unit number to be used. The maintenance I O configuration will be displayed on the console to show the operator the set of units found on the last attempt to find or to access the BOOT CODE file. If the correct unit does not appear in the table, then it is likely that there are problems in the I O subsystem 500 If the unit is in the table, but the BOOT CODE file is not found on the specifying unit, it is then likely that a BOOT CODE file was never created on that particular unit. Another possibility is that the disk in question has been damaged or corrupted, and the operator should then specify a backup unit if one exists or else he should load the software from the BOOT CODE tape which is also supplied in the described computer network system. If the backup BOOT unit exists, it may be specified as the next unit to try. However, if no BOOT unit has been found, it is then not useful to attempt one of the units already displayed in the I O configuration table since that list would have already been searched. It is necessary to make sure that the expected BOOT unit is operable, and if not, to take action to bring the BOOT unit to an operable state, after which the operator should retry the operation by specifying the unit number. It is possible that a BOOT CODE unit may be located but that parity errors are encountered while loading the software. When that situation occurs, the operator will be instructed to specify another BOOT unit. Thus, a backup unit should be specified if there is one in existence and available. If the software loading consistently fails due to errors in the maintenance subsystem memory, the system must be serviced to replace the failing elements before the power on sequence can be successfully completed. If no BOOT code file is available, the maintenance subsystem must be tape loaded . This procedure is done by first mounting the BOOT CODE tape on a tape unit visible to the maintenance subsystem and then to specify this unit as the BOOT unit the screen on the operator s console 100 The maintenance subsystem will then operate off of the tape unit rather than the disk unit. The tape unit must remain mounted throughout the initialization sequence in order to allow subsequent files to be read. When the MCP master control program operating system is finally up and running, the operator must create a BOOT CODE file on an in built disk and again he must initiate the switch for power off power on for the system. The next and all subsequent uses of power on will find and use the BOOT CODE file on the disk and thus the BOOT CODE tape may then be dismounted. The status line at the bottom of the operator s screen will indicate that state. This loading will take approximately 30 seconds. If the loading fails, the reason will then be shown on the console of the display unit 100 If the loading fails because of errors in the control store of the processor 30 memory into which the system microcode is stored , then the failing elements must be serviced. Any failure to load the SYSTEM UITLOADER program may be due to I O problems with the BOOT unit or certain system problems. In the event of a failure, the cause of the problem will be displayed on the operator s console 100 Since the requirements for initialization and maintenance in a computer system network are similar, this similarity has been made use of in order to yield a particularly significant cost reduction by sharing the access interface hardware. The sharing of the hardware for initialization and for maintenance allows the reporting of failures either locally or remotely and also permits initialization to occur with only a small functional set of circuitry. A further advantage of this shared hardware is the high degree of visibility to all of the subsystems within the overall system network. This direct visibility permits excellent analysis for faults and for fault resolution. The access and viability of the initialization and maintenance functions for the computer network system is provided through the use of the User Interface Processor 100. The particular computer network system disclosed here is composed of the following items The maintenance subsystem which is basically the maintenance and initialization subsystem of this disclosed computer network is comprised of the following items In order for diagnostic routines to occur in the described computer system network there are certain parameters and requirements which are involved. These are The following elements are required for initialization of the disclosed computer network The diagnostic program involved in this system has two main functions, first to serve as a confidence test on any well defined subsystem and second to resolve any failures detected by the confidence routine to the location of a specific card unit. All subsystems which have a microprocessor must be able to perform self test. For those units which do not have a microprocessor, the diagnostic access hardware for the self test is provided on each printed circuit board. Self test is accomplished by connecting with the User Interface Processor 100 which provides the intelligence to drive the test via the processor interface card 40. These tests are developed as diagnostic tests which provide means for dynamic testing at the system level. This dynamic testing incorporates the event analyzer of the processor interface card 40 and the history file of the processor interface card 40. The fault types to be detected in this system are categorized by the level of the test required to detect the fault, the level of skill required to correct the fault, and the time at which the fault is detected. There are four fault types which are considered for detection in the computer system network. Here there is no diagnostic program which is readily available or there is more than one failure present. The probability is high that the fault is in the core logic circuitry. This type of failure cannot be verified from a remote service center. The characteristics of this type of fault are structural failures stuck at 1, stuck at 0, or short circuits. Correction of this type of problem merely requires replacing the card or cards called out on the Maintenance Display Console. Type III failures are detected by a high number of device failures reported in the maintenance log the failure of the master control program MCP to initialize continuous dumps which are not cleared by a halt load and or an error message displayed by running internal diagnostic E mode diagnostics programs. The characteristics of this fault type III are peripheral device failure or a memory unit failure and a failure which can be verified from a remote service center. The corrective factors in this type of problem may involve the adjustment of peripheral devices or replacement of logic cards, or both. The characteristics of this type of fault are a data dependent failure, an intermittent hardware failure or software failure. However, these failures must be such that they can be verified from a remote support center. This type of problem requires high skill for correction. The problem can only be identified in a running system environment or by analysis of dumps. The diagnostic tests involved are divided into four levels where each is intended to deal with a particular fault type. Generally, the execution of a test case depends on the successful execution of the preceding test case unless the tests are used to handle or cover completely independent logic. Each test case is so arranged as to avoid the use of previously untested hardware. This type of test is used to gain a minimal level of structural and functional confidence in the hardware involved. Its purpose is to verify the initialization path during system power up, to serve as a confidence test during debug and later as a manufacturing test. These tests use diagnostic codes running either on the UIP basic board tests or the on board microprocessor state machine self tests . The level 1 tests cover tests involving the main central processor 30, the memory control unit 32, the host dependent port 500, and the processor interface card 40, whereby each of these four units are given a basic board test which is driven by the User Interface Processor 100. The level 1 tests also cover certain other units which are defined as a self test which is driven by an on board microprocessor unit. These units which are given the self test via the microprocessor are the User Interface Processor 100, the power control card 50, the storage module disk data link processor, the printer tape data link processor and the data comm data link processor. These tests are used to obtain a higher level of confidence in main frame hardware by testing the interactions between sub modules in a controlled environment and are also used as memory sub unit exercises. These tests are written in OHNE microcode and are run on the central processor 30 at normal clock speed 4 megahertz with a driver running on the User Interface Processor 100 that controls the execution of test cases and monitors the results. These level 2 tests cover the following items The E mode stand alone diagnostics are NEWP New Programming Language compiled E mode programs that run on top of the normal system microcode. The E mode involves Burroughs stack architecture and is described in a paper entitled An E Machine Workbench by G. Wagnor and J.W. Maine, published by ACM Association for Computing Machinery in the proceedings of the 16th annual workshop on Microprogramming, October 11 14, 1983. They are used to obtain a higher level of confidence in the main frame hardware by arranging for the testing of the following These level 3 tests fall into two groups the processor group and the I O group. The processor group tests are designed to test E mode OPs in an environment where the complexities of the master control program are not involved. Standard test cases are provided that run OPs in singles, pairs and triples. There is also the option to generate test cases using a patched NEWP compiler in order to enable a few engineers to take a failing code from the master control processor environment and run it in a diagnostic environment using the computer network features of event and history logic in order to aid the diagnosis, as well as using the extensive debug features which are brought into this particular program. The I O group are diagnostic which are designed to test the complete path from the E mode, through the processor 30 and the host dependent port 500 microcode hardware, the message level interface data link interface MLI DLI and the data link processors to the peripheral itself. This is in a relatively simple controlled environment which can use the event and history logic and the extensive debug features of these programs. The level 4 tests are used to find failures which only occur in a system environment . After the computer main frame 30 is verified to be functioning properly, the master control program can drive the interactive tests PTD and SYSTESTS in order to further diagnose the problem in a master control program environment. Further, the event and history logic can also be used to trap failures that only occur while running the system or while running the application software. When there is an occurrence of an error, the diagnostic system will provide error messages indicating which boards have malfunctioned. At the basic board or at the interactive level, the hardware is tested in separate building blocks with the testing of one block depending on the successful test completion of a preceding block. Thus, the diagnostic test will terminate upon the occurrence of an error within the module under test, but it will continue to run tests on other modules providing that they are not dependent on the previous test in order to further diagnose failures in areas such as the M bus or the control bus that can potentially affect more than one module. Upon the occurrence of a recoverable error, for example, data miscompares in a pattern sensitivity test, the diagnostic tests will log all information relating to an error when it occurs and will continue until completion. The diagnostics are graded by running against a list of faults which can be generated by DDRIVE program for generating test cases . The number of faults detected by the diagnostic tests can be used to determine the percentage of testing necessary. There are six maintenance interfaces which will be discussed as follows In order to provide a unified approach, an interface to the diagnostics, an executive program called the TEST RUNNER will control the execution, the interface and error logging of all of the off line diagnostics. The TEST RUNNER is a simple menu driven program which gives unambiguous details of failures at the board level and is designed to complement the overall maintenance philosophy of resolving problems to units which can be replaced. There are two modes of operation for the TEST RUNNER. First, there is the automatic mode which is involved during the system initialization sequence and which runs a subset of the diagnostics. Any critical failure detected during this mode will take the system out of automatic and put into manual initialization mode, where diagnostics can be run to verify or further isolate the problem. Any non critical failure detected for example, memory module other than a module or data link processor which is not required for initialization will be flagged to the operator, but will now allow initialization to be continued. Secondly, there is the MANUAL or INTERACTIVE MODE. This mode can be entered during system initialization or it will be entered as a result of a critical failure during the automatic mode. This mode allows the specification of which diagnostics are to be run and it also allows the use of hardware software screens and event history logic in order to trap and or examine the system s state. The diagnostic tests for the main processor 30, the memory control unit 32, and the host dependent port 500 are initiated from the User Interface Processor 100. Here, the User Interface Processor functions as follows The User Interface Processor hardware and its functionality are discussed in conjunction with FIGS. 1 through 9 of the specification. The User Interface Processor 100 is a processor that has a limited input output capability. The UIP 100 can communicate with peripheral devices that are configured into the system via the data link interface. The User Interface Processor 100 through the power control card 40 provides the link to the remote support center shown as 50 The User Interface Processor 100 also provides the link to the local terminals for maintenance and for operative display terminal 100 The UIP 100 has the ability to communicate with peripherals in order to provide system maintenance, to load the operator microcode into RAM, to perform diagnostics, to enable remote maintenance and to provide for Halt Load. The software programs which do this reside on peripheral devices whose data link processors are connected on the data link interface that is, system maintenance programs that are used by the User Interface Processor 100 . The UIP communicates with terminals via a TDI link Terminal Direct Interface . The UIP 100 can communicate with data link processors via the data link interface shown in FIGS. 1B, 1C, and 1D. To the data link processor, the UIP 100 commands will look like commands sent by the host dependent port 500, FIGS. 1C and 1B, that is to say, the User Interface Processor 100 has the ability to control devices connected on to the data link interface. There are eight available addresses 0 7 for data link processors on the data link interface. The UIP 100 occupies the first address 0 on a data link interface. A printer tape data link processor occupies one slot, since it is a one card data link processor and because it is logically considered as two data link processors communicating with two types of peripheral devices. A SMD DLP storage module disk data link processor occupies a fourth address on the data link interface. This leaves four addresses available for expansion. The User Interface Processor 100 can communicate with peripheral devices by sending I O descriptors to the data link processors and receiving back I O result descriptors from the data link processors, In order to determine the system configuration, the UIP 100 sends a Test I O operation to the peripheral devices on the data link interface. From this information a data link interface configuration table can be built. The computer system network disclosed herein may have several UIO universal input output bases. One base includes all of the data link processors and the peripherals on the data link interface. A separate base may also be configured on the message level interface MLI port on the HDP 500 as seen in FIGS. 1B and 1C. The UIP 100 cannot communicate directly with the peripherals on the message level interface. Thus, the software programs and the files that are used by the UIP 100 to perform diagnostics and other maintenance functions must reside on peripherals whose data link processors are on the data link interface. The power up of the described computer system network is an automatic sequence of events that does not generally require operator intervention, except in certain specific cases. If the default path is not functional for example, a system disk is not operational , then other means of bringing up the system are provided. Several options that require operator intervention here are as follows It may be noted that both the Utiloader and the Loader must reside on the peripheral devices which are connected to the data link interface. The UIP 100 has provision for some diagnostic capabilities for the I O subsystem. The UIP 100 can determine the configuration on the data link interface, thus to provide a basic interface test. In addition, the UIP 100 can initiate self test on the storage module disk and the printer tape data link processors. Finally, the UIP performs tests on other data link processors that are part of the system configuration via the Burroughs direct interface BDI , that is, the test bus function. The UIP 100 via the PCC 40 also provides the link to the remote support center 50 While a preferred embodiment of the User Interface Processor and its maintenance subsystem has been described, other equivalent embodiments may be developed within the concepts of this disclosure which are hereinafter defined by the following claims