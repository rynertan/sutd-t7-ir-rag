# Speech synthesis system and method for exciting speech synthesis filter thereof.

## Abstract
Speech synthesis system implementable in an integrated circuit device and capable of converting frames of digital data into analog signals representative of human speech. The frames of data comprise digital representations of values of pitch energy and filter coefficients which are stored in non volatile memory. The filter coefficients are utilized to control a linear predictive filter of the speech synthesis system with the filter being excited by voiced and unvoiced excitations stored in non volatile memory. Components of the speech synthesis system include a variable interpolation circuit within the linear predictive filter to allow a variable number of interpolation steps to be calculated between successive values of reflection coefficients, control circuitry for determining the rate at which new frames of data are utilized, a pulse width modulated digital to analog converter operable at low voltage control, circuitry coupling the voiced and unvoiced excitation signals to the filter wherein an operator may select an external excitation signal rather than precalculated stored excitation signals and control circuitry for detecting a control signal indicating whether the speech parameters representative of pitch energy and filter coefficients being input to the speech synthesis system are in coded or uncoded format and including decoding circuitry within the system such that all calculations within the system may be based upon uncoded input parameters. The speech synthesis and control circuitry may be constructed by employing metal insulator semiconductor technology so as to provide circuits capable of low voltage operation.

## Claims
WIIBT IS CLAIMED IS 1. A speech synthesizer system comprising a input means for receiving frames of data, said frames of data comprising speech data and interpolation data b digital storage means for storing scale data c address means coupled to said input means and said digital storage means for selectively addressing specific scale data in response to said interpolation data d interpolation means coupled to said input means and said digital storage means for interpolating between adjacent frames of said speech data based upon said specific scale data e synthesizer means coupled to said input means and to said interpolation means for selectively converting said speech data into digital signals representative of human speech f digital to analog converter means coupled to said synthesizer means for converting said digital signals representative of human speech into analog signals g audio means coupled to said converter means for converting said analog signals into audible sound. 2. The speech synthesis system according to Claim 1, wherein the interpolation data of said frames of data receivable by said input means is coded interpolation data and further including decoding means coupled to said input means for decoding said coded interpolation data said address means being coupled to said decoding means for selectively addressing specific scale data in response to said decoded interpolation data. 3. The speech synthesis system according to either of Claims 1 or 2, wherein said digital storage means comprises a nonvolatile memory means. 4. The speech synthesis system according to either of Claims 1 or 2, wherein said digital storage means comprises a random access memory. 5. The speech synthesis system according to any of Claims 1 4, wherein said scale data represents a plurality of linearly related fractional values. 6. The speech synthesis system according to any ofClaims 1 4, wherein said scale data represents a plurality of nonlinearly related fractional values. 7. A speech synthesis system comprising a input means for receiving frames of speech data, said frames of speech data comprising binary representations of pitch data, energy data, reflection coefficient data and coded frame rate data b decoding means coupled to said input means for decoding said frame rate data c interpolator means coupled to said input means and to said decoding means, for providing a variable number of interpolation steps between adjacent frames of speech data, said variable number of interpolation steps being directly related to said frame rate data d synthesizer means coupled to said interpolator means for selectively converting said pitch energy data reflection coefficient data and interpolated values thereof into digital signals representative of human speech e converter means coupled to said synthesizer means for converting said digital signals into analog signals f audio means coupled to said converfer means for converting said analog signals into audible sound. 8. A speech synthesis system comprising a input means for receiving frames of speech data, said frames of speech data comprising binary representations of pitch data, energy data, reflection coefficient data and coded frame rate data b decoding means coupled to said input means for decoding said frame rate data c frame control means coupled to said decoding means and said input means for controlling the rate at which new frames of data are inputted to said input means d synthesizer means coupled to said input means for selectively converting said frames of speech data into digital signals representative of human speech e converter means coupled to said synthesizer means for converting said digital signals into analog signals f audio means coupled to said converter means for converting said analog signals into audible sound. 9. A speech synthesis system comprising a memory means for storing selectable speech data, said frames of speech data comprising binary representations of pitch data, energy data, reflection coefficient data and coded frame rate data b controller means for controlling the selective accessing of said speech data from said memory means c input means coupled to said memory means for receiving selected of said frames of speech data as accessed under control of said controller means d decoding means coupled to said input means for decoding said frame rate data e frames control means coupled to said decoding means and said input means for controlling the rate at which new frames of data are inputted to said input means f speech synthesizer means coupled to said memory means and responsive to said frames of speech data for generating digital signals representative of human speech g digital to analog converter means coupled to said speech synthesizer means for converting said digital signals representative of human speech into analog signals and h audio means coupled to said digital to analog converter means for converting said analog signals into audible sound. 10. The speech synthesis system according to either of Claims 8 or 9, further including an interpolator means, coupled to said frame control means, and responsive to said frame rate data for providing a variable number of interpolations between adjacent frames of speech data. 11. The speech synthesis system according to either of Claims 7 or 10, wherein said variable number of interpolations is 2XN where N is an integer less than one hundred. 12. The speech synthesis system according to Claim 9, further including switch means responsive to operator commands, said controller means being responsive to said switch means for controlling the selective accessing of said speech data from said memory means in accordance with said operator commands. 13. The speech synthesis system according toClaim 12, wherein said switch means comprises a keyboard having a plurality of operator actuatable key switches. 14. The speech synthesis system according toClaim 13, wherein said speech synthesis system comprises a portable learning aid. 15. The speech synthesis system according toClaim 13, wherein said speech synthesis system comprises a portable calculator device. 16. The speech synthesis system according toClaim 13, wherein said speech synthesis system comprises a portable language translator device. 17. A speech synthesis system comprising a input means for receiving frames of speech data, said frames of speech data comprising binary representations of pitch data, energy data and reflection coefficients b synthesizer means for selectively converting said frames of speech data into digital signals representative of human speech c converting means coupled to said synthesizer means for converting said digital signals representative of human speech into analog signals, said converter means comprising i controllable pulse width generating means for generating a pulse in response to a plurality of digital values, the width of said pulse being directly related to the magnitude of said digital values. ii converter means, responsive to said pulse for generating analog signals wherein magnitude of said analog signals in directly related to the width of said pulse. 18. A speech synthesis system comprising a voiced excitation means for generating voiced excitation signals b unvoiced excitation means for generating unvoiced excitation signals c filter means coupled to said voiced and unvoiced excitation means for selectively converting said voiced excitation signals and said unvoiced excitation signals into digital signals representative of human speech d converter means coupled to said filter means for converting said digital signals into analog signals representative of human speech e audio means coupled to said converter means for converting said analog signals into audible sound said unvoiced excitation means comprising a digital storage means for storing at least two different excitation signals b random address generating means, coupled to said digital storage means, for randomly generating the address of one of said at least two different excitation signals. 19. The speech synthesis system according to Claim 18, wherein said voiced excitation signals comprise a repeating chirp function. 20. The speech synthesis system according to either of Claims 19 or 20, wherein said filter means comprises a linear predictive filter. 21. The speech synthesis system according to any of Claims 18 20, wherein said digital storage means comprises a read only memory. 22. The speech synthesis system according to any of Claims 18 20, wherein said digital storage means comprises a random access memory. 23. A speech synthesis system comprising a voiced unvoiced excitation means for generating voiced unvoiced excitation signals b external excitation input means for receiving externally generated excitation signals c filter means for converting excitation signals into digital signals representative of human speech d control means for selectively coupling either said voiced unvoiced excitation means or said external excitation input means to said filter means in response to a control signal e converter means coupled to said filter means, for converting said digital signals representative of human speech into analog signals f audio means coupled to said converter means for converting said analog signals into audible sound. 24. The speech synthesis system according toClaim 23, wherein said filter means comprises a linear predictive filter. 25. The speech synthesis system according to either of Claims 23 or 24, wherein said control means comprises a tristate buffer. 26. The speech synthesis system according to any of Claims 23 25, wherein said externally generated excitation signals comprise residual excitation signals. 27. A speech synthesis system comprising a input means for receiving a control signal and a plurality of frames of data, said frames of data comprising coded or uncoded speech data b decoding means for decoding coded speech data c synthesizer means for converting uncoded speech data into digital signals representative of human speech d control means responsive to the presence of said control signal for causing said decoding means to be coupled to said input means and for causing said synthesizer means to be coupled to said decoding means e second control means responsive to the absence of said control signal for causing said synthesizer means to be coupled to said input means f digital to analog converter means coupled to said synthesizer means for converting said digital signals representative of human speech into analog signals g audio means coupled to said converter means for converting said analog signals into audible sound. 28. The speech synthesis system according toClaim 27, wherein said synthesizer means comprises a linear predictive synthesizer. 29. The speech synthesis system according to either of Claims 27 or 28, wherein said control signal is provided by a microprocessor. 30. The speech synthesis system according to any of Claims 27 29, wherein said coded or uncoded speech data is comprised of a plurality of parameters, said parameters consisting of a plurality of digital bits. 31. The speech synthesis system according toClaim 30, wherein said parameters comprising said coded speech data are shorter in length than said parameters comprising said uncoded speech data. 32. The speech synthesis system according to any of Claims 27 31, wherein said decoding means comprises a selectively addressable digital storage means. 33. The speech synthesis system according toClaim 32, wherein said digital storage means comprises a nonvolatile memory circuit, 34. A low voltage speech synthesis system comprising a memory means for storing selectable speech data b semiconductor integrated circuit controller means for controlling the selective accessing of said speech data from said memory means c complementary metal insulator semiconductor integrated speech synthesizer means coupled to said memory means and responsive to said speech data for generating digital signals representative of human speech d semiconductor integrated circuit pulse width modulated digital to analog converter means coupled to said speech synthesizer means for converting said digital signals representative of human speech into analog signals e audio means coupled to said digital to analog converter means for converting said analog signals into audible sound. 35. The speech synthesis system according toClaim 34, wherein said controller means is a complementary metal insulator semiconductor circuit. 36. The speech synthesis system according to either of Claims 34 or 35, wherein said controller means and said synthesizer means are integrated on a common semiconductor substrate. 37. The speech synthesis system according to Claim 34, wherein said pulse width modulated digital to analog converter means is a complementary metal in sulator semiconductor circuit integrated on a common semiconductor substrate with said synthesizer means. 38. The speech synthesis system according to any of Claims 34 37, wherein said controller means is a microprocessor. 39. The speech synthesis system according to any of Claims 34 38, further including switch means responsive to operator commands, said controller means being responsive to said switch means for controlling the selective accessing of said speech data from said memory means in accordance with said operator commands. 40. The speech synthesis system according to Claim 39, wherein said switch means comprises a keyboard having a plurality of operator actuatable key switches. 41. The speech synthesis system according toClaim 40, wherein said speech synthesis system comprises a portable learning aid. 42. The speech synthesis system according toClaim 40, wherein said speech synthesis system comprises a portable calculator device. 43. The speech synthesis system according toClaim 40, wherein said speech synthesis system comprises a portable language translator device. 44. The speech synthesis system according to Claim 40, wherein said speech synthesis system comprises a portable electronic game. 45. The speech synthesis system according toClaim 40, further including a complementary metal insulatorsemiconductor integrated time keeping circuit, wherein said speech synthesis system comprises a portable time keeping device. 46. The speech synthesis system according to any of Claims 34 45, wherein said pulse width modulated digitalto analog converter means comprises a controllable pulse width generating means responsive to a plurality of digital values for generating a pulse, the width of said pulse being directly related to the magnitude of said plurality of digital values b converter means responsive to said pulse for generating analog signals wherein the magnitude of said analog signals is directly related to the width of said pulse. 47. The speech synthesis system according to any preceding claim, wherein said audio means comprises a speaker. 48. The speech synthesis system according to any of Claims 1 46, wherein said audio means includes amplifier means coupled to a speaker. 49. A digital to analog converter circuit comprising a full pulse width generating means responsive to a first plurality of digital values for selectively generating a variable pulse width which is a multiple of a basic period b fractional pulse width generating means responsive to a second plurality of digital values for selectively generating a variable pulse width which is a fraction of said basic period c pulse width coupling means for coupling the output of said full pulse width generating means and said fractional pulse width generating means and d converting means for converting the output of said pulse width coupling means into analog signals representative of said first and second pluralities of digital values. 50. The digital to analog converter circuit according to Claim 49, wherein said first plurality of digital values comprises the most significant bits of a digital value. 51. The digital to analog converter circuit according to either of Claims 49 or 50, wherein said second plurality of digital values comprises the least significant bits of a digital value. 52. The digital to analog converter circuit according to any of Claims 49 51, wherein said full pulse width generating means comprises a digitally controllable shift register. 53. A digital to analog converter circuit comprising a controllable pulse width generating means for generating a pulse in response to a plurality of digital values, the width of said pulse being directly related to the magnitude of said digital values b converter means, responsive to said pulse for generating analog signals wherein the magnitude of said analog signals is directly related to the width of said pulse. 54. The digital to analog converter circuit according to Claim 53, wherein said controllable pulse width generating means comprises a digitally controlled shift register. 55. A method of exciting a speech synthesis filter, comprising the steps of a storing a periodic excitation signal in a first digital storage means b storing at least two different excitation signals in a second digital storage means c randomly selecting one of said at least two different excitation signals in said second digital storage means d selectively applying said periodic excitation signal and said randomly selected one of said at least two different excitation signals to the input of a speech synthesis filter. 56. The method of exciting a speech synthesis filter according to Claim 55, wherein said periodic excitation signal is a repeating chirp function.

## Description
BACKGROUND OF THE INVENTION This invention relates to a digital speech synthesis system and to circuits included as components thereof and capable of being implemented in an integrated circuit device, as well as a novel method of exciting a speech synthesis filter of the system. More specifically, this invention relates to the following aspects of a speech synthesis system interpolation circuitry utilized to increase the effective data rate in speech synthesis circuits data frame rate control in speech synthesis circuits digital to analog converter circuitry suitable for speech synthesis circuits methods and apparatus for speech synthesis filter excitation excitation of linear predictive filters within speech synthesis circuits by alternate sources of excitation data input techniques for speech synthesis circuits and low voltage speech synthesis circuits implemented in complementary metal insulator semiconductor technology. Several techniques are known in the prior art for digitizing human speech. For example, pulse code modulation, differential pulse code modulation, adaptive predictive coding, delta modulation, channel vocoders, cepstrum vocoders, formant vocoders, voice excited vocoders, and linear predictive coding techniques of speech digitization are known. The techniques are briefly explained in 1voice Signals Bit by Bit on pages 28 34 of the October, 1973 issue of IEEE Spectrum. In certain applications and particularly those in which digitized speech is to be stored in a memory, most researchers tend to use the linear predictive coding technique because it produces a very high quality speech using rather low data rates. An excellent example of the use of linear predictive coding systems, implementable in integrated circuit techniques may be seen in U.S. PatentApplication Serial No. 901,393 filed April 28, 1978, and assigned to the assignee of this invention. The speech synthesis system described in the aforementioned U.S..patent application utilizes frames of data which are comprised of digital representations of pitch, energy and certain linear predictive coefficients which are utilized to control a digital filter. The system described in the aforementioned U.S. patent application is capable of producing high quality synthetic human speech at a bit rate of as low as 1200 bits per second, utilizing a fixed rate of data frame entry. A more accurate representation of human speech may be obtained by increasing the frame rate to a level significantly higher than that described in U.S. PatentApplication Serial No.901,393 however, a corresponding increase is experienced in the number of bits which must be stored in memory to synthesize a given quantity of human speech.Further, certain aspects of human speech are quite redundant, and may be accurately synthesized utilizing a data rate significantly lower than that disclosed in the aforementioned U.S. patent application. An ideal solution to the aforementioned problem, would require a speech synthesis system capable of synthesizing human speech from frames of data which change rapidly during those complex periods of human speech and change slowly during redundant periods, thereby minimizing the required bit storage. A problem encountered in attempting to utilize variable frame rate data in speech synthesis circuits occurs when interpolation calculation is utilized between frames of data to enhance data rate capability. A fixed interpolation system such as that described in U.S. PatentApplication Serial No. 901,393, wherein eight interpolation calculations take place between each frame of data is adequate for fixed frame rate systems however, a variable frame rate system requires much more sophistication in interpolation circuitry. Specifically, during slowly changing periods of speech data, a more accurate portrayal of the human speech waveform may be achieved by increasing the number of interpolation steps between frames. Conversely, during rapidly changing aspects of human speech, few or no interpolations between frames of data are required to accurately synthesize human speech.Thus, in order to solve the aforementioned problem, a speech synthesis circuit must be able to vary the number of interpolation calculations taken between successive frames of speech data. Further, it has been discovered that in certain aspects of synthesis of human speech, the interpolation between frames of data may more accurately portray human speech if interpolated linearly, or in other circumstances, non linear interpolation may provide greater accuracy. In accordance with one aspect of the invention, a speech synthesis system is constructed with a linear predictive filter utilizing coded reflection coefficients to produce digital signals representative of human speech.A variable interpolation circuit within the linear predictive filter allows a variable number of interpolation steps to be calculated between successive values of reflection coefficients. Additionally, a user programmable option allows the user to select a linear, nonlinear, or combination form of interpolation. As previously described, speech synthesis if carried out at an increased data rate would typically require a corresponding increase in the number of bits to be stored in a memory to synthesize a given quantity of human speech.To reduce the bit storage requirements of the memory while maintaining the capability of speech synthesis at a relatively high data rate is the subject of two papers delivered at the 1977 IEEE Conference on Acoustics, Speech and Signal Processing, and published in the record thereof.One attempted solution was suggested in Variable to FixedRate Conversion of Narrowband LPC Speech by E.Blackman,R. Viswanathan and J. Makhoul. The aforementioned solution required transmission of pitch, gain and reflection coefficients in three separate variable rates, with separate transmission criterion and a three bit header code to distinguish transmissions. Additionally, transmit and receive buffers were necessary in that system to convert the transmission back into a fixed rate signal. The second attempted solution was documented in a paper entitled The Application of a Functional Perceptual Model of Speech to Variable RateLPC Systems by R. Viswanathan, J. Makhoul and R. Wicks.This second solution involved the transmission of pitch and gain information at a fixed frame rate, and utilizing a variable frame rate for transmission of reflection coefficients. In another aspect of the invention, a speech synthesis system which is implementable in an integrated circuit device , and capable of converting frames of data into analog signals representative of human speech is constructed. The frames of data are comprised of digital representations of values of pitch, energy and certain filter coefficients. A control circuit determines the rate at which new frames of data are utilized by the speech synthesis circuit by varying the number of interpolation steps between each frame of data. This approach enables the speech synthesis system to accurately synthesize human speech at the lowest possible data rate from frames of data which are utilized at varying rates thereby minimizing the bit storage requirements of the memory included in the speech snythesis system. Another problem encountered in integrated circuit speech synthesis circuitry involves the conversion of digital signals into analog signals with sufficient accuracy to generate analog signals representative of human speech.While certain large values of speech signals may be clipped or truncated, accurate portrayal of small values in the speech waveform is necessary to synthesize human speech accurately. Standard digital to analog conversion techniques such as disclosed in U.S. Patent Application Serial No. 901,393, while adequate for higher voltage PMOS implements tion lack sufficient accuracy and resolution for lower voltage applications such as CMOS circuitry. A lower voltage application such as CMOS circuitry prohibits the large voltage swing necessary to implement standard digital toanalog converter circuitry. The present invention addresses this latter problem by providing a digital to analog converter capable of accurately converting digital data into analog signals representative of human speech, while operating at lower voltage levels, A digitally programmable shift register is utilized to generate a pulse, which is generally related to the magnitude of a digital signal. A programmable delay circuit provides finer resolution by converting the least significant digital bits of data into pulse width information of shorter duration than the minimum pulse width generated by the controllable shift register. Pulse width information generated by the shift register and delay circuit is applied to the bases of two crossconnected transistors to drive a speaker or voice coil. Linear predictive coding systems utilize a linear predictive filter which is excited by voiced and unvoiced excitation signals. Typically, a voiced excitation signal is generated by a periodic source, such as a chirp function.In other linear predictive coding synthesis systems, the unvoiced excitation is typically characterized as white noise, or pseudorandom digital signal. Such systems implemented in integrated circuitry, typically generate a fixed digital value as an unvoiced excitation signal, and simulate a white noise input by pseudorandom generation of a sign bit to be utilized with the fixed digital value.Such systems adequately generate a signal in digital circuitry which is equivalent to a white noise excitation however, variances in amplitude between a chosen fixed digital value for unvoiced excitation and the varying periodic excitation utilized result in unbalanced voiced unvoiced excitation signals. In accordance with another aspect of this invention a speech synthesis system is provided within which the unvoiced excitation signal may be accurately scaled to balance with the voiced excitation signal. This approach enables the operator to choose an accurate level of unvoiced excitation signals. To this end, the speech synthesis system utilizes a linear predictive filter with voiced and unvoiced excitation to produce a digital signal representative of human speech. The voiced excitation is provided by a repeating chirp function stored in memory. The unvoiced excitation consists of two excitation signals of opposite sign, stored in progammable memory and randomly addressed.The programmable storage of unvoiced excitation signals allows gain scaling between voiced and unvoiced excitation to be easily accomplished. Typically, a speech synthesis system such as described in U.S. Patent Application Serial No. 901,393 utilizes an excitation signal generated from fixed circuitry, or stored in non volatile memory within the speech synthesis circuit. While this method is acceptable for synthesis of a standard speaker s voice, the range of excitation values necessary to provide alternate speaker s voices, or sound effects or the like, is not generally stored within speech synthesis circuits due to the wide range of possible values.The use of speech synthesis circuits in vocoder applications, wherein the excitation signal is the residual signal generated during the analysis phase of the vocoder operation is known in the art. Such vocoder synthesizers,however, are generally incapable of synthesizing speech from prerecorded data. The present invention addresses this latter problem by providing a speech synthesis system capable of generating synthetic speech from excitation signals which may be either prerecorded and stored within the speech synthesis circuit or spontaneously generated by the operator of the system. To this end, there is provided a speech synthesis circuit capable of synthesizing human speech from excitation signals which may be either prerecorded and stored within the speech synthesis circuit or which may be residual excitation signals generated during speech analysis. In accordance with the present invention, a speech synthesis system implementable in an integrated circuit device and capable of converting frames of data into analog signals representative of human speech is constructed.The frames of data are comprised of digital representations of values of pitch, energy and certain filter coefficients, which are stored in nonvolatile memory. The filter coefficients are utilized to control a linear predictive filter which is excited by voiced and unvoiced excitations stored in nonvolatile memory. A control circuit coupling the excitation signals to the linear predictive filter allows the operator to select an external excitation signal rather than the precalculated stored excitation signals. Thus, the synthesizer may be utilized in a vocoder application, wherein a residual excitation signal transmitted from an analysis circuit may be utilized as the excitation signal. The speech synthesis system of U.S. PatentApplication Serial No. 901,393 utilizes a coded input parameter system common in speech synthesis systems wherein a coded value is utilized t9 minimize the data input rate required by the speech synthesis system. Such coded parameters may accurately portray the values of parameters necessary to synthesize human speech however, certain speech parameter generation algorithms provide the necessary filter, pitch, and energy paran eters in uncoded format.While an increase in the bit rate required to accurately synthesize human speech is experienced while utilizing uncoded parameters, the coding method may add unnecessary steps to a system wherein filter parameters are directly calculated. A speech synthesis system capable of utilizing both coded and uncoded parameters to generate human speech must be capable of accepting input parameters of various lengths, since coded parameters normally consist of fewer bits than uncoded parameters. Therefore, the present invention has as another aspect the provision of a speech synthesis system capable of accurately synthesizing human speech from input parameters which are directly loaded or loaded in an encoded format. The speech synthesis system is capable of synthesizing human speech from frames of data which may consist of parameters of varyinglensths and is implementable in an integrated circuit device. The system is capable of converting frames of data into analog signals representative of human speech, wherein the frames of data are comprised of digital representations of values of pitch, energy and certain filter coefficients. The binary representations of pitch, energy and filter coefficients may be inputted as prearranged coded values or may be directly loaded into a data input register. Control circuitry within the speech synthesis system detects a control signal indicating whether the parameters being inputted are in coded or uncoded format, and provides decoding circuitry within the speech synthesis system.All calculations within the speech synthesis system are thus based upon uncoded input parameters. As integrated speech synthesis systems continue to develop, a need arises for low voltage applications.Such low voltage applications which are known in the art wherein a small battery source may provide the electrical supply, have two inherent problems. Firstly, in an embodiment such as an electronic learning aid, translator, or calculator the current source required for such a system will result in short battery life. Secondly, a low voltage speech synthesis system will have difficulty in accurately simulating the human speech waveform while constrained to a low voltage swing. Standard digital to analog converter devices utilized in integrated circuit speech synthesis systems, such as the circuit described in U.S. Patent ApplicationSerial No. 901,393, lack sufficient accuracy and resolution to be utilized in low voltage applications such as complementary metal insulator semiconductor technology. An ideal solution to the aforementioned problem, would require a speech synthesis system capable of synthesizing human speech from frames of data at sufficiently low voltage levels to reduce the current drain which shortens battery life, and a digital to analog converter capable of producing accurate representations of complex waveforms at low voltage levels. The present invention has as another aspect, the provision of a speech synthesis system capable of accurately synthesizing human speech at low voltage levels.To this end, the speech synthesis system includes a digitalto analog converter capable of accurately modeling complex waveforms at low voltage levels to provide a low voltage speech synthesis system with a linear predictive filter.The linear predictive filter utilizes reflection coefficients to produce digital signals representative of human speech. An integrated circuit controller controls the access of digitized speech data stored in a memory circuit.Synthesis and control circuits are implemented in metalinsulator semiconductor technology to provide low voltage operation. A pulse width modulated digital to analog converter permits accurate conversion of digital signals into analog signals in low voltage operation. BRIEF DESCRIPTION OF THE DRAWINGS The novel features believed characteristic of the invention are set forth in the appended claims. The invention itself, however, as well as a preferred mode of use, further objects and advantages thereof, will best be understood by reference to the following detailed description of an illustrative embodiment when read in conjunction with the accompanying drawings, wherein FIGURE la is a view of an electronic learning aid which is a suitable structure for enclosing the speech synthesizer system FIGURE 1b is a generalized block diagram of a speech synthesis system FIGURES 2a and 2b form a detailed block diagram of the speech synthesizer FIGURE 3 is a logic diagram of the input data register and frame control PLA FIGURE 4 is a logic diagram of the interpolation counter circuity FIGURE 5 is a detailed logic diagram of the speak latch circuitry and status latch circuitry. FIGURE 6 is a detailed logic diagram of the instruction decoder circuitry. FIGURE 7 is a detailed logic diagram of the parameter load control circuitry. FIGURES 8a and 8b form a composite block diagram of the array multiplier FIGURES 9a 9d are detailed logic diagrams of the blocks which form the array multiplier. FIGURES 10a 1Oc are detailed logic diagrams of the recoding logic FIGURE 11 is a detailed logic diagram of the filter adder FIGURE 12 is a detailed logic diagram of one cell of the B Stack, PPC, Y Latch register FIGURE 13 is a detailed logic diagram of multiplex 58 and register 66 FIGURES 14a and 14b are detailed logic diagrams of the digital to analog and output circuitry. GENERAL DESCRIPTION OF THE INVENTION Referring to Figure 1a, there is shown an electronic learning aid which may serve as a suitable structure for enclosing the speech synthesis system of the present invention. Figure 1b shows a generalized block diagram of the major components which make up such a learning aid.Keyboard 16 may be a standard matrix keyboard such as the type disclosed in U.S. Patent No. 4,074,055. Various algorithms required to implement the desired modes of operation of an electronic learning aid, electronic language translator or other applications may be programmed into the microprocessor in a manner well known in the art. An example of one such algorithm may be seen in U.S. Patent ApplicationSerial No. 901,393 filed April 28, 1978. Data ROM 12 is a standard non volatile Read OnlyMemory such as is described in the aforementioned U.S.Patent Application Serial No. 901,393. The coded or uncoded filter parameters which are utilized to control synthesizer 10 are stored therein. Synthesizer 10 is a linear predictive filter type synthesizer such as is described in U.S. PatentApplication Serial No. 905,328 filed May 12, 1978 however, improvements in the synthesizer circuitry which result in higher quality speech, lower data rates and smaller circuit size are incorporated herein.Synthesizer 10 is controlled by microprocessor 14, and generates synthetic speech at speaker 18 by utilization of certain filter parameters stored in ROM 12. While synthesizer 10 is shown being controlled by microprocessor 14, it will be understood by those skilled in the art that any digital control mechanism may control synthesizer 10.In an embodiment disclosed herein, in which synthesizer 10 is implemented in complementary MIS, such as CMOS, it is preferable that microprocessor 14 also be implemented in CMOS to permit both devices to be operated from a single low voltage source, such as a battery.The linear predictive filter utilized in synthesizer 10 is a single multiplier, lattice type filter similar to the filter described in U.S. Patent Application SerialNo.905,328 filed May 12, 1978. U.S. Patent ApplicationSerial No. 905,328 is hereby incorporated by reference.The reader is encouraged to read the aforementionedU.S. Patent Application to familiarize himself with the basic operation of this complex circuitry. DETAILED BLOCK DIAGRAM Referring to Figures 2a and 2b, there is shown a detailed block diagram of synthesizer 10. Most of the blocks of Figures 2a and 2b are shown in greater detail in later figures. Speech data, comprising either coded or uncoded filter coefficients, is received by synthesizer 10 fromROM 12 at the Data In pad of input register 22, Input register 22 is a ten bit register latch which accepts the speech date serially and outputs the data in parallel to frame control PLA 30. Input output pads 1, 2, 4 and 8 accept control data from microprocessor 14, and input the control data to instruction decoder 20. Input output pads 1, 2, 4 and 8 are bidirectional lines and microprocessor 14 is therefore able to access speech data out of input register 22 as in an alternate embodiment wherein a control mechanism may be utilized to examine such data. Instruction decoder 20 is utilized to decode the instructions which microprocessor 14 inputs to synthesizer 10. Instruction decoder 20 also sets speak latch 24 and parameter load control 26. Speak latch 24 generates logic signals which are utilized throughout synthesizer 10 to indicate that synthetic speech is being generated. Parameter load control 26 is utilized to control the loading of data into input register 22.In addition to instruction control of parameter load control 26, the status latch 28 is also capable of controlling the input of data to input register 22 by detecting certain special states of input data which will later be described in detail. Framecontrol PLA 30 is utilized to decode the aforementioned special states of input data which in turn set the special state latches in status latch 28. Frame control PLA 30 also decodes special states of the input data which control how many interpolation steps take place between each frame of data, thereby allowing synthesizer 10 to vary the rate at which data is applied. Interpolation counter 34 is utilized to generate a signal which controls the number of interpolation steps which will be calculated between adjacent frames. Code RAM 32 is a twelve by ten bit RAM utilized to store an entire frame of data. An entire frame of data will include a pitch parameter, an energy parameter and ten filter parameters. The maximum length of an uncoded parameter is ten bits, and twelve parameters are normally required for each frame. In one mode of operation, synthesizer 10 generates synthetic speech from uncoded parameters. These parameters are transferred from code RAM 32 to the ROM RAM load, parallel serial converter 38, to be serially loaded out to the linear predictive filter. In the alternative mode of operation the coded parameters are utilized by address PLA 36 to generate an address for the appropriate uncoded parameter stored in parameter ROM 40. The uncoded parameters from ROM 40 are inputted to converter 38 and then serially loaded out to the linear predictive filter. The parameters outputted from converter 38 are coupled into array multiplier interpolator 50. Array multiplier interpolator 50 functions similarly to the array multiplier of U.S. Patent Application Serial No. 905,328, with the additional capability of conducting interpolation steps. Array multiplier interpolater 50 is coupled to filter adder 54, which is utilized to perform the additions and subtractions necessary to implement the filter function.The output of adder 54 is coupled to B stack, PPC register and Y latch register 56 and to multiplexer 58. Register 56 serves as a temporary store for those intermediate values necessary to perform the filter calculations, and storing the pitch period count PPC . Register 56 also serves to drive D to A converter 64 with appropriate output values. D to A converter 64 converts the output of the filter to analog signals which drive speaker 18. Multiplexer 58 serves to couple information back up into multiplier interpolator 50 through recoding logic 52 from adder 54 or the multipurpose shift register 66. Shift register 66 is a multipurpose shift register utilized to couple excitation data or scale data from ROM 78 into multiplier interpolator 50 through multiplexer 58 and recoding logic 52. Scale data is utilized by multiplier interpolator 50 to perform interpolation. Additionally, shift register 66 couples pitch period counter PPC information which is utilized to address excitation data in ROM 78.Pitch period counter information is coupled through multiplex 70 to address register 72 where it is utilized to address excitation data in ROM 78. Unvoiced address generator 76 is utilized during unvoiced periods of speech to randomly address one of two excitation values, utilized during unvoiced speech, which are stored in ROM 78. Tri state buffer 68, in an alternative embodiment of the present invention is utilized to control the excitation input to shift register 66. Synthesizer 10 may be utilized as a residually excited synthesizer, in a vocoder application, for example. In such an alternative embodiment a residual excitation signal is applied to residual input pin 80, and tri state buffer 68 is disabled by a control signal at residual control pin 82. In this alternative embodiment, parameters are inputted to multiplier interpolator 50 from an external source, rather than through converter 38. SYSTEM TIMING The synthesizer 10 is preferably implemented using precharged conditional discharge type logics. Thus, four clock signals, 1 4 are appropriate for. use in such precharge, conditional discharge logic. There are two main clock phases 01 and 2 and two precharge clock phases 03 and 4 . Phase 3 goes high during the first half of phase 1 and serves as a precharge therefor. Phase 4 goes high during the first half of phase 2 and serves as a precharge therefor. A set of clocks 1 4 is required to clock one bit of data, and thus correspond to one time period. Timing signals, labelled TI T22, each having a period on the order of 4.5 microseconds are utilized throughout the system. Selecting a time period on the order of 4.5 microseconds permits data to be outputted from synthesizer 10 at a 10 kilohertz rate i.e. at a 100 microsecond period which provides for a frequency response of 5 kilohertz in the digital to analog converter 64. It will be appreciated by those skilled in the art, however, that depending upon the frequency response desired, the number of reflection coefficients utilized and the type of logics utilized, the periods or frequencies of the clocks and clock phases may be substantially altered. Thirteen parameter count PC signals are also utilized in the depicted embodiment of the invention.The first twelve of these, PC O through PC 11 correspond to the times when the energy, pitch, and K1 K10 reflection coefficients are available in parallel serial converter 38.Each of the first twelve parameter counts comprise two cycles, referred to as the A and B cycles. Each cycle, whether A or B, begins at T18 and ends at the next T18.During each parameter count the value in parallel serial converter 38 is utilized as a target value for interpolation with an existing value stored in a recirculating portion of multiplier interpolator 50. During the A cycle, the appropriate existing parameter is withdrawn from the recirculating portion of multiplier interpolator 50, and during the B cycle the newly interpolated value is reinserted. The thirteenth parameter count, PC 12, is provided fpr timing purposes so that all twelve parameters are interpolated once each 2.5 millisecond, and for indicating that period of time during which variable frame rate data is inputted. As was discussed earlier with respect to interpolation, the synthesizer of the present invention is capable of performing from zero to one hundred twenty seven interpolations between each frame of parameters inputted.A new interpolation count signal is available from interpolation counter 34 every 2.5 milliseconds, and is utilized to address a scale value in excitation scale ROM 78. Thus the period for interpolation remains constant at 2.5 milliseconds,regardless of the number of interpolation steps between two values. PARAMETER DATA COMPRESSION New parameters may be inputted to synthesizer 10 at a fifty hertz frame rate. It will be seen subsequently that in multiplier interpolator 50, the pitch data, energy data and reflection coefficients are utilized as ten bit binary numbers. If each of the twelve parameters were updated with a ten bit binary number at a fifty hertz rate, a 12x10x50, or 6,000 hertz bit rate would result.Therefore, in order to lower the bit rate, the data compression scheme of U.S. Patent Application Serial No.901,393, filed April 28, 1978, may be utilized. Accordingly, the aforementioned U.S. Patent Application is incorporatd herein by reference. In Figure 6 of the aforementioned U.S.Patent Application there is shown pictorially a representation at four different lengths of data frames. One frame, labelled voiced frame has a length of 49 bits, while another labelled unvoiced frame , has a length of 28 bits. A repeat frame has only ten bits and a zero energy frame has only 4 bits. In an alternative embodiment to the coding scheme of U.S. Patent Application Serial No. 901,393 of April 28, 1978, a direct, uncoded, ten bit binary number may be loaded for each parameter. The input circuitry of synthesizer 10 is capable of accepting either format. SYNTHESIZER LOGIC DIAGRAMS Various portions of synthesizer 10 will now be described in detail with reference to Figures 3 3 through 14, which depict in detail the logic circuits which implement synthesizer 10. Certain well known sections of the block diagram depicted in Figures 2a and 2b are not included in Figures 3 14. The following discussion, with reference to Figures 3 14, refers to logic signals available at many points in the circuit. Synthesizer 10, in the embodiment disclosed, is implemented in complementary MIS, such as CMOS. It must be remembered that in CMOS devices, a logic zero corresponds to a zero voltage, that is Vss. Further, theP channel devices depicted in the aforementioned figures are conductive when a logic zero is applied to their respective gates. Also, a logic one in CMOS devices course sponds to a positive voltage, 3V in the embodiment disclosed Vdd . Therefore, the N channel devices depicted are conductive when a logic one is applied to their respective gates. When a logic signal is referred to which is unbarred, the signal is to be interpreted as True logic, that is, a binary one indicates the presence of Vdd and a binary zero indicates the presence of Vss. Logic signals which are barred indicate False logic and the aforementioned relationships are reversed.It should also be understood that a numeral in a clocked gate indicates which of the clock phases is utilized, as a precharge clock.The letter S in a gate indicates the gate is statically operated. INPUT DATA REGISTER Referring to Figure 3, there is shown a logic diagram of input data register 22. Input data register 22 is a ten stage register, the first stage of which is shown within the detail marked A. Input data register 22 is ten stages in length to allow synthesizer 10 to accommodate uncoded parameters up to ten bits long, or, in an alternative embodiment, coded parameters of the type utilized in U.S.Patent application Serial No. 909,393. Certain signals are utilized to control input data register 22. A clear signal CLR is generated by parameter load control 26, and is utilized to clear input data register 22 at time T22, during speech. The IO, ROM control signal, is delayed to form IOD, which is utilized to clock bits of data into input data register 22. An optional control signal, HC, is utilized as a modified Huffman code. This signal is utilized during variable frame rate operation to control the receipt of the Huffman code, which, those skilled in the art will recall, is a variable length code. FRAME CONTROL PLA Frame control PLA 30 is shown in Figure 3. PLA 30 is a programmable PLA, and is therefore shown without gates. PLA 30 is utilized to detect certain special states which occur in the input data. Among those special states are those which effect the length of each individual frame, including the Repeat state RPT the Energy equal zero state E O the Pitch equal zero state P O and the End of File or Energy equal fifteen state E 15 . Additionally, the lower half of PLA 30 also decodes the Huffman code mentioned earlier, or a standard binary code, either of which may be utilized during variable frame rate operation. The decoded variable frame rate data is utilized to generate the signals ICP6 ICPO, which are in turn utilized to control interpolation counter 34. The parameters in input data register 22 are also passed through PLA 30 to the parameter RAM 32. These signals are shown as DIO DI9. INTERPOLATION COUNTER Interpolation counter 34 is shown in detail inFigure 4. Previous attempts at variable frame rate voice synthesis have had difficulty due to the problem of varying lengths of time between each frame, and the question of interpolation therein. Interpolation counter 34 is capable of utilizing the variable frame length data to control the number of interpolation steps between each frame. Thus, during rapidly changing speech, few or no interpolations take place between data frames. However, during slowly changing speech, up to one hundred twenty seven interpolations may take place. Register 343 is a seven stage shift register, which is initially set by the signals ICP6 ICPO. The first stage of register 343 is shown within the detail marked A The signals ICP6 ICPO initially set register 343 to some number, the interpolation count, which is between zero and one hundred twenty seven. The interpolation count initially set into register 343 is clocked out and around through a series of inverters which generate an appropriate amount of delay. Gates 344 are utilized to selectively increment the interpolation count after each interpolation. The new interpolation count is then shifted back into register 343, whose gate 341 is utilized to detect the interpolation count equal zero IC O state. When the IC O state is detected, gates 342 are utilized to latch this condition.The IC O condition is utilized throughout synthesizer 10 to indicate the end of interpolation, and allow the entry of new data. The interpolation count is outputted from interpolation counter 34 to be utilized as part of the address in excitation scale ROM 78. SPEAK LATCH Figure 5 shows a detailed logic diagram of speak latch 24. Speak latch 24 consists of four latch circuits utilized to set and hold signals which indicate synthesizer 10 is generating speech. Gates 241 form a latch which hasSPK as its input. SPK is generated by instruction decoder 20 in response to an input command which causes speech to be generated utilizing coded speech parameters. Instruction decoder 20 may also generate SPKEXT in response to an input command which causes speech to be generated utilizing uncoded, ten bit, binary parameters, as discussed earlier with respect to an alternate method of operation. The SPK command is utilized to generate the speak enable SPKE command out of gates 241, and to set latch 242 to generate SPKL.The SPKEXT command will set a latch 244 comprised of gates 243, which in turn will set latch 244 and generate SPKEXTL.The occurrence of either SPKEXTL or SPKL will in turn generate the TALK signal. Gate 245 is utilized to reset the latches comprised of gates 241 and 243 during a power up, or after a reset signal. The speak reset SPRST command is generated by gate 246 by receipt of an end of file or Energy equal fifteen E 15 code. Additionally, gate 247 is utilized to latch out a talk status signal which indicates synthesizer 10 is generating speech. Thus, the logic signals outputted by speak latch 24 are utilized throughout synthesizer 10 to indicate the generation of speech. STATUS LATCHESStatus Latches 28 are also shown in detail in Figure 5.The function of the various status latches is identical to the function described in U.S. Patent Applciation Serial No. 901,393, and will only be described briefly herein. Latching signal LATCH 1 is generated by gate 281 at the beginning of a frame of data, the inputs to gate 281 all signifying a frame start. The LATCH 1 signal will strobe any SPKEXTL or SPKL signal at latch 244 or 242 in the speak latch 24, and will additionally strobe the output of latches 289 the Pitch equal zero P O latch and 290 the Energy equal zero E O latch into latches 284 and 285 to generate Old E O and Old P O. The contents of latches 284 and 285 are utilized in conjunction with theP O signal to generate the INHIBIT signal. As in the synthesizer of U.S. Patent Application Serial No. 901,393, the INHIBIT signal is utilized to inhibit interpolations in certain conditions.During transition from voiced to to unvoiced speech, or unvoiced to voiced speech, it is advantageous to insert new parameters directly, without interpolations.Also, interpolations are not desirable when transi.ioning from silence to speech. Aswans explained in detail in U.S. PatentApplication Serial No. 901,393, it has been determined that fewer parameters are required to accurately represent unvoiced speech. Therefore, gate 288 is utilized to generate a zero parameter ZPAR signal during unvoiced speech Old pitch equal zero after the parameter count has reached five PC 5 . Gate 288 also zeroes all parameters during non speaking periods, by utilizing the TALK signal and the TALKD signal generated by latch 283. INSTRUCTION DECODER Referring to Figure 6, there is shown a detailed logic diagram of instruction decoder 20. Instructions from microprocessor 14 are input to synthesizer 10 on I O pinsI 01, I 02 and I 04. The instructions are clocked in each time a Processor Data Clock PDC signal is generated. The instructions are decoded by PLA 202. Many of the instructions are identical to those utilized by the synthesizer of U.S.Patent Application Serial No. 901,393. A brief description of each instruction and its function is listed below. The Reset RST instruction is a software reset instruction which is utilized by gate 201 in conjunction with the synthesizer power up clear PUC signal to form PUC RST.This instruction is then utilized to reset speak latch 24. The Read READ instruction is a signal from microprocessor 14 telling synthesizer 10 to access one data bit from ROM 12. The Load Address LA instruction is an instruction which requires two PDC signals to execute. On the first PDC, the LA instruction is latched into latch 203. Latch 203 disables PLA 202 so that no command is decoded. On the second PDC, gate 205 is enabled, causing instruction decoder 20 to output an 11 signal to ROM 12.The I1 signal instructs ROM 12 to load four bits of address. The Speak SPK instruction causes synthesizer 10 to begin synthesizing speech utilizing coded speech parameters. The SPK instruction is utilized throughout synthesizer 10. The Speak External SPKEXT instruction causes synthesizer 10 to begin synthesizing speech utilizing direct, uncoded, parameter loading, as in the alternate embodiment discussed herein. The Read and Branch R B instruction is an instruction to ROM 12 to internally read data and load the data back into its address register, to allow indirect addressing. The Test Talk TTALK instruction and the output OUTPUT instruction both require three PDC signals to execute. The TTALK instruction sets latch 206 and disables PLA 202 through gate 240. On the next PDC, the output of latch 206 is clocked through gate 208 to generate signalC2. Signal C2 is utilized to control the buffer betweenI 08 and IR9, allowing the talk status TALKST signal to be output on I 08. Thus, microprocessor 14 can determine whether synthesizer 10 is talking. The next PDC signal shuts off the C2 signal and resets latch 206. The OUTPUT instruction also requires three PDC signals to execute. Latch 207 and gate 209 interact in the same manner as latch 206 and gate 208. However, in the case of the OUTPUT instruction, a C1 signal is generated which enables the buffer to all of the I O pads.In this manner, microprocessor 14 can access data in ROM 12, through synthesizer 10. Detail diagrams of the buffers for the I O pads are also shown in Figure 6b. PARAMETER LOAD CONTROL Parameter load control 26 is shown in detail inFigure 7. Parameter load control 26 generates the IO signal to ROM 12. The IO signal and the 11 signal, generated by instruction decoder 20, control ROM 12 in the manner described in U.S. Patent Application Serial No. 901,363.The IO signal is utilized to clock data out of ROM 12. Gate 261 is utilized to generate the ParameterLoad Enable PLEN signal which allows parameters to be written into code RAM 32. PLEN is generated unless one of three conditions exist at the input of gate 261. When a repeat RPT bit is detected, the PLEN signal stops. A RPT bit is utilized when old parameters are to be repeated, thus no new parameters should be loaded. When the Energy parameter is zero E O , indicating silence, the PLEN signal is disabled. Lastly, as described in U.S. PatentApplication Serial No. 901,393, during unvoiced speech the system utilizes fewer parameters to accurately represent speech. Thus, when the pitch parameter is equal zero P O and the parameter count indicates that the first six parameters have been loaded PCe5 , PLEN is disabled. Gate 262 is utilized during variable frame rate operation to allow the frame rate data to be loaded atPC 12 despite a condition which would preclude loading parameters. Gate 266 is utilized to set latch 263, the output of which is utilized in conjunction with the even clock times TEVEN by gate 264 to generate IO signals.Gate 266 is utilized to distinguish between loading coded or direct parameters, since in the embodiment disclosed coded parameters consist of two to seven bits and direct parameters consist of ten bits. Gate 265 is utilized to reset latch 263. Gate 267 is utilized to generate theCLR signal which clears the input register. RECODING LOGIC Recoding logic 52 couples the outputs of multiplexor 58 to multiplier interpolator 50. Recoding logic 52 is shown in detail in Figures 10a d. Recoding logic 52 consists of six stages, three of which are identical, as seen inFigure 10b. The first stage of recoding logic 52 labelledREL 20 generates signals for the first two stages of multiplier interpolator 50. The subscripts on each control signal indicate to which stage of multiplier interpolator 50 it is coupled. The third stage of multiplier interpolator 50 and the seventh stage require additional control signals due to the interpolation function therein The INT signal discussed in the interpolation section is generated in the section of reading logic 52 labelled REL 30 in Figure 10a, and the T18 signal for the seventh stage is generated by the stage labelled REL 50 in Figure 10c. Recoding logic 52 outputs 2, 2, 7 and 1 to each stage of multiplier interpolator 50 with the exception of stage one which receives only 1, 1, and outputs. Effectively, as seen in U.S. Patent Application Serial No. 901,393, recoding logic 52 permits multiplier interpolator 50 to process, in each stage thereof, two bits of information in lieu of one, by utilizing Booth s Algorithm.Booth s Algorithm is explained in Theory and Application ofDigital Signal Processing , published by Prentice Hall 1975, at pp. 517 18. MULTIPLIER INTERPOLATOR A block diagram of multiplier interpolator 50 is formed by the composite of Figures 8a and 8b. Multiplier interpolator 50 is an array multiplier. Array multipliers are sometimes referred to as Pipeline Multipliers . For example, see Pipeline Multiplier by Granville Ott, published by the University of Missouri. Multiplier interpolator 50 has seven stages, stage 1 through 7 and operates similarly to the array multiplier disclosed in the aforementioned U.S. Patent Application Serial No. 905,328. The equations in Table I herein represent the operation of the digital filter wherein multiplier interpolator 50 and filter adder 54 are utilized to solve these equations. The inputs to multiplier interpolator 50 are the target values for new parameters, input at the PROMOUT terminal of the first stage, the aforementioned 1, 1, 2 and 2 signals from recoding logic 52, and the INT and TPAR signals from recoding logic 52. The outputs of multiplier interpolator 50, MULT O MULT13 and PITCH O PITCH 9 are applied to filter adder 54. The blocks which make up individual sections of each stage are labelled A 1, B 1 through B 5, C 1 through C 3 and D 1 and D 2. The detailed logic diagrams of each block section are shown in Figures 9a 9d. The operation of multiplier interpolator 50 is identical to that of the multiplier in U.S. Patent Application Serial No.901,393, with the exception of additional interpolation circuitry which will be explained with reference to Figures 8a and 8b and also 9a 9d. The first stage of multiplier interpolator 50 is comprised of nine A 1 blocks, with an additional bit of storage in the two inverters on its input and are thus responsive to the TPAR signal and to rT, Tri, 5 signals output from recoding logic 52. When multiplications occur in multiplier interpolator 50, the most significant bit is always maintained in the cleft most column elements while the partial sums are continuously shifted toward the right. Inasmuch as each stage of multiplier interpolator operates on two binary bits, the partial sums, labelled E are each shifted to the right two places. Thus, a total capacity of ten bits is available.As explained earlier, whether coded or direct parameters are utilized, the parameters utilized in multiplier interpolator 50 are ten bits in length, due to the decoding of any coded values by address PLA 36 and ROM 40. The ten bit parameters which are loaded into multiplier interpolator 50 represent the target values for current calculations. As the interpolation calculations reach these target values, the target values become current values, and new target values are loaded into multiplier interpolator 50 at the PROMOUT point. Current values for filter parameters are stored within multiplietir.terpolator 50 in recirculating shift registers contained in all but the most significant bit of each stage. The recirculating shift registers circulate out of B terminals of each block and into the A terminals of the block below. At the bottom or seventh stage, the values are circulated back up through the D terminals into the C terminals. The current values shifted into the A terminals of each block are the multiplicands. The multipliers are the values input to multiplier interpolator 50 by recoding logic 52. The recirculating shift registers within multiplier interpolator 50 form an eleven bit shift register, with each parameter shifting by each eleven time periods. There are twenty two time periods, and each parameter K1 K9 is utilized twice during filter calculations. Thus eighteen time periods are required for these nine parameters. The K10 value and the energy value, as disclosed in U.S. PatentApplication Serial No. 901,393, are each utilized once in filter calculations, and are therefore swapped or exchanged, in the seventh stage of multiplier interpolator 50. This requires two additional time periods. Of the two remaining time periods, one is utilized during interpolation, and the other is not utilized. In Figure 9d, there is shown a detailed logic diagram of blocks D2 and D1. In each of the D type blocks, there is shown a group of gates labelled 501. The leftmost, latch 501a is a recirculating latch wherein either K10 or the energy value is stored. The multiplex gate 501b, in gates 501, is controlled by the signals labelled P and E which determine whether the signal outputted at the D terminal is the input from terminal A, or the contents of latch 501 a. When the input signal at terminal A is the K10 parameter, it is stored in latch 501a and the previous contents of latch 501a is output through multiplexer 501b. The output of multiplex gate 501b is coupled to terminal D through a transmission gate controlled by the signal labelled F. INTERPOLATION AS discussed above, multiplier interpolator 50 contains a recirculating shift register formed by vertical contacts between stages. The energy and K1 K10 parameters, which represent the current values, are recirculating through this register, occupying twenty of the possible twenty two time periods. In order to perform interpolation,the current value of any given parameter must be captured and presented in the stage of multiplier interpolator 50 to determine the difference between that current value and the target value being input at the appropriate time. Interpolation must take place when each target value is inputted, and not necessarily when the current value has circulated up to the proper position.The new current value Vn 1 represents the sum of the old current value Vn plus some scale factor N times the difference between the old current value Vn and the target value VT . N, the scale value is some fractional number stored in ROM 78 and utilized during variable interpolation. Thus the interpolation formula may be expressed 1 Van 1 Van n N VTVn The sample of any given current value must therefore be stored until the unused time period which is utilized for interpolation. Each block in the seventh stage of multiplier interpolator 50 has a storage latch 502, wherein the current value is temporarily stored.When a parameter to be interpolated circulates into the seventh stage D block, it passes through multiplex 501b and out through the D terminal, the value i also sampled through the transmission gate controlled by the signal N, and placed in storage latch 502. Storage latch 502 has a two input NOR gate on its recirculation line, the other input of which is the ZPAR signal utilized to zero parameters in specific states discussed above. Thus, the current value of the parameter to be interpolated is temporarily stored in storage latch 502. At the appropriate time period T7 in the embodiment disclosed the control signal labelled G is generated, and the contents of storage latch 502 is output to the D terminal.Therefore, the recirculating shift registers in multiplier interpolator 50 contain the parameters K1 K9 an exchanged value representing K10 or Energy, and the about to be interpolated value of one of the parameters. The value to be interpolated is shifted up to the second stage of multiplier interpolator 50 and, at the same time, the target value for that particular parameter is serially shifted into the first stage. Recoding logic 52 provides a 1 signal to the second stage, which operates on the value to be interpolated, the result of which is then added to the target value, which generates VT Vn, r for output at the output terminal. The third through sixth stage of multiplier interpolator 50 act as an eight by ten bit multiplier during the interpolation time period for multiplying the difference between the target value and the current value VT Vn times the scale value N. The various values for N are stored in ROM 78 and inputted to multiplier interpolator 50 through recoding logic 52, from multiplex 58 and shift register 66 as shown in Figure 2b . The third stage of multiplier iterpolator 50 is different from other stages due to the fact that the sum out of the second stage during interpolation is not merely added to the next calculation. In the interpolation operation, it is required that VT Vn be utilized as the multiplicand in order to be multiplied by scale factor N. Thus, the VT Vn value must be substituted for the multiplicands which are normally inputted on the A terminal from the B terminal above, in the normal recirculating shift register operation described above. In order to accomplish this exchange, each of the C blocks of multiplier interpolator 50, shown in Figure 9c, has a multiplex gate 503, controlled by the signal INT, which operates during the interpolation mode.When a VT Vn value is present in the second stage of multiplier interpolator 50, the INT signal controls gates 503 so that the signal at the E input terminal is selected bb gate 503 and VT Vn is inserted into the recirculating shift register to be utilized as the multiplicand. The VT Vn value is inserted during one of the two unused time periods discussed above and therefore has no effect on the recirculating current parameter values. Since during interpolation, the third stage of multiplier interpolator 50 is utilized as the first stage of an eight by ten bit multiplier, as discussed above, the input on the H terminal must be forced to zero. This is also accomplished by theINT signal coupling Vss into each C block at the H terminal. The VTV value is thus forced into the multipli n cand position, and multiplied by the scale value N. Therefore the output of the sixth multiplier stage is the value N VT Vn . The seventh stage of multiplier interpolator 50 is utilized to add the current value of a parameter to the recently calculated N VT Vn value. As shown in the detail of the D blocks in Figure 9d, at time T18, the normal S input terninal is disabled and the E input is enabled through the bank of transmission gates depicted.T18 also enables a transmission gate which allows the contents of storage latch 502 to be coupled to full adder 504.Thus the output of full adder 504 is the solution to Equation 1 or Vn N NT Vn . The output of full adder 504 is coupled through a transmission gate controlled by the signal labelledI and coupled into storage latch 502. This is necessary since the newly interpolated value is always available atT19, due to the requirement that all interpolation calculations take place during the aforementioned window or open spot which occurs in the recirculating shift register. At the appropriate time, the contents of storage latch 502 is forced back into the recirculating shift register through a transmission gate controlled by the signal labelled G. A special case occurs at the last interpolation prior to achieving the target values or as described earlier herein, the IC O state.To avoid the problems generated by slight errors which may cause the interpolated value to be slightly over or under the target value, a special case is utilized for the last intere iation or interpolation count equal zero state IC C . As in normal interpolation, the current value of a particular parameter is captured and inserted into the interpolation time period in the recirculating shift register. Howe er, rather than being operated upon by the 1 signal from reroding logic 52, the current value is zeroed and then subtracted from the target value. The target value is then circ lated down to the seventh stage of multiplier interpolator 50 where it is input on the A terminal. The signal is then shifted through multiplier 501b in each block of the seventh stage, and inserted into storage latch 502 directly by way of a transmission gate controlled by a signal labelled H.Thus, rather than a newly interpolated value, during the last interpclation the target value itself is inserted into storage latch 502. Again as above, at the appropriate time the contents of storage latch 502 is inserted into the recirculating shift register to replace the old current value.This progress is repeated, and a new parameter is interpolated. A slightly different operation is utilized for interpolation of the pitch value. After a target value for pitch iE input to multiplier interpolator 50, it is circulated don through the recirculating shift register discussed above. Entering the seventh stage at the A terminal, it is passed through multiplex gate 501b and stored in storage latch 502. If the value in storage latch 502 is a pitch value, it is stored in pitch latch 505. Each block of the seventh stage of multiplier interpolator 50 has a latch 505 for storing one bit of the pitch value. The pitch latch 505 is controlled by the signals labelled M and N in Figure 9d.Pitch latch 505 then stores the pitch value until the appropriate time, when the control signal labelled L allows the pitch value to be outputted. The outputs of multiplier interpolator 50 include PITCH 0 PITCH 9, representative of the pitch value stored in the pitch latch formed by gates 505, and MULT O MULT 13 which represents the intermediate products generated during filter operation. As shown in Figure 8b, the least significant bit of the MULT output MULT O is forced to the value of the sign bit MULTSN . This transaction is utilized to prevent the negative drift which normally results from simple truncation of a two s complement number. By forcing the least significant bit to the value of the sign bit, truncation is always toward zero. Those skilled in the art will appreciate that this truncation scheme will help avoid the limit cycle problem. FILTER ADDER Filter adder 54 is shown in Figure 11. The tenth and fourteenth block of filter adder. 54 are shown in detail.Filter adder 54 is utilized to perform the additions and subtractions necessary to solve the equations listed in Table I.There are twenty addtions or subtractions required to implement a ten pole filter, utilizing twenty of the twenty two time periods. During the free time periods, filter adder 54 increments a pitch period counter signal and compares it to the pitch value inputted from multiplier interpolator 50. The pitch period counter PPC is utilized to address periodic or voiced excitation values in ROM 78. When the PPC signal is equal to the pitch value, it is zeroed and begins incrementing again. A more detailed description of the PPC signal operation is listed below. B STACK B stack 56 is a temporary storage facility utilized to temporarily store those intermediate values or b values which are necessary to solve the equations listed in Table I.B stack 56 is shown in detail in Figure 12. B stack 56 also provides temporary storage for the aforementioned PPC signal and the YLATCH signal which represents the output of the filter formed by multiplier interpolator 50 and filter adder 56. The YLATCH output is coupled to the digital to analog converter and is utilized to generate analog signals representative of human voice. The PPC signal is output to multipurpose shift register 66 where it is utilized to address excitation values. FILTER INTERCONNECTS The multipurpose shift register 66 and multiplex 58 are shown in FIGURE 13, and two of the stages are shown in detail therein. Referring to the block diagram ofFigure 2b and the equations of Table I will facilitate an understanding of the interworkings of the filter output circuitry. The MULT outputs from multiplier interpolator 50 represent intermediate products required to solve the equations of Table I. Such products may be a K value times a b value, or a K value times a Y value. Filter adder 56 then adds or subtracts the intermediate product from a Y value or a b value to obtain a Y value or a b value. B stack 56 is utilized to store these b values, since each b value is utilized in filter adder 56 to calculate the next b value.The PPC signal from B stack 56 is input to shift register 66 and output to multiplex 70. Multiplex 70, not shown in detail, utilizes the PPC signal to address voiced excitation values stored in ROM 78. Any conventional address scheme may be utilized. The values stored in ROM 78 represent a chirp function, as in U.S. Patent Application Serial No. 901,393, as it has been found that a chirp function closely models vocal cord excitation Multipurpose shift register 66 also receives the aforementioned excitation values, or scale values addressed by an interpolation count signal from ROM 78 which are multiplexed out as MR signals to recoding logic 52. The scale values stored in ROM 78 are chosen by the operator to generate any desired type of interpolation.As previously discussed, the IC or interpolation count may be any number from one to one hundred twenty seven. The IC count is utilized to address scale factors in ROM 78, thus, in the embodiment disclosed, up to one hundred twenty seven custom scaling values may be stored in ROM 78. A mask programmable option, or programmable type memory will allow easy substitution of scale values or excitation values.Scale values are typically fractional values utilized during interpolation of speech data and may be linearly or nonlinearly related. Another important feature of the excitation signals provided by ROM 78 concerns the capability of scaling unvoiced excitation. In previous speech synthesis systems, such as disclosed in U.S. Patent Application Serial No. 901,393, the unvoiced excitation is characterized as white noise.Such an input may be generated in many ways, such as a constant value with a pseudorandom sign bit. This solution is quite adequate however, the inability to scale the unvoiced excitation to the voiced excitation results in unbalanced excitation signals. ROM 78, in the embodiment disclosed, also stores two unvoiced excitation signals, of approximately equal value, and opposite sign. A random bit is generated by unvoiced address generator 76 and is utilized as one bit in the address of the two aforementioned unvoiced excitation signals.This allows great resolution of the level of the unvoiced excitation, and further, allows the operator to change the level or value to balance excitation signals.Although ROM 78 is disclosed in the present embodiment as a Read Only Memory, those skilled in the art will appreciate that a Random Access Memory will provide an easier method of value changing than the mask programmable method required by a Read Only Memory. An alternate form of excitation is also available through tristate buffer 68, shown in Figure 2b. This gate allows synthesizer 10 to be utilized as a residually excited synthesizer, in a vocoder application for example. Multiplex 58 is utilized two couple the newly calculated b values or Y values to recoding logic 52.Multiplex 58 may also couple excitation values or scale values to recoding logic 52, the former for filter calculations, and the latter for interpolations. The outputs of multiplexer 58 are labelled MRO MR12 and MRSN for sign bit . DIGITAL TO ANALOG CONVERTER The digital to analog converter herein described is particularly well suited to low voltage applications and may be implemented in complementary MIS, such as CMOS, and may be integrated on a comrron semiconductor substrate with the CMOS synthesizer described above. Digital to Analog converter 64 receives the YLATCH output signal from B stack 56 in a nine bit, two s complement notation, and converts the YLATCH signal into an analog signal representative of human speech. A detail description of Digitalto Analog converter 64 is seen in Figures 14a and b. In Figure 14a, there is shown a PLA 641 with inputsYLATCH3, YLATCH4 and YLATCH5. Another input is the signalCLIPP from gate 642. Gate 642 and Gate 643 form a clipping circuit. A nine bit two s complement signal has a range from 256 to 255. It has been demonstrated that the larger values df a speech waveform convey little intelligence and may be clipped without loss of essential intelligence. Gates 642 and 643 examine the two most significant bits of the YLATCH signal YLATCH6 and YLATCH7 and the sign bit YLATCHSN to determine if the absolute value of the incoming value exceeds 64, aCLIPP or CLIPN signal is generated. Shift register 640 is a controllable register triggered off gate 644. Gate 644 generates a leading edge of the time periods T18 through T3 or T7 through T14, when synthesizer 10 is generating speech. Gate 644 may be disabled by the CLIPN signal, thus preventing a pulse from shifting into register 640. Assuming a large negative value is not present, the leading edge propagates down register 640, to an extent controlled by PLA 641. The YLATCH values input to PLA 641 will determine how far down register 640 the pulse propagates. It should be noted that in the event of a large positive value, CLIPP will cause the pulse to propagate to the end of register 640. The output gate 644 is coupled directly to gate 645, as are the complemented outputs of the eight stages of register 640.Therefore, if gate 644 is enabled,gate 645 will act as an OR function, and at point X there will be generated a variable width pulse, ranging from one to eight time periods in length. Additionally, the composite signal comprised of TALK, and T18 through T3 or T7 through T14 is delayed by gates 646 to form TCOMPD4, a delayed signal. The TCONPD4 signal is further delayed to form a signal calledWINDOW. Gates 647 are shown providing the additional half bit of delay however, for additional accuracy, the WINDOW signal may be finely adjusted utilizing high speed clock signals. The WINDOW signal is required to remove the PULGEN, minimum pulse width, when all inputs are zero. The PULGEN signal is required to charge the logics in the programmable delay shown in Figure 14b. In Figure 14b is shown a detailed logic diagram of a three stage programmable delay 648 and the output speaker drive circuitry. The programmable delay shown in Figure 14 has three stages. EAch stage has a positive or P type device and a negative or N type device above and below it. A zero at point X will turn on the P.device in stage 1, the N device in stage two and the P device in stage 3, causing PW to be a logic one or VDD. Thus a positive pulse out of gate 645 Figure 14a will be propagated through programmable delay 648 statically. When the pulse ends, or X goes to a logic one, the P device in stage one shuts off and the N device conducts. Following this, the output of stage one will go toVss, or logic zero, conditionally, based upon the clock gates contained between the P device and N device.The clocked gates in stage one are thus capable of extending the pulsewidth seen at PW. Stage one is clocked to provide either one half of a time period of delay, or no additional delay.Similarly, stage two can provide either one fourth of a time period delay, or no additional delay. Stage three also operates similarly however, a special high speed clock 0800 is utilized to provide a delay of one eighth of a time period.Thus, the output at PW is either zero, when large negative numbers cause gate 644 to be disabled, or a pulse from one to eight and seven eighths time period in length, with one eighth time period resolution. The PW signal is still expressed in two s complement notation, and must therefore be converted to sign magnitude data for negative numbers. Gates 649 and 650 are utilized to generate complementary sign magnitude, pulse width modulated signals. The positive numbers are generated by gate 650 YLATCHSS equal zero with PW and WINDOW, to eliminate the PULGEN pulses. PW is inverted to effectively convert negative numbers YLATCHSN equal one to sign magnitude data through gate 649. The two pulsewidth modulated values SPK1 and SPK2 are then applied to a push pull output circuit 651. Circuit 651 is utilized since it possesses no DC power component, and will effectively drive speaker 18. ALTERNATIVE EMBODIMENTS Although the invention has been described with reference to a specific embodiment, this description is not meant to be construed in a limiting sense. Various modifications of the disclosed embodiment as well as alternative em bodiments of the invention will become apparent to persons skilled in the art upon reference to the description of the invention. It is therefore contemplated that the appended claims will cover any such modifications or embodiments that fall within the true scope of the invention. TABLE IEQUATION STAGEY10 i Y11 i K10b10 i 1 10Y9 i Y10 i K9b9 i 1 9 b10 i b9 i 1 K9Y9 i 9Y8 i Y9 i K8b8 i 1 8 b9 i b8 i 1 K8Y8 i 8Y7 i Y8 i K7b7 i 1 7 b8 i b7 i 1 K7Y7 i 7Y6 i Y7 i K6b6 i 1 6 b7 i b6 i 1 K6Y6 i 6Y5 i Y6 i K5b5 i 1 5 b6 i b5 i 1 K5Y5 i 5Y4 i Y5 i K4b4 i 1 4 b5 i b4 i 1 K4Y4 i 4Y3 i Y4 i K3b3 i 1 3 b4 i b3 i 1 K3Y3 i 3Y2 i Y3 i K2b2 i 1 2 b3 i b2 i 1 K2Y2 i 2 TABLE I cont dEQUATION STAGEY1 i Y2 i K1b1 i 1 1 b2 i b1 i 1 K1Y1 i 1 b1 i Y1 i