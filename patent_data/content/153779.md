# Data processing system provided with a memory access controller

## Claims
Datenverarbeitungsanlage mit einem Prozessor, der mit einem gemeinsamen Adreßbus verbunden ist, einer Speicherhierarchie mit mindestens einem Cache Speicher und einem lokalen Speicher, die mit dem gemeinsamen Bus verbunden sind, und mit einem Speicherzugriffssteuergerät, das mit dem gemeinsamen Bus und über einen Cache Adreßbus mit dem Cache Speicher verbunden ist, wobei das Speicherzugriffssteuergerät folgendes enthält

## Description
The invention relates to a data processing system as is indicated in the preamble of Claim 1 comprising a processor connected to a commun address bus, a memory hierarchy comprising at least a cache memory and a local momary connected to the commun bus, a memory access controller conntected to the commun bus and via a cache address bus to the cache memory, which memory access controller comprises Such a data processing system is known from the European patent application no. 0 052 370. The memory access controller which is part of the known data processing system comprises a cache controller and a translation unit. When an access to the memory hierarchy is requested by the processor, the latter generates a virtual address which indicates the location which has to be accessed in one of the memories of the memory hierarchy. Said virtual address being first presented to the first address input of the first check unit which is part of cache controller. Upon reception of a virtual address, the cache controller checks if the requested data indicated by the received virtual address is present in the cache memory which is connected thereto. This check is realized by the first check unit, which verifies if the received virtual address corresponds to one of the first indicators stored into the first storage unit. In the known cache controller these indicators are formed by the addresses of the data stored in the cache memory. If the received virtual address corresponds to one of the indicators, this implies that the requested data is present in the cache memory, and a first check result signal is generated. Upon receiving a first check result signal the first enabling unit enables the access to the cache memory and the requested data is fetched from the cache memory. But if at the other hand the requested data is not present in the cache memory, a second check result signal is generated. Under control of that second check result signal the virtual address is then supplied via the commun bus to the second address input of the translation unit which is then activated. The second check unit which is part of the translation unit then checks if the requested data is present in the local memory. This check is realized by verifying if the virtual address received corresponds to one of the second indicators. Upon correspondence a third check result signal is generated and supplied to the second enabling unit. Said second enabling unit then enables the translation of the received virtual address into a physical address, which is then presented to the local memory in order to fetch the requested data. If the requested data is not present in the local memory, the second check unit generates a fourth check result signal. A drawback of the known data processing system is that the memory access controller operates sequentially i.e. that first there is ckecked whether or not the requested data is present in the cache memory, and then if the requested data is not present in the cache memory there is checked if it is present in the local memory. In order to check the presence of the requested data in the local memory, the virtual address has to be transferred via the commun bus to the translation unit, thus implying the request of a bus access. Such a bus request and the sequential checking requires execution time during which the processor has to wait, thus reducing his performance. Further the transport of the virtual address over the commun bus will increase the load of the bus. It is an object of the present invention to reduce the memory access timing problem and to nudge the processor closer to its theoretical performance maximum even as to permit the cache controller and the translation unit to operate simultaneously. A data processor according to the invention is therefore characterized in that the cache controller by means of his first address input and the translation unit by means of his second address input being connected in parallel to an address bus which is connected to a virtual address output of the processor, which address bus being provided for transporting the virtual address simultaneously to the cache controller and the translation unit. A first preferred embodiment of a data processing system according to the invention is characterized in that the memory access controller comprises a microcontroller which comprises a bus access signal generator connected to said second check unit and being provided for generating upon receiving the fourth check result signal a bus access signal in order to acquire access to the commun bus, said bus access signal generator being connected to said processor. A second preferred embodiment of a data processing system according to the invention is characterized in that said memory hierarchy further comprises a main memory, and wherein the micro controller comprises a second control input for receiving a bus access right generated by the processor upon reception of a bus access signal, said microcontroller further comprises a mapping unit connected to the address bus and provided for translating virtual addresses into map addresses for addressing the main memory, said microcontroller also ccmprises third enabling means for generating an enable signal in order to access to the main memory. It is favourable that said translation unit being provided with first loading means, having a third control input for receiving said enable signal and being provided for loading data fetched from said main memory into said local memory under control of said enable signal, and for loading a second indicator into said second storage unit which indicates the data loaded into the local memory. Thus there is realized that the data fetched from the main memory is present in the local memory for a further requests. It is favourable that said first check unit and said first storage unit being formed by a content addressable memory which is connected to the address bus. It is favourable that said second check unit and said second storage unit being formed by a content addressable memory which is connected to the address bus. A third preferred embodiment of a data processing system according to the invention is characterized in that said memory hierarchy further comprises a main memory, said main memory being partitioned into a first number of sectors and said cache memory being partitioned into a second number of sectors, said virtual address comprising a first field indicating a sector number of a sector in said cache memory, said first checking unit being provided for fetching said first field out of said virtual address and for realizing said checking upon the content of said first field. This enables a fast execution of the checking because only a few bits, namely those of the first field have to be checked. Further the partitioning in sectors is also advantageous in that the cache memory can be loaded sector wise so that all data which belongs to one sector is present in the cache memory. It is favourable that said sectors of the main memory and the cache memory being partitioned into a third respectively a fourth number of blocks, said virtual address comprising a second field indicating a block number of a block in said cache memory, said first storage unit comprises a presence bit memory for the storage of presence bits indicating the blocks present in the cache memory, said first checking unit being provided for fetching said second field out of said virtual address and for realizing said checking by controlling if the presence bit of the block number indicated in said field is set in said presence bit memory. It is favourable that said second loading means being provided for loading said data block wise into said cache memory and for setting the presence bit for the loaded block into said presence bit memory. A fourth preferred embodiment of a data processing system according to the invention is characterized in that the memory access controller comprises register means connected to said address bus for partitioning the virtual address space occupied by the virtual addresses into a number of different regions and for providing a region number to each region obtained, said register means having a set input for enabling a programmable length of the regions to be partitioned, said register means being provided for realizing said partitioning upon the address bits of virtual addresses. A fifth preferred embodiment of a data processing system according to the invention is characterized in that said local memory being partitionable into a variable number of segments, each of the segments being partitionable into fixed length pages, said virtual address comprising a segment number for indicating the number of a segment and a page number field for indicating the number of a page within a segment indicated by the segment number field, said memory access controller further comprising a segment table pointer register for storing descriptors of the segments present in the local memory, each of said descriptors comprising a segment table pointer for indicating a segment table of the local memory. It is favourable that said register means comprises for each region partitioned a register pair, said register pair comprises a segment table pointer register for storing references about the areas of the virtual address space accessible to a current process, and a segment table length register for indicating the length of the segment. The use of a segment table pointer register and a segment table length register permits a flexible and efficient method for using the region concept and identifying the regions. It is favourable that said mapping unit has a first input connected to said register means for receiving region numbers and a second input connected to said segment table pointer register for receiving segment table pointer indications indicating the segment table for said region number in the local memory, said mapping unit being provided for generating a physical address by using the segment number field of the virtual address as an index for indicating a position in said segment table and by using the page number field as an index for indicating a position in a page table register indicated by the indexed position in said segment table. It is favourable that said descriptors comprise a protection field for indicating whether or not the access to the segment indexed by the descriptor is protected. It is favourable that segment table pointer register comprises a location for storing a protection indication in order to indicate whether or not the access to the indexed region is protected. Thus protection is easily realized on region basis. It is favourable that said descriptors comprise a non cacheable bit for prohibiting if setted that a segment is loaded into the cache memory. A sixth preferred embodiment of a data processing system according to the invention is characterized in that the memory access controller is connected to an I O unit by means of the address bus, said memory access controller comprises a further mapping unit for mapping a received virtual address into a physical address for the I O unit. This offers the possibility to use virtual addresses for I O operations. Embodiments of the invention will now be described, by way of example, with reference to the accompanying drawings, in which Figure 1A shows a block diagram of a first embodiment of a data processing system using a single Memory Access Controller hereafter to be called MAC according to the invention. The MAC 1 is placed between the processor 2 and the memory device which in this embodiment is formed by a cache memory 3 and two memory modules 6 and 7. The cache memory is directly connected to the MAC. The memory modules are connected to the processor and the MAC via a data bus 4 and an address bus 5 , to which also I O modules 8, 9 are connected. The MAC handles all the processor requests to memory device and completely controls the cache memory. This is a fairly straightforward solution, as all the DMA Direct Memory Access requests to the I O modules use real addresses. While this is fairly straightforward for the hardware, the software has to arrange that blocks which have to be DMA d into memory fit into consecutive real addresses, unless the DMA units can handle a scattered real memory. Figure 1B shows a block diagram of a second embodiment of a data processing system using a single MAC. For the same components, the same reference numbers are used. In this second embodiment the request to the I O modules uses virtual addresses. This is much easier for the software to handle, but the address and data bus onto which the I O modules hang are the address bus 10 and data bus 11 between the processor and the MAC. This is a favourable solution for a data processing system with limited modularity. Figure 1C shows a block diagram of a third embodiment of a data processing system wherein several MAC s according to the invention are used. In this third embodiment there are three units A, B and C each comprising a MAC 1 A, 1 B, 1 C , a cache memory 3 A, 3 B, 3 C and a processor 2 A, 2 B, 2 C . Those three units are each connected to the data bus 4 and the address bus 5 of the data processing system. This embodiment will allow up to several MAC to work without seriously disturbing one another. Note that although this embodiment shows processors each with their own MAC, these processors could just as easily be I O units with DMA properties. Figure 1D shows a block diagram of a fourth embodiment of a data processing system wherein two MAC s according to the invention are used and wherein each unit A, B contains a local memory 12 A, 12 B . Embodiments like this can be used if there is a way to partition the application. This can be done in many ways depending upon the complexity of the data processing system and the software. Some applications can be partitioned statically, e.g. a process control system where the task can be pre assigned to a processor. In this case, the local memory can be used for code and to process specific data, e.g. stacks. Of course, applications that are re assigned dynamically can also be processed using this embodiment. The MAC provides facilities to page in and out of local memories. It monitors which page is where and interrupts when a processor requires access to a page which is marked as local and yet is not marked as being in that particular unit s local memory. Figure 1E shows a block diagram of a fifth embodiment of a data processing system where two MAC s attached to one processor are used. The two MAC s 1 A and 1 B are attached to the data bus 4 and the address bus 5. Each MAC has its own cache memory 3 A, 3 B . In some special cases there may be a need to attach more than one MAC to a processor. Normally this should not be necessary as the cache hit rate should be high enough 90 and the descriptor cache hit rate should be better than 99.5 . However if this is not enough or if a fast response is wanted for interrupts then multiple MAC s can be used. The hit rate indicates how often a memory access is satisfied from the cache memory rather than the main memory for example comprising the memory modules . The higher the hit rate, the closer the processor comes to ideal performance. After considering different possibilities of applying one or more MAC s to a data processing system the set up and the operation of a MAC according to the invention will now be described. Figure 2 shows a detailed set up of how the MAC is implemented into a data processing system. Four groups of connections have to be distinguished. A first group of connections of the MAC enables the interface between the microprocessor 2 and the MAC1. This first group of connections comprises a first address bus 32 which is connected to the MAC1, the microprocessor 2, the cache memory 3 and the address bus interface 38. This first address bus 32 enables the transport of the physical addres part for an address of a memory location to be accessed. Said first group also comprises a second address bus 35 connected between an address output of the microprocessor and an address input of the MAC. The second address bus applies virtual address parts generated by the microprocessor to the MAC. To the second address bus there is also connected a decoder 30 which decodes the presence of a virtual address on the second address bus and thereupon generates a chip select CS signal which is applied to the CS input of the MAC. A second group of connections comes into play when a memory request can be satisfied from the cache memory 3. This second group comprises a cache address bus 36 connected between a cache address output of the MAC and an address input of the cache memory 3. This cache address bus transports the cache addresses generated by the MAC upon a received virtual address. A third connection line 34 is connected between the MAC and the cache control 31. Upon receiving, via said third connection line, a control signal such as for example a cache enable signal or a cache write enable signal, generated by the MAC, the cache control 31, which is connected to the cache memory 3, enables that cache memory for the requested access. A third group of connections comes into play when a memory request can not be satisfied from the cache memory. This third group comprises a second address bus 41, connected between an address output of the MAC for physical addresses and the address bus interface 38. This second address bus transports the physical address generated by the MAC upon a received virtual address. The physical address is then used to address a location in the memory module. A fourth group of connections comes into play in addition to delivering the requested data from the memory module. The MAC then fills a cache slot from the cache memory with blocks of data from the memory module, which required a series of read operations. Via a sixth connection line 42 the MAC sends a Physical Address Latch Enbale PALE signal and a Load Address Clear signal LACLR to the cache memory in order to clear a slot in the cache memory indicated by the physical address generated by the MAC and thereafter load at that physical address the data originated from the memory module. Figure 3 shows the architecture of a memory access controller according to the invention. The MAC contains three main substems, namely a cache controller 50, a translation look aside buffer 51 and a microcontroller 52. The cache controller provides all the matching and control logic needed to communicate with the cache memory. The translation look aside buffer is provided to translate a virtual address presented by the second address bus 35 into its physical counterpart in the local or main memory. These two sub systems in particular help the overall system performance. They allow write operations to overlap with a subsequent read operation and permit memory management and cache operations to overlap a subsequent read operation and permit memory management and cache operations to overlap as well. The micro controller subsystem performs several tasks, among them updating the translation look aside buffer. The cache controller and the translation look aside buffer are both connected to the second address bus 35 which carries the high order virtual addresses generated by the microprocessor. The microcontroller is connected to that second address bus 35, to the cache address bus 36 and to the address bus 41. The control signals DTACK and DS are applied via communication line 44 to the microcontroller. The operation of the MAC will now be described on the hand of the flow chart illustrated in Figure 4. When the MAC receives 70 a virtual address generated by the microprocessor, this virtual address is transmitted via the second address bus 35 in parallel to the cache controller 50 and to the translation look aside buffer 51. Upon receiving a virtual address the cache controller will check 71 if this address is present in the cache memory. Therefore the supplied virtual address is inputted into a content addressable memory 53 which is part of the cache controller. The operation of a content addressable memory is for example described in the French Patent Application No. 24 12 140 . On the other hand, if the translation look aside buffer does not contain 77N the received virtual address it is not able to execute the virtual to physical adress map, and is must get that map to complete the access. To do this after enable check 76Y the microcontroller of the MAC asserts 82 its halt signal and a bus error signal to acquire use of the system bus from the processor. The microcontroller of the MAC then translates 83 the received virtual address into a physical address and applies this physical address to the second address bus 41 upon receiving access from the microprocessor to that second bus. Then the microcontroller fetches 84 the necessary mapping information from the system memory and loads it into the translation look aside buffer. With the mapping information on hand, the microcontroller gives up the bus to the microprocessor, which once more requests 85 the previous virtual address from the MAC. Again there is checked 86 by the translation look aside buffer if the requested data is available and if virtual to physical address translation is possible. If the requested data is present 86Y and translation is possible the requested data is transferred to the microprocessor 87. However it is possible that the requested data is not present and that no virtual to physical address translation is possible 86N for example because the requested data is only on a disk. In that case an interrupt is sended 88 by the microcontroller to the microprocessor and the later is forced to enter the operating system s memory management routine. This routine transfers 89 the requested data from the disk into the RAM of microprocessor and, if necessary moves blocks of data from that RAM to the disk in order to make space. The need for a cache memory stems from the fact that processors are inherently faster than memories, a mismatch that keeps a microprocessor from running as fast as it otherwise might. By creating a hierarchy of memories, however, a designer can minimize the time a processor spends waiting and thus nudge it closer to its theoretical performance maximum. The microprocessor and the MAC together support a hierarchy of five levels of memory i.e. The different levels of that hierarchy will now be considered in more detail. The registers on the MAC are used for five purposes The MAC will issue a bus error signal BERR if any access to a register is made without using a supervisor function code. Registers on the MAC can be accessed by the microprocessor when the chip select CS input is active. The register addresses are then decoded from address signal supplied via the second address bus 35, Figure 2 . The MAC comprises a variety of registers which will be given hereunder. These registers define the hardware configuration of the system. Essentially they describe parameters such for example the cache size and page length. This register has a capacity for storing for example 8 bits. The first five bits of this register are used to indicate the page size of the pages stored in the main memory. One of the remaining bits is used to indicate that a check will be made on pages which are in a segment of the main memory which is marked as local to see if the page is in the required local memory. This register, which is reset to zero on a MAC reset, defines the part of the address that selects a segment. The contents of the SSR is the encoded number of address bits, that are part of the segment number. This register specifies the cache memory organization. This register is used in order to indicate the presence or absence of a cache memory. These registers are used to divide the virtual address space into different regions. This register establishes which regions are active and defines the region attributes. When an access is attempted to a region for which the enable bit is not set, a BERR will be generated. This register defines the boundaries of the regions in which the virtual address space is divided. These registers contain pointers and length information to be used by the MAC, and define the location and length of the current segment table. These registers contain the address of the segment tables currently valid. When it is loaded, all the mappings in the MAC in the relevant region are reset i.e. the cache memory appears empty of all addresses in the region and all page descriptors in the MAC in the regions address space are invalidated. These registers contain the length i.e. the number of segments of the segment tables currently valid. This register contains the physical address of the MAC stack in memory. The pointer points to the beginning of the page containing the stack. In a multi processor system with local memory, the processor has to identify itself to the MAC so that the latter can check whether a local page is in the required local memory. This is done through the Processor Identification register. A write to this register will cause the MAC to execute the Translate command. These registers are used to set the interrupt vector so that the MAC can interrupt the processor. They are also used to provide information about the interrupt back to the processor. This memory element contains a copy of program and data which are in the memory. It is completely controlled by the MAC and is transparent to the software. The cache is a small, fast memory that allows the processor to see the cache access time instead of the usual system memory access time for 90 of its accesses and reduces the bus usage by 85 . The associated principle of the cache memory works because most words of local or main memory memory are accessed more than once within a relatively short time interval. The MAC automatically stores each word read by the processor in the cache memory and, if the processor tries to read that word a second time, the MAC provides the word from the cache memory instead of accessing the main memory. When the processor writes a word the MAC implements a write through policy i.e. the word is written into both the cache memory and the memory. If a segment is marked as local then this refers to the local memory and not the main memory. If the bus is not available to the processor, the MAC allows the processor to proceed, and if the bus is granted before the next cache miss or before the next write, the processor need not be aware that there was a bus access latency time. Under some conditions, i.e. when two processors are sharing access to a common segment of memory interleaved in time, it may not be desirable to cache the data. Segments can be marked as non cacheable. Although many types of cache implementations can be thought of, there are three main types which are briefly discussed. These are These are the normal caches as used in many mini and mid range computers. Associated with each cached item is a tag identifying the upper address bits. These tag bits are compared against the high order address bits of the word being sought. If they match and a presence bit is set, then a hit is recorded. Associative caches are similar to tagged caches in that they have an identifier attached to each cache word. They differ from tagged caches in that the identifier is a content addressable memory CAM which holds the high order bits of the address. Semi associative caches are an attempt to temper the idea of an associative cache with a dose of reality. Basically a semi associative cache adds one assumption to the idea of associative caches. The assumption is that there is a working set of memory locations which in fact is reasonably small and tends to cluster, on a medium time grain, around some points. In a semi associative cache the cache itself is divided into a number of sub caches. This number is called the set size. These sub caches are defined by the high order address bits as shown by the following example Take an address n bits in length. This divided into three areas In other words an address looks like The label field defines a sub address space of 2 Local memories can be attached to each processor in a multiprocessor system. The MAC provides facilities to control the movement of code and data in and out these local memories. This feature is transparent to the user software. This is the main memory accessible to all parts of the system. A demand paged virtual memory system can be implemented with one or more MAC s. The MAC makes a multiprocessor system practical by reducing bus utilization as a MAC can be attached to each processor. The MAC provides facilities for allowing DMA units to use either real or virtual addresses. In the latter case all control units which are virtual addresses must be connected to a MAC. Thus tlne MAC provides all the necessary memory access and control to allow true demand paged virtual memory systems to be built. This part of the memory requires a long access time and is provided in a well known matter of a magnetic or optical disk. The disk constitutes the background memory of the system. Now that memory hierarchy has been described, the realization of the MAC can be explained more in detail. The cache technique employed by the MAC is called sector associative. In this scheme as is illustrated in Figure 5, the main memory is partitioned into n equalsized sectors, and the cache memory is partitioned into a number of sector sized slots, for example 32 sector sized slots. Thus any main memory sector can occupy one of these 32 slots. However, since there are too many main memory sectors to fit each one into its own cache slot, the MAC employs a mapping procedure using a 32 position content addressable memory CAM 101 to identify those sectors in the cache memory. The procedure for checking if a particular sector is present in the cache memory is described on the hand of Figure 5 and the flow chart illustrated in Figure 6. Although sectors are naturally large and filling a 32 k byte cache memory one sector at a time is not all practical. For that reason sectors are partitioned into blocks made up by 2, 4, 8 or 16 bytes. To address a block, the virtual address contains a block field. However, because not every block in a sector is necessarily in the cache, a presence bit is needed to say whether or not the address block is there. That presence bit is stored in the presence bit memory 102 which is connected to the CAM 101. The MAC then verifies 112 if the sector field is present in one of the CAM s 101 positions. If that sector field is present Y then a cache hit occurs 113 , if not a miss occurs 120 . If that sector field is present, the MAC verifies 114 if the particular block within that sector is present. This verification is realized on the basis of the presence bit, and it is necessary because not every block in the sector is necessarily in the cache memory. If the requested block is present Y , it is fetched 115 from the cache memory, if not N a block miss occurs 116 . When a block miss has occurred, the MAC will access 117 the main memory in order to fetch the requested data block. The requested data block is then transferred 118 from the main memory to the microprocessor even as to the cache memory. After storage of that data block in the cache memory, the MAC sets 119 a presence bit in the presence bit memory 102 . Returning now to step 120 where a miss occurred due to the absence of a sector in the cache memory, the MAC will then access 121 the main memory and transfer 122 the requested sector to the processor and the cache memory. Thereafter the sector address is loaded 123 in the CAM. The advantage of sector associative cache memory used with the MAC is that due to the check as well on sector basis as on block basis, the cache memory is only accessed when the MAC has established the presence of the requested data in the cache memory. It is thus not necessary to access the cache to check whether the requested data is present, this is done by the MAC and thus access time is saved. In case that a semi associative cache memory is used the basic algorithm executed by the MAC to see of a requested word is present in the cache memory is given hereunder. Note that this replacement algorithm is essentially a FIFO mechanism. Simulations have shown that, with a working set the size of the MAC s, there is no real performance difference between a FIFO and a LRU replacement algorithm. Besides its ability of controlling a cache memory, the MAC also acts as a memory management unit and offers a large, linear virtual address space. There are three methods of subdividing the virtual memory space managed by the MAC, i.e. The first method segmentation is illustrated in Figure 7 a . This first method divides the virtual address space 100 into segments that are continuous in memory and allocated in multiples of a page size. A virtual address is then composed of a segment number SN , a page number PN and an offset OFFS . When segmentation is used, the MAC is always provided with a segment table pointer register wherein descriptors of the most recently accessed pages are stored. Those descriptors contain inter alia the segment table pointer STP , the page or segment page length even as some other status information such as for example its associated subdivisions, access rights, its ability to be cached, whether it has been written to since cache, and other information. The segment table pointer register is loaded upon reception of the CS signal by the MAC. The second method, called paging, is illustrated in Figure 7 b . In this method the virtual address space 100 is divided into pages of fixed sizes, with each page configured to be for example 1, 2, 4 or 8 k byts long. The virtual address comprises a page number PN and an offset OFFS . In Figure 7 b there is also illustrated a second level page table SPT . This is usefull in order that it permits to divide the page number given by the virtual address into two parts. The first part then indicates a location in the page table PT . At this location there is stored an indication to the second level page table. The second part of the page number given in the virtual address is then used to access a location in the second level page table. This implementation offers a greater flexibility for forming the physical address. The advantage of paging is that the pages have a fixed length which implies that when a page is removed and replaced by another one, the accessible memory space will again be completely occupied. The third method, called segmentation with paging, is illustrated in Figure 7 c . In this method the virtual address space 100 is divided into segments, but unlike the first method, the segments are not contiguous. Instead the pages can be scattered throughout the memory. This method thus combined the advantages of the first and the second method. The descriptor indicates the segment table ST of the main memory, while the segment number SN of the virtual address indicates a location in that segment table. At this location there is an indication to the page table PT wherein a location is indicated by the page number PN of the virtual address. The physical address is then generated by adding the offset to the page basis as given by the page table. The problem can occur that the virtual address space is rather large and thus difficult to handle. This problem could in particular rise when there is a need for a change in a running process or when two processors using the same MAC execute different processes. In this case it should be necessary if no additional means where provided to update the segment table pointer register, thus loosing their actual content. For example suppose that during the execution of a process it is necessary to have a picture displayed. For the execution of that process there are stored in the local memory the required code and data and the descriptors loaded in the segment table pointer registers indicate the segment table of that particular process. But the need for displaying that picture will require that another part of the memory needs to be accessed and thus other descriptors to be loaded in the segment table pointer register. This on his turn implies that when the process will be further executed it is necessary to reload the descriptors for that program. In order to solve this problem, the MAC can partition a processor s virtual address space into four different regions. The four regions are defined sequentially starting from the bottom end of the virtual address space. The upper limit of each region is specified in turn. This implicilty defines the lower limit of the next region. Thus if only one region is to be specified, then its upper limit is given as FFFFFFFFF. The four regions are all equivalent. Despite their separation, the contents of separate regions can still interact through entry points, which is a usefull feature for sharing a library of function subroutines. In fact, a small program can increase its size several times when linked with library sub routines. The MAC determines the region number from the most significant bits of the applied virtual address. In addition, to support the four regions, the MAC is provided with four register pairs, each pair consisting of a segment table pointer register STPR and a segment table length register STLR . Each region also has an associated segment table or first level page table see Figure 7 c . The segment table defines which areas of the virtual address space are accessible to the current process. The definition of a current region is achieved by re setting these registers on the MAC. If a reference is made to a region whose enable bit is reset, a bus error signal BERR is generated. Region definition and enabling is done via a set of dedicated registers. This offers the possibility of programming the length of the regions. The system designer may use only one or as many pieces as desired over a maximum of four regions. For example, a two region system might have 12 pieces in region 0 and 20 pieces in region 1. A simple system is defined as having only one region which is accessible by all function codes. Thus protection is performed by the protection bits associated with each segment. This system is configured by writing FFFFFFFF into all Region Definition Registers, thus defining the upper boundery of R0 to be FFFFFFFF and the lower boundary of R0 to be 00000000. Nothing further has to be done. The system can be used as if it had only one region which stretches uniformly from 0 to FFFFFFFF. An example of how all four regions can be used in the implementation of an efficient operating systems which protects users from one another and from itself will now be described on the hand of Figure 8. Suppose the system memory SM comprises four different areas i.e. an operating system area OS , a system library area SL , an area for the code and data for a process A A and an area for the code and data for a process B B . For a process A PRC A and a process B PRC B executed by one or two microprocessors the virtual address space is divided into four regions. Region R0 is used only by the privileged part of the operating system OS and contains the part of the kernel which is privileged. Thus, all segments in this region are marked with an indication that supervisor permission is needed to access them. This part of the operating system should be as small as possible, as it has access to all of memory. The next region, R1, is used by the supervisor. This is the part of the operating system that provides the non privileged functions. This code is nevertheless trusted code and can have access to resources that are not available to user programs. While running user code this region is normally disabled. There are often a large body of utilities in a system which is used by most programs. If the data which they access is protected, then there is no reason why these utilities can not automatically be made available to all users in an execute only mode. Thus, R2 is used as a system library SL , available to all processes and always enabled. The last region, R3, is the user region. This region contains the process specific code and data PRC D . The mapping of this virtual address space into an associated physical address differs from process to process. This re mapping is performed by chaning registers in the MAC. The MAC is quite flexible in the range of virtual memory systems that it can support. Some systems may have a large number of large sized segment and page tables. In such systems the tables for user task regions may reside in virtual memory, in which case address translation for the table pointers needs to be done in order to access those tables. All table pointers should belong to a region where the translation tables themselves are in main memory. This is necessary because otherwise these tables could not be accessed and no address translation could be done. So it is possible to distinguish so called regions in which all tables reside in physical memory, from task regions where the segment and page tables are in virtual memory. When the MAC can not find a virtual address in its cache or its translation look aside buffer, it uses the registers to search the main memory descriptor tables. When regions are used, the MAC first determines the region number on the basis of the received virtual address and then accesses the segment table pointer register of that region s associated segment table. In case of a paged segment Figure 7 c , the region s segment table length register determines the size of the segment. Then, using the segment field number from the virtual address as an index, the MAC accesses the segment table that is referenced by the segment table pointer register. In turn, the accessed segment descriptor contains the associated page table pointer and page length. The MAC then uses the page number field of the virtual address as an index into the page table to find the physical page basis address. It computs the physical address by linking the physical page frame address with the offset field of the virtual address. As already described the MAC uses a memory which can be divided into regions and which regions can be divided into variable length segments. Those segments in turn are divided into fixed length pages. This division now enables to provide protection on segment basis which protection has the following attributes These attributes are recognized and protected dynamically by the hardware of the MAC, for example by means of gates or flip flops. If a user attempts to access a segment for which he has no permission, a bus error BERR signal is generated. If a very sophisticated protection scheme is needed, this can easily be accomplished without any appreciable performance loss using simple software. Each segment has associated with it a software protection bit. If the software protected bit is set, the BERR will be asserted when the segment is first executed. Thus it is simple to add a domain field to a segment descriptor to ensure that certain subroutines can only be called through access gates which provide additional access permission checks. Alternatively, the entries in a process s segment table can be used to restrict its address space to those entities for which is legitimately needs access. Aside from these protection attributes, the MAC supports three additional attributes which are used to control the memory hierarchy. These attributes are This attribute forces associated segments to never be cached. It forces segments which are shared between processes to have only one copy which is always up to date. If the system has local memory then this attribute is used to force the associated page into the memory local to the processor and save bus accesses. This attribute if set indicates a segment that has no page table associated with it. Such segments are to be loaded and relocated in memory as a whole. The MAC is also provided for enabling protection at region level. Figure 9 shows an example of the format of a 32 bits segment descriptors in the Segment Table for a paged non contiguous segment. Figure 10 shows an example of the format of the contiguous segments descriptors. This field contains the pointer to the page table which defines the current segment. Page tables must be aligned on long word boundaries in memory. This field contains the length of the segment in pages. Each use of a segment is protected differently depending on the permission granted to each process. This field contains the bits which define the status of the segment. These fields comprise for example 9 bits which have the following signification bit 1 Supervisor Permission S needed to access this segment. bits 2 4 Access Permission Bits. The three access permission bits allow the access mode if set. These bits are This bit is used to indicate whether the segment is valid or not. If this bit is set, a trap will be generated the first time the associated segment is accessed. Subsequent accesses to the segment may or may not generate a trap. Thus, the trap handling software should either reset this bit after the first interrupt, or should be capable of handling multiple traps. This bit is meant to provide a software filter for entry into segments. The final three bits define how the segment can be mapped. These are If the associated segment comprises semaphores or could be used by two processors or I O units concurrently it should be so marked. This indicates that the segment is stored in one or more memories local to the processor. This bit indicates that the segment has no page table. It is a segment only and should be mapped into memory as a whole. The MAC also enables protection at the level of the page table. Figure 11 shows an example of the format of a 32 bits page descriptor in the Page Table memory. It may be desirable to place most of the system tables mentioned above in virtual memory without necessarily having them in physical memory all the time. The MAC clearly allow multiple page faults while fielding a cache fault, i.e. if the MAC needs a descriptor and finds that the descriptor itself is not present in the physical memory then it will generate a BERR giving the address of the descriptor as well as the cause of the access fault. Thus, the only tables that need to be always present in the physical memory are those of the interrupt handling routines and the memory management routines i.e. the tables containing pointers to the segment and page tables . It should be noted that a page fault does not indicate any error condition rather it indicates that an action is needed. However, a page error indicates that an error has occurred either an access was made to a segment for which the requisite permissions were not held or that an access was made to an invalid segment. The MAC provides mechanisms for implementing systems with varying degrees of protection. The simplest protected system would only separate user code form OS code. Protection is basically provided by only giving a process access to the resources it needs. These resources include memory and I O. Access to I O is accomplished by giving a process access to the necessary I O management routines. This access can be execute only and the entrance to these routines can be controlled via hardware in the normal manner or by putting a software gateway as the access point. This gateway is essentially an execute only segment which can be marked so as to cause a trap when entered. Thus, a trusted program can be used to do the I O access or to provide extra entry points to the calling program. For example, if a file is opened then this technique can add segments to the calling process s virtual address space, where each segment performs an I O function. The process will only have access to these routines. Naturally, this process will only be effective if a process is forbidden to access its segment descriptors. This is achieved by not putting the segment tables belonging to a process in a segment directly accessible to the process. Naturally this segment is accessible to the operating system and the MAC. Sharing of code and data can be accomplished by merely putting a segment descriptor pointing to the same page table in more than one process s segment table. Note that these segments can have different virtual addresses for the different processes. Message passing can then be easily and efficiently implemented by asking the operating system to add a descriptor to another process s address space. The MAC can be used as a MMU Memory Management Unit either with or without using the cache controller function. If a simple system is desired, a sub set of the MAC s possibilities can be used. The following are some examples of possible system configurations Clearly, more examples can be generated. These are only provided to emphasize that all the facilities need not always be used. Now that the concept of regions and protection facilities has been introduced, and that the general architecture of the MAC has been described, more details about the operation of the MAC will be given hereunder. As already mentioned, the MAC comprises a cache controller and a translation look aside buffer Figure 3 . The cache controller manages a semi associative cache. It has a working set of for example 32 subcaches. These subcaches are defined not only by the address, but also implicitly by the address space. The MAC recognizes four address spaces defined by the four regions. The distinction between the regions, in the cache controller, is made purely to allow the cache entries belonging to the separate address spaces to be invalidated for a region as a whole. If a systems dynamic working set is favourable, this will allow interrupt service routines, for instance, to remain in the cache while the processor continues a process or even changes processes. On the reset, the cache is marked as empty and all 32 sub caches are available to all four regions. All sub caches which are in use by a region are automatically marked as empty whenever that region s Segment Table Pointer Register STPR is loaded. A word can only get into the cache if it has satisfied the criteria of the segment descriptor. Thus, when a word is read and it is found in the cache, it is valid if the processor has the necessary permissions. A copy of the segment permission rights is kept with the associated subcache. If a write is performed, then this is only written into the cache if the processor has write permission. The dirty bit in the MMU section of the MAC and the page table is updated. When a write is accomplished the information is written to the memory. Only when a subcache is already allocated for this data, is the information also written to the cache memory. If the width of the data to be written is the same as the cache width, then the relevant block presence bit is marked as valid. If the width of the write datum is not the same as the cache block width, then the presence bit is left unchanged. On a write the MAC will strobe the address and data into latches and start a memory write cycle. Before doing so it will check if it has the required descriptor if not it will fetch it from memory. If it is not already set, the MAC will also set the dirty bit in both the page table in memory and the page descriptor cache on the MAC. Then it will allow the processor to proceed the asserting the DTACK signal to the processor while the memory transfer is taking place. The processor will be allowed to proceed unless it requests another memory transfer either a cache read miss or a write before the first write is conplete. In terms of bytes the cache can then vary from a minimum of 2 K bytes, 1 K blocks of 2 bytes, to 64 K bytes, 4 K blocks of 16 bytes. Although, in general, a cache of 1024 blocks of 4 words, i.e. 1 K x 64, will result in the processor seeing a cache access time for at least 95 of the memory accesses. For example, if a cache hit or an overlapped write occur fast enough not to cause any wait states in the processor and a memory access results in 4 wait states then the average number of wait states per memory access is 0.2. The translation look aside buffer performs paging control between three levels of memory. These three levels are In a multiprocessor situation it may be desirable, in order to reduce bus traffic, to attach a local memory to each or some of the processors. If so, the MAC is capable of providing signals to the processor if the segment is marked as belonging to local memory. A page fault trap will be generated if the accessed page is not present in the local memory. Thus the MAC can not only control paging between the system memory and the background memory but also between local memories and the system memory or background memory. The translation look aside buffer TLB of the MAC contains descriptors for pages, for example 32,which are loaded on demand by the MAC. As in the cache, each page is identified only by its logical address. In addition the TLB contains four register triplets. These consists of a Region Definition Register RDR , a Segment Table Pointer Register STPR and a Segment Table Length Register STLR . Each of these triplets define the current context of their respective regions. The page descriptors are in a fully associative descriptor cache on the MAC. Each descriptor consists of the following fields If a word is read and it is not in the cache memory, then the TLB is accessed to find its physical address. If the relevant page descriptor is not in the TLB then the MAC will use the region STPR to find it. This will be used together with the length established in the STLR register. Only if the page is not present in memory will a page fault be generated by asserting BERR. During the process of fetching the segment descriptor the MAC checks to see whether the segment number is valid, i.e. it is less than the length set in the register for the address space, relative to the lower region boundary. It also checks to see that the page number is not greater than the maximum page number in the segment descriptor. If either of these conditions is violated than a fault notification is generated. If the segment is marked as local and this check is enabled, then the page descriptor will be checked to see if the page is in the requesting processor s local memory. If the used bit is not set in the page descriptor in memory, then it is set by the MAC. If any permitted write is made to a page and the dirty bit in the page descriptor in the cache is not set, then it is set both in the descriptor cache and in the memory. If an access is made to a memory location for which the required permission bits are not set then the BERR is set. The offending address and the reason are stored on the MAC stack in memory. If an access to a non resident page is made, the same procedure will be followed. This will be done wheter the page at fault was the desired page or a page containing either the segment table or the page table. Part of the communication between the MAC and the controlling processor is done via the MAC stack in main memory. Each MAC in a system must have such a stack, occupying a given number or bytes for example the first 512 of one page that should always be present in memory. The MSPR register on the MAC stores the physical address of the page frame in memory containing the stack. This stack is used in the following way When an error or a page fault is detected by the MAC during its operation, an error report containing the address causing the error as well as a description of the problem is stored in the stack by the MAC. The MAC then generates an BERR to the processor. The 512 byte stack is divided in 8 sections which are indexed by the function code signals. Index 000 indicates the section for the processor, the remaining seven sections are for I O devices. The processor section is used to store the faulting address and the error cause in case of an error or page fault on an attempted memory access by the processor. This section also contains the virtual and real addresses used in the address translation command. The other seven sections are each divided into 8 blocks. Each of those 8 byte blocks can contain an error report consisting of the faulting address plus a description of the problem. A written bit in each of those blocks is set whenever the MAC writes an error report in that block. This bit then indicates that the block contains an error report to be serviced by the processor and it can be reset by the processor only after it has handled the error. The MAC will write an error report in a block only when the written bit is not set. An extension of the capacity for computing the physical addresses for the processes in main memory is the MAC s ability to use virtual addresses for I O operations, creating a virtual I O. This ability is particularly important for paged virtual memory, where logically contiguous pages may not occur in consecutive locations. Without virtual I O, disk operations, for one thing, would require complicated computations in software to read and write data that is across scattered pages. However, the controller solves this problem by allowing a DMA controller for example, the disk controller to use virtual memory. The I O unit indicates with a function code bit that is performing an I O rather than a processor memory reference. When that function code bit indicates that an address is an I O reference, all protection checking is suspended and the remaining function code bits indicate which particular I O controller is involved. This indication is necessary, since the controller must report any errors caused by illegal accesses by an I O unit, and those remaining function code bits identify the offending unit. Because multiple I O errors can occur before the processor can investigate the reason, a single error register in the MAC is not enough. Instead, a communication area in main memory, indexed by the I O address, is dedicated to writing I O error messages the portion of memory indexed by device 0 is reserved for the processor . When an error occurs, the controller writes an error message into the appropriate memory area. There the most significant bit of an error message field indicates whether a valid error messages exists. The field also indicates the memory region and address at which the error occurred, as well as an error message number to identify the cause. Also, the MAC aborts the transfer with a BERR signal to the peripheral. When an I O controller receives the abort, it interrupts the processor, which in turn executes an interrupt service routine to identify the failure. This routine determines the I O unit number and uses it as an index into the memory s communication area. There the routine searches for all valid error messages, processes them, and resets the most significant error bit. An important benefit of the controller is to lighten the load on the system bus, thus freeing it so that more processors can be added. In a typical 68000 based Motorola microprocessor 68000 virtual memory system with a cache memory, a typical program will, on the average, read on 85 of its memory accesses and write on 15 . Since about 90 of the read accesses will be satisfied by the cache memory, the system bus is lightly loaded. In contrast, in a non cache system, the processor must access the bus for every memory reference. But with the MAC and a cache memory, this figure can be significantly reduced. Thus, with a cache system, a designer can add a few processors without significantly reducing performance. Still, with ordinary memory controllers, a processor must wait if it tries to access a bus that is occupied. With the controller chip, however, this is not a common occurrence, since it overlaps write operations with any read operations that are resolved by the cache memory. Multiprocessing makes demands on software as well as hardware, and here, too, the controller distinguishes itself by letting the designer mark pages or segments of the main memory as non cacheable. This capability is necessary when access to sections of software must be limited to one processor at a time. When the controller encounters such a page or segment, it places the page or segment mapping information in its translation look aside buffer, but it never places the page or segment in cache. Thus it prevents access by more than one processor at a time. The MAC offers a similar solution for acquiring semaphores locations used to restrict access to a section of code to one processor at a time. Say a processor has a semaphore in its cache. If another processor attempts a semaphore action on the same semaphore, the semaphore values seen by both processors could be different. Ultimately this might result in a software crash. The MAC solves this problem by marking the semaphore itself as uncacheable. Moreover, the technique that marks a segment or page as uncacheable is also useful for I O operations. For example, in an ordinary cached system that reads data from a UART Universal Asynchronous Receiver Transmitter , the data will wind up in the cache as well as in the main memory. When the processor attempts to read successive characters, it will get stale data from the cache rather than updated characters from the UART. It is necessary therefore that all data areas for devices that can change state autonomously I O devices and coprocessors, for example be marked as non cacheable. If more than four processors are required in a design, the MAC permits a powerful multiprocessing scheme that adds a relatively small local memory to each processor. Whenever the processor accesses a page, the controller will check to see if that page is in a local memory and specifically within the local memory of the requesting processor. If the page is in local memory, the access takes place unhindered. If it is not. however, the controller sends a Bus Error signal to the processor, which then loads the local memory with the requested data. This is analogous to paging data from the disk to RAM, and it occurs unseen by the programmer.