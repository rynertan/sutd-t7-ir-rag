# METHODS OF AND APPARATUS FOR SPEECH RECOGNITION

## Claims
Verfahren zur Spracherkennung mit den Schritten

## Description
This invention relates to methods of and apparatus for speech recognition. There has been proposed speech recognition apparatus having provision for counter measures against fluctuations in the utterance speed of speech, that uses the so called dynamic programming DP processing. Such apparatus is disclosed, for example, in published Japanese patent application No. 50 96104. With such known speech recognition apparatus using the dynamic programming matching processing, speech recognition can be carried out by matching input speech signals against stored templates without problems of utterance speed fluctuation and differences in word lengths, because the time dimension of the input is optimally warped, that is, time normalization is performed. However, in such speech recognition apparatus, when the number of words to be recognized is increased, there is the problem that the calculation time and memory capacity necessary for dynamic programming matching processing are inevitably and undesirably increased. A real time word recognition system generally as set out in the precharacterizing part of claim 1 is disclosed in IEEE Transactions on Computers, Vol. C 20, No. 9, September 1971, pages 972 to 978. The present invention provides a method of and an apparatus for speech recognition as defined in independent Claims 1 and 12, respectively. The invention will now be described by way of example with reference to the accompanying drawings, throughout which like parts are referred to by like references, and in which In embodiments of the present invention, an input speech signal is segmented and a plurality of time sequential acoustic parameters are produced from the segmented speech signals. Then, on the basis of data points, hereinafter referred to as dots, in a parameter space defined by the time sequential acoustic parameters at each sampling time, a trajectory thereof is obtained for use in performing the speech recognition operation. Throughout this specification the term speech recognition is used not only to indicate specifying the speech content uttered, but also to indicate specifying the identity of the speaker. In Figure 1, a microphone 1 supplies a speech signal to an amplifier 8 of an acoustic analyzer 2. The speech signal after having been amplified by the amplifier 8 is supplied through a low pass filter 9, having a cut off frequency of 5.5 KHz, to a 12 bit analog to digital A D converter 10, which has a sampling frequency of 12.5 KHz. The digital speech signal from the A D converter 10 is supplied to a bank of digital bandpass filters 11A, 11B, ... 11O forming, for example, fifteen channels, all of which are connected in parallel. Each of the fifteen digital bandpass filters 11A to 11O is formed as a quaternary digital filter, for example, a fourth order Butterworth filter, and the passband of each is assigned such that the frequency bands from 250 Hz to 5.5 KHz are provided so as to have equal intervals on a logarithmic scale. The output signals from the digital bandpass filters 11A to 11O are respectively supplied to rectifiers 12A, 12B, ... 12O in the fifteen channels, and the rectified outputs from the rectifiers 12A to 12O are respectively supplied to low pass filters 13A, 13B, ... 13O in each of the fifteen channels. One example of the digital low pass filters 13A to 13O is a finite impulse response FIR type low pass filter having a cut off frequency of 52.8 Hz. The fifteen output signals of the low pass filters 13A to 13O are respectively supplied to a sampler circuit 14 having a sampling period of 5.12 milliseconds. By use of the sampler circuit 14, the output signals from the low pass filters 13A to 13O are sampled with a sampling period of 5.12 ms. The sampled output signals from the sampler circuit 14 are supplied to a sound source characteristic normalizer 15 that removes or normalizes differences in the speech characteristics by the speakers. If it is desired only to identify a particular speaker and not to determine the speech content, the sound source characteristic normalizer 15 can be omitted. In the sound source characteristic normalizer 15, the sampling signal Ai n i 1, ... R where i is the serial number of the bandpass filters 11A to 11O for acoustic analysis and n is the sampling time is subjected to a logarithmic transformation expressed as where R is fifteen in this embodiment. If the normalized parameter of the sound or vocal source is taken as Pi n , when a n is greater than 0 is established, then the parameter Pi n is expressed as Further, when a n is greater than 0 is established, only the level of the input speech signal is normalized and, thus, the parameter Pi n is expressed as The parameter Pi n whose vocal source characteristic is normalized by such processing is supplied to a parameter memory 16, in which there is stored at every speech interval a vocal source characteristic normalized parameter Pi n by a segment detecting signal produced from a vocal period detecting section or segmentizer 17. The digital speech signal from the A D converter 10 is supplied to a zero cross counter 18 and to a power calculator 19 that form part of the segmentizer 17. The zero cross counter 18 counts the number of zero crosses of the digital speech signals at 64 points every 5.12 ms and supplies the counted value to a vocal period segment detector 20. The power calculator 19 calculates the power, or a squared sum, of the digital speech signals every 5.12 ms interval and supplies a power signal indicative of the power within that interval to the vocal period segment detector 20. The vocal source characteristic normalized data a n and b n obtained from the source characteristic normalizer 15 are both supplied to the segment detector 20, where in on the basis of the zero cross number, the interval power, and the source characteristic normalized data a n and b n , the discriminating processing for discriminating silence, unvoiced sound, and voice sounds, is carried out to determine the speech interval or segment. In this case, the speech interval or segment may be determined in units of phonemes, words, and sentences. The speech segment detecting signal indicative of the segmented speech from the segment detector 20 is supplied to the parameter memory 16 as the output of the segmentizer 17. The acounstic analyzing technique for an input speech signal in the acoustic analyzer 2 is not limited to this embodiment using bandpass filters, but can comprise any technique, so long as it can extract the necessary characteristics of the input speech signal. The acoustic parameter Pi n , whose source characteristic is normalized at every segment speech stored in the parameter memory 16, is supplied to a normalization along trajectory NAT processor 21. The NAT processor 21 is arranged to produce a trajectory from the time sequential acoustic parameter Pi n in the parameter space thereof. In the NAT processor 21, the time sequential acoustic parameter Pi n i 1,... I n 1, ... N where n is the sampling time draws dots in a parameter space of the I Figure 3 is an example of a trajectory formed by connecting the dots of Figure 2 by a smooth curve. If a trajectory such as shown in Figure 3 can be obtained, then speech utterance speed fluctuations can be removed. This is because it can be considered that time length differences of the segmented speech signals due to speech utterance speed fluctuations are almost all caused by time length expansion and contraction of the quasi stationary portion. This is equivalent to the dot density of the quasi stationary portions in the case of the dots shown in Figure 2. Thus, the influence of the time length on the non stationary portion is relatively small. The NAT processor 21 of Figure 1 then performs time normalization, in view of the fact that the trajectory is not changed relative to such speech utterance speed fluctuations. In other words, from the time sequential acoustic parameter Pi n represented in Figure 2, the trajectory of Figure 3 is obtained, which is formed by the smooth continuous curve beginning at start point Pi 1 to end point Pi n . If the curved line indicative of this trajectory is expressed as Pi and s O is less than or equal to s is less than or equal to S , it is not always necessary that Pi and O Pi 1 and Pi and S Pi N be established and, basically, the curved line may be such that Pi s will pass approximately through all of the dots. By matching the shape of the trajectory drain by the segmented speech signals thus obtained, or the trajectory length with the previously registered standard trajectory or trajectory length, it then becomes possible to carry out speech recognition. As a practical example, the trajectory of the segmented speech signals is obtained by using straight or curved lines to interpolate the dots drawn by a plurality of time sequential acoustic parameters produced from the segmented speech signals in the parameter space at every sampling point. Alternatively, the trajectory is assumed on the basis of more than two dots drawn by a plurality of the time sequential acoustic parameters. The length SL of this trajectory is obtained and, as shown by the circles in Figure 4, new dots are sampled at predetermined lengths along the trajectory. If, for example, M dots are sampled, dots on the trajectory are sampled on the bases of a predetermined length, that is, the sampling interval T SL M 1 . If a series of sampled dots are taken as Qi m i 1, ... I m 1, ... M , then Qi 1 Pi o and Qi M Pi S are established. The new time sequential acoustic parameters Qi m thus obtained are time normalized and used as time sequential speech recognition data suitable for use in the matching processing. When the sampling number M is fixed, even if the length of the trajectory formed by the segmented speech signals changes, the sampling number of the time sequential speech recognition parameters will be constant, so that the above described sampling number can coincide with that of the previously registered standard trajectory, making the matching processing easy. In a second practical example, the sampling interval carried out along the trajectory to obtain the new dots in the first example is kept constant, regardless of the length of the trajectory. The new time sequential acoustic parameter obtained in this sampling is used as the speech recognition data, in which case because the trajectory drawn by the segmented speech signals is always sampled with a predetermined length regardless of the trajectory length, the length of the trajectory drawn by the segmented speech signals can be used as data for the matching processing. The above described first example can be explained more fully with reference to Figure 1, wherein a trajectory length calculator 22 in the NAT processor 21 calculates the length of the trajectory drawn in the parameter space by the time sequential acoustic parameter Pi n , or the trajectory length. In general, the Euclidean distance D a Accordingly, a distance S n between the adjacent parameters in the case where the trajectory is obtained from the I where SL 1 O. Furthermore, the trajectory length SL is expressed as The trajectory length signal indicative of the trajectory length SL produced from the trajectory length calculator 22 is supplied to an interpolation distance or sampling length calculator 23 that calculates a sampling interval T of predetermined length, which is used to sample new dots along the trajectory by using straight line interpolation. In such case, if dot M is sampled the sampling interval T is expressed as An interpolator 24 is supplied with the sampling interval signal indicative of the sampling interval T from the sampling length calculator 23 and the time sequential acoustic parameter Pi n from the parameter memory 16. In the interpolator 24, along the trajectory formed by the time sequential acoustic parameter Pi n in its parameter space, or the trajectory formed, for example, by straight line approximation, new dots are sampled with the sampling interval T to form the speech recognition data parameters Qi m , called new time sequential acoustic in the following. The signal processing in the interpolator 24 can more clearly be described with reference to the flow chart of Figure 5 in which following Start in step 24a, a variable J, which indicates the sampling number, is set to 1 and a variable IC, which indicates the sampling time of the time sequential acoustic parameter Pi n , is also set to 1 . In step 24b, the variable J is unit incremented and in step 24c, depending on whether the variable J is less than or equal to M 1 M is the sampling number that has been previously set , it is judged whether the sampling number at that time becomes the last sampling number that must be sampled. If not, the processing proceeds to step 24d, in which a sampling distance DL from the first sampling point to the J Figure 6 is a graphical representation of the two dimensional time sequential acoustic parameters P 1 , P 2 , ... P 8 . The curve between the dots of the acoustic parameters are approximated by straight lines and along this trajectory, six new time sequential acoustic parameters Q 1 , Q 2 , ... Q 6 are respectively formed by straight line interpolation along the trajectory. In other words, when signal processing is carried out following the flow chart of Figure 5, the new time sequential acoustic parameter Qi m is formed from the time sequential acoustic parameter Pi n that was obtained from the input speech signal. This new time sequential acoustic parameter Qi m contains the data of the segmented input speech signals and is already time normalized. In discussing a second example, it should first be noted that the sampling length set by the sampling length calculator 23 in the first example is fixed at a predetermined length, regardless of the length of the trajectory formed by the segmented speech signals. By sampling the trajectory formed by the segmented speech signals with a predetermined length along the trajectory at all times, the length of the trajectory drawn by the segmented speech signals can be also used in the matching processing, so that when this trajectory is matched with the previously registered standard trajectory, the number of previously registered standard trajectories used in the matching processing can be reduced. For example, as a substitute for step 24c in the flow chart of Figure 5, this signal processing can be established by comparing the quantity IC with N 1, if the time sequential acoustic parameters obtained from the segmented speech signal are taken as Pi n n 1,... N . Figure 7 shows another embodiment of the speech recognition apparatus, in which elements corresponding to those of Figure 1 have the same reference numerals, and in this embodiment the time sequential acoustic parameter derived from the acoustic analyzer 2 is supplied to the NAT processor 21, in which the trajectory in the parameter space is obtained from the time sequential acoustic parameter. Then, normalization along trajectory processing forming a new time sequential acoustic parameter along the trajectory is carried out several times to perform speech recognition. This embodiment provides the advantage that even when the speech fluctuates, it is possible to obtain a relatively high recognition ratio. The time sequential acoustic parameter Pi n from the acoustic analyzer 2 is supplied to a first NAT processor 21 and the new time sequential acoustic parameter Qi m derived therefrom is supplied to a second NAT processor 26. In this second NAT processor 26, a trajectory in that parameter space is produced from the first new time sequential acoustic parameter Qi m by, for example, straight line approximation, and along this trajectory a second new time sequential acoustic parameter Ri m is formed by straight line interpolation, for example. In such signal processing, the first time sequential acoustic parameter Qi m produced from the first NAT processor 21 is supplied to a trajectory length calculator 27 in the second NAT processor 26, which is similar to the trajectory length calculator 22 in the first NAT processor 21, and the trajectory length calculator 27 calculates the length of the trajectory drawn by the first new time sequential acoustic parameter Qi m in the parameter space. A second trajectory length signal indicative of the length produced from the second trajectory length calculator 27 is fed to a second sampling length calculator 28, which is similar to the first sampling length calculator 23 in the first NAT processor 21. The second sampling length calculator 28 calculates the second sampling interval of the predetermined length in order to sample the new dots along the trajectory. A second interpolator 29 receives the second sampling interval signal from the second sampling length calculator 28 and the first new time sequential acoustic parameter Qi m produced by the first NAT processor 21. Just as the first interpolator 23 in the first NAT processor 21, the second interpolator 29 samples new dots on the trajectory drawn by the new time sequential acoustic parameter Qi m in the parameter space along the trajectory obtained by straight line approximation, for example, with the second sampling interval to form the second new time sequential acoustic parameter Ri m from the new dots. In this embodiment, normalization along trajectory processing is carried out twice however, it will be understood that if the NAT processing is carried out three or more times, the same beneficial action and effect will be obtained. The NAT processing can be carried out a plurality of times not only by first and second NAT processors 21 and 26 connected in cascade but also by a single NAT processor connected so that the output signal thereof is fed back to the input. Furthermore, if the sampling is always carried out with a predetermined length, regardless of the length of the trajectory that is drawn by the segmented speech signals, then the sampling length calculator is unnecessary. In addition and most importantly, the length of the trajectory drawn by the segmented speech signals can be used as data useful in selecting the registered standard trajectory in the matching processing. Although in the above examples the trajectory in the parameter space is obtained from the time sequential acoustic parameter by straight line approximation, and the new time sequential acoustic parameter is formed from this trajectory by straight line interpolation, it will be easily seen that if the trajectory is obtained by circular arc approximation, spline approximation, and so on, and a new time sequential acoustic parameter is formed from this trajectory by circular arc interpolation, spline interpolation, and so on, the same beneficial action and effect as abovedescribed can be achieved. In the above embodiments, the new time sequential acoustic parameter obtained from the NAT processor is selectively changed over by a mode switch 3, whereby in the registration mode it is stored in a standard parameter memory 4 at every segmented speech signal to be speech recognized, whereas in the recognition mode it is supplied to a Chebyshev distance calculator 25. Other kinds of distance calculators are suitable for use in this system and the Chebyshev one is provided as a well known example. In the recognition mode, the standard time sequential parameter stored in the standard parameter memory 4 is also supplied to the Chebyshev distance calculator 25. The Chebyshev distance calculator 25 calculates the Chebyshev distance between the new time sequential acoustic parameter with time normalized speech and the standard time sequential parameter stored in the standard parameter memory 4. The distance signal indicative of the Chebyshev distance from the Chebyshev distance calculator 25 is supplied to a minimum distance detector 6 that detects the standard time sequential parameter in which the Chebyshev distance relative to the time sequential acoustic parameter produced from the segmented input acoustic signals is at a minimum, the detected result then being supplied to an output terminal 7. In the above matching of the segmented input speech signal with the previously registered speech signal, the Chebyshev distance between the segmented input acoustic signal and the previously registered speech signal is calculated by the Chebyshev distance calculator 25, although any method can be adopted provided that the distance therebetween can be calculated. If the dynamic programming matching method is adopted for this distance calculation, because the segmented input speech signal is already time normalized there are advantages that the amount of calculation is reduced and that the memory capacity necessary for processing is minimized. It is also possible to use a linear matching method and a discriminant function to accomplish this distance measurement. In explaining the difference between the amount of calculation of the speech recognition apparatus provided by the above embodiments, which carry out the normalization along trajectory processing and that of the prior art speech recognition apparatus, which uses the dynamic programming matching method, it is seen that if an average amount of calculation necessary for dynamic programming matching per standard pattern relative to the input pattern is taken as α, an average amount of calculation in the Chebyshev distance calculator 25 is taken as β, and an average amount of calculation of the NAT processor 21 is taken as γ, then an amount of calculation C₁ necessary for dynamic programming matching J standard patterns can be expressed as That is, as the number of words to be recognized increases, the relationship between the amount of calculation C₁ and the amount of calculation C₂ becomes C₁ is much greater than C₂. As a result, with embodiments of speech recognition apparatus according to the present invention, which employs the NAT processing, there is an advantage that the amount of calculation can be decreased considerably. Figure 8 is an embodiment of the speech recognition apparatus according to the present invention in which added to the speech recognition apparatus of Figure 1 is a silence parameter adder 30, which adds an acoustic parameter indicative of silence to the plurality of time sequential acoustic parameters that are to be supplied to the NAT processor 21. Figure 9 graphically represents a trajectory that is drawn by a plurality of time sequential acoustic parameters to which the silence acoustic parameter, produced by the silence parameter adder 30 Figure 8 have been added. The trajectory drawn by the segmented speech signals with the added silence acoustic parameter is illustrated in a two dimensional parameter space for simplicity, and by virtue of the trajectory drawn by the segmented speech signals with the added silence data, it is possible to remove an influence of the time displacement of the segmentation of the speech signal exerted upon the speech recognition by the segmentizer 17 Figure 1 . The NAT processor 21 calculates the time sequential speech recognition parameter from the trajectory drawn by the segmented speech signal with the added silence signal. Although this trajectory is obtained by adding the silence acoustic parameter to both ends of the time sequential acoustic parameter indicative of the segmented speech signal, it is possible to obtain the trajectory by adding the silence acoustic parameter only at the front portion or the rear portion of the acoustic time sequential parameter indicative of the segmented speech signal. In the embodiment of Figure 10, before the trajectory drawn by the time normalized input speech signal to be speech recognized and the previously registered standard trajectory are matched with each other using the length of the trajectory drawn by the input speech signal, a desired standard trajectory is selected from a plurality of previously registered standard trajectories, thereby decreasing the number of standard trajectories that need be used in the matching processing. This provides a corresponding reduction in calculation time. Elements in Figure 10 corresponding to those of Figure 1 are identified with the same reference numerals and will not be described in detail. In Figure 10, a length data adder 31 adds data indicative of the trajectory length of the trajectory drawn by the segmented speech signal produced from the trajectory length calculator 22 to the time sequential speech recognition parameter derived from the trajectory drawn by the segmented speech signal that is produced from the NAT processor 21. The new time sequential acoustic parameter with the added trajectory length signal produced by the length data adder 31 is selectively changed over by the mode switch 3 so that in the registration mode it is stored in the standard parameter memory 4 at every segmented speech signal to be speech recognized, whereas in the recognition mode it is supplied to the Chebyshev distance calculator 25. In the recognition mode, the standard time sequential parameter stored in the standard parameter memory 4 is supplied to a standard parameter selector 32 that compares the trajectory length signal added to the new time sequential speech recognition parameter produced from the present segmented input speech signal with the trajectory length signal added to every standard time sequential parameter stored in the standard parameter memory 4, whereby the compared result is used to select the standard time sequential parameter to carry out the matching processing for the time sequential speech recognition parameter produced from the input segmented speech signal. The standard parameter selector 32 is described more fully as follows. Generally, it is considered that if words are the same, the time sequential acoustic parameters of the same words will draw the trajectories of nearly the same shape and length in the parameter space thereof. From this standpoint, the standard parameter selector 32 is arranged to select the standard trajectory having the trajectory length that is displaced from the trajectory length of the trajectory drawn by the input speech signal. For example, if the trajectory length of the standard trajectory is taken as TRLS and the trajectory length of the trajectory drawn, by the input speech signal is taken as TRLI, a trajectory length displacement TRL between the standard trajectory length TRLS and the trajectory length TRLI of the trajectory drawn by the input speech signal, as calculated by the signal processing, can be expressed by the following equation In this case, the trajectory length displacement TRL can be calculated not only by the above described equation but also by other suitable functions. As is seen from equation 14 , when the trajectory length TRLS of the standard trajectory and the trajectory length TRLI of the trajectory drawn by the input speech signal are equal, this trajectory length displacement TRL takes a minimum value of two. In this embodiment, any standard trajectory in which the trajectory length displacement TRL between the trajectory length TRLI drawn by the input speech signal and the trajectory length TRLS of the standard trajectory that has a value not larger than 2.1 is supplied to the Chebyshev distance calculator 25. In the embodiment of Figure 10, the speech signal applied to the microphone 1 is converted to the time sequential acoustic parameter by the acoustic analyzer 2. This time sequential acoustic parameter is then supplied to the NAT processor 21 that forms the new time sequential acoustic parameter, which is time normalized in the parameter space, from the time sequential acoustic parameter. In the length data adder 31 the trajectory length signal indicative of the trajectory drawn by the segmented input speech signal produced from the trajectory length calculator 22 of the NAT processor 21 is added to the new time sequential parameter. The combined output is supplied through the mode switch 3 to the standard parameter memory 4 in the registration mode, whereas in the recognition mode, it is supplied to the Chebyshev distance calculator 25. Then, the trajectory length signal produced from the trajectory length calculator 22 and the standard time sequential acoustic parameter added to the trajectory length signal and stored in the standard parameter memory 4 are respectively supplied to the standard parameter selector 32. In the standard parameter selector 32 the trajectory length displacement TRL between the trajectory length TRLI of the trajectory drawn by the segmented input speech signal and the trajectory length TRLS having the standard parameter is calculated in keeping with equation 14 . The standard parameter selector 32 then selects the standard time sequential acoustic parameter in which the trajectory length displacement TRL has a value not larger than, for example, 2.1 and supplies this standard time sequential acoustic parameter to the Chebyshev distance calculator 25. The Chebyshev distance calculator 25 calculates the Chebyshev distance between the time sequential speech recognition parameter obtained from the segmented input speech signal and the selected standard time sequential parameter, and the distance signal indicative of the Chebyshev distance is supplied to and detected by the minimum distance detector 6. Thus, the recognized result indicating to which particular standard time sequential parameter, the time sequential speech recognition parameter, or particular standard trajectory drawn by the input speech signal, corresponds is supplied to the output terminal 7. Because the trajectory length of the trajectory drawn by the segmented input speech signal is used as the recognition data for the matching processing, it is sufficient to match the above described trajectory with less than all of the standard trajectories, so that the calculation amount necessary for processing in the Chebyshev distance calculator 25 and the minimum distance detector 6 are decreased considerably. In the embodiment of Figure 10 the time sequential acoustic parameter produced from the acoustic analyzer 2 is supplied to the trajectory length calculator 22 of the NAT processor 21, and the trajectory length of the trajectory drawn in the parameter space by the segmented input speech signals is calculated by the trajectory length calculator 22. However, it will easily be seen that if another trajectory length calculator is provided independent of the trajectory length calculator 22, and the new time sequential acoustic parameter produced from the NAT processor 21 is supplied to this other trajectory length calculator, which then calculates the trajectory length of the trajectory drawn in the parameter space by the new time sequential acoustic parameter, and the standard trajectory is selected on the basis of this calculated trajectory length, then the same beneficial effects as those of the above described embodiment can be obtained. Further, it will easily be seen that when the normalization along trajectory processing is carried out several times, the above described signal processing can be carried out. In the embodiment of Figure 11, when the trajectory drawn by the segmented input speech signals and the previously registered standard trajectory are matched with each other, taking both trajectory lengths into consideration, the correct standard trajectory is selected, thereby increasing the recognition ratio. In Figure 11 elements corresponding to those of Figure 1 have the same reference numerals and need not be described in detail. The length data adder 31 is supplied with the new time sequential acoustic parameter produced from the interpolator 24 of the NAT processor 21, and the trajectory length signal from the trajectory length calculator 22 thereof. Accordingly, the length data adder 31 produces the time sequential acoustic parameter added to the trajectory length signal indicative of the trajectory length of the trajectory drawn in the parameter space by the segmented input speech signals. The new time sequential acoustic parameter added with the trajectory length signal produced from the length data adder 31 is selectively changed over by the mode switch 3, whereby in the registration mode it is stored in the standard parameter memory 4 at every segmented input speech signal to be recognized, whereas in the recognition mode, it is supplied to the Chebyshev distance calculator 25. In the recognition mode the standard time sequential parameter stored in the standard parameter memory 4 is supplied to the Chebyshev distance calculator 25 that calculates the distance signal indicative of the Chebyshev distance between the time sequential speech recognition parameter produced from the segmented input acoustic signal and the standard time sequential parameter and produces the distance signal and the signal indicative of the trajectory length of this standard trajectory. The distance signal and the signal indicative of the trajectory length of the standard trajectory produced from the Chebyshev distance calculator 25 are supplied to a distance corrector 5 that also receives the signal indicative of the trajectory length from the trajectory length calculator 22 of the NAT processor 21. The distance corrector 5 operates to compare the trajectory length of the trajectory drawn by the segmented input speech signal and the trajectory length of the standard trajectory with each other, and corrects the Chebyshev distance produced from the Chebyshev distance calculator 25 based on such comparison. In describing the distance corrector 5 more fully it is seen that, generally, if the spoken words are same, the time sequential acoustic parameters of the same words draw trajectories of substantially the same shape and length in the parameter space thereof. Accordingly, in view of this, the distance corrector 5 corrects the distance the Chebyshev distance in this embodiment, but a distance obtained by some other calculation method could also be adopted between the trajectory by the segmented input speech signal and the standard trajectory in accordance with the trajectory length displacement between the trajectory drawn by the segmented input speech signal and the standard trajectory. In other words, if the trajectory length of the standard trajectory is taken as TRLS, and the trajectory length of the trajectory drawn by the segmented input speech signal is taken as TRLI, the trajectory length displacement TRL calculated by the signal processing can be expressed by the following equation In this case, as will be clear from equation 15 that when TRLS TRLI is established, the trajectory length displacement TRL has a minimum value of two. If the distance signal is taken as Chbs, as derived from the trajectory length displacement TRL, the distance signal Chbs can be distance corrected by suitable signal processing expressed by The corrected distance signal CHBS from the distance corrector 5 is then supplied to the minimum distance detector 6, and the other circuits, such as the acoustic analyser 2, are similar to those of the speech recognition apparatus of Figure 1.