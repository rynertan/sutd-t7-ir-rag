# DATA PROCESSOR SYSTEM AND METHOD

## Claims
Datenverarbeitungssystem mit einem Systembus 1 mit Bustakt, Daten Eingabemitteln 6, 7F, 9B, 9C zur Eingabe von Daten, Anzeigemitteln 9J, 9H zur Anzeige von eingegebenen Daten und von verarbeiteten Daten, Speichermitteln 5 zum Speichern der eingegebenen Daten und der verarbeiteten Daten und gemeinsam genutzten Speichermitteln 2 , die über den Systembus 1 mit jedem der vorgenannten Mittel verbunden sind, wobei das System eine Datenverarbeitung in der durch die Daten Eingabemittel bestimmten Weise ausführt,

## Description
The present invention relates generally to a data processing system and more specifically to a data processing system suitable for processing image information composed of a large amount of digital data indicative of an image including pictures and characters such as in documents or drawings. The field in which data processing systems for image information of the above mentioned kind is applicable is now expanding. Therefore, if document preparation, electronic files, mutual communications, etc. can be configured as a series of systems simply at a low price, it is possible to provide a data processing system useful for general business processing transaction in various fields such as office automation, future of the office, paperless office, etc. The image information of this kind, however, includes a great amount of information about 100 times or more greater than that of the case where the general data coded into a predetermined code are processed for instance, numerical value calculation, data processing, word processing, etc. . Therefore, in digitally processing image information, it is necessary to adopt hardware having a throughput 100 times or more greater than that of the case where general data are processed. For the reason described above, conventionally, there have been adopted various methods such as a special processor, a special hardware logic, or a large scale electronic computer all designed in accordance with special specifications so as to be able to process a great amount of data, while reducing the load applied to hardware by compressing data in order to reduce the amount of data to be processed. In the case where the conventional method is adopted, however, there exist problems in that it is unavoidable that the overall system configuration of the data processing system is large in size and complicated, and additionally a costly system should be used. To solve these problems it may be considered that image information can be processed by use of personal computers, mini computers, office computers, etc. which are all available as versatile units. However, since these versatile units are not configured so as to process a great amount of data since the processing speed is slow and since these units have no processing capability to execute various tasks independently, it is impossible to process a great amount of data in a short time even if the functions of these units are utilized simply as they are. Document D1 on which the pre characterizing portion of claims 1 and 13 are based discloses a multi processor system for image sequence analysis in which the microprocessors are connected in a multiple instruction multiple data mode to multiple large RAM modules. The processors access the memory bank via a bus system having separate buses for data, address and control signals between every processor and memory bank in the system and arbiters to control access to the memory banks. With these problems in mind, therefore, it is the primary object of the present invention to provide a data processing system for processing image information at a practically and sufficiently high data execution and processing speed by arranging a number of devices such as versatile microprocessors, memory units, etc. of low processing speed and low processing capability which are all connected to each other through a system bus and by providing arbitration functions such that each device can process data in simultaneous parallel fashion. According to the present invention there is provided, a data processing system of the type having a system bus, including a bus clock, data input means for inputting data, display means for displaying inputted data and processed data, storage means for storing the input data and the processed data, and shared storage means connected to each of the above means through the system bus, said system executing data processing as designated by the data input means, wherein the system comprises The invention also provides a method of processing data including the steps of inputting data, storing processing and displaying data including the steps of In the data processing system according to the present invention, said executing means may further comprise means for allocating each time slot so formed so as to synchronize with the bus clock in the system bus to a plurality of said memory bank means, respectively and for transferring a unit of processed data constituting the divisional data through the system bus at the timing of the time slot allocated to the memory bank means designated by the memory request. Preferably said executing means comprises second means for transferring a unit of processed data for said memory bank means other than that designated by the memory request through the system bus at the timing of the allocated time slot corresponding to one memory bank means not designated by the memory request. Advantageously said executing means comprises third means for forming a time slot allocated to no memory bank means in addition to the time slots allocated to a plurality of said memory bank means and for transferring a unit of processed data for the memory bank means designated by the memory request through the system bus at timing of the non allocated time slot. Furthermore, said executing means may comprise fourth means for transferring data corresponding to the memory request to the memory bank at the timing of the time slot next to an empty time slot, when an empty time slot not designated by the memory request is produced in a series of time slots. In the data processing system, the time slot is selected to have a time duration shorter than a memory cycle required when the memory bank means writes or reads data or the time duration is selected to be shorter than the data processing time required when said processor processes the data read through the system bus. The data processing system according to the present invention may further comprise arbitrating means for selecting one of simultaneously outputted memory requests in accordance with a priority order previously determined with respect to each processor means and for processing data corresponding to the memory request selected on the basis of priority, when a plurality of memory requests are outputted simultaneously from two or more processor means to the same memory bank. Said arbitrating means comprises a lock function such that a selection of other memory requests are refused until data corresponding to one of the priority selected memory requests have been processed by a predetermined amount. In summary, the data processing system divides data to be processed respectively in response to a memory request outputted from each processor into predetermined portions of divisional data and executes the data processing corresponding to each memory request being classified according to the divisional data in synchronization with the clock of the system bus in simultaneous parallel fashion. Therefore, when memory requests for each processor are generated in sequence, all the data corresponding to each memory request can be processed for each divisional data without processing all the data simultaneously that is, the divisional data are processed in sequence simultaneously in parallel fashion, so that it is possible to markedly reduce processing time on the whole, because almost all parts of the data processing corresponding to all the memory requests can be processed within a short time during which the divisional data corresponding to a plurality of simultaneously outputted memory requests are executed simultaneously. Therefore, even if versatile devices of small throughput are used as the processors and memory banks, it is possible to execute the processing of all the data at a practically and sufficiently high data execution processing speed. In other words, in processing the data including non coded data such as image data, it is possible to readily configure a data processing system having the same degree of throughout as in a specially ordered computer by simply adopting several versatile devices. The features and advantages of the data processing system according to the present invention will be more clearly appreciated from the following description of the preferred embodiments of the invention taken in conjunction with the accompanying drawings in which like reference numerals designate the same or similar elements or sections throughout the figure thereof and in which An embodiment of the present invention will be described in further detail with reference to the attached drawings. As shown in Fig. 1 the data processing system comprises a system bus 1 connected to eight subsystems 10, 11, 9, 12, 6, 8, 7, 5, for sharing the task of a series of data processing steps to be executed in sequence. The system bus 1 is also connected to a shared storage device 2 shared by each subsystem. The shared storage device 2 includes a board 2A on which a bus and a memory controller MBC are mounted and two boards 2B and 2C on each of which a RAM having a memory capacity of 2 mega bytes referred to as MB hereinafter is mounted. The bus and the memory controller read and write corresponding data in or from the RAMs on the boards 2B and 2C through a local bus 2D in response to memory requests outputted from each subsystem through the system bus 1. In the case that the memory requests from each subsystem are concurrent, the bus and the memory controller MBC arbitrate this concurrent relationship so that the data can be processed simultaneously in parallel fashion. That is, the bus and the memory controller MBC include a function which is responsive to all the requests of the subsystems in a short time. The system bus 1 is connected to each subsystem s CPU, P₀ to P₇, and is shared by all the processors P₀ to P₇ for transferring signals and data between each processor CPU P₀ to P₇ and the bus 1 and the memory controller MBC in the shared storage device 2. In a first subsystem, a file storage device STS 5 is allocated and a processor P₀ having a data processing speed of 2 MB sec is connected to the system bus 1. Being mounted on a board 5A, the processor P₀ can store or read file data in or from a DRAW direct read after write device 5B and a HDD hard disk device 5C which configure a storage device for filing data in the data processor. In this embodiment, an interface DRAW I F for the DRAW 5B is disposed on the board 5A. Further, a board 5D on which an interface HDD I F for the HDD 5C is mounted is connected to the processor P₀ through a local bus 5E. Therefore, the processor P₀ writes data stored in the shared storage device 2 into the HDD 5C or the DRAW 5B through the system bus 1 and transfers data stored in the HDD 5 or the DRAW 5B to the shared storage device 2 through the system bus 1. Further, in a second subsystem, a data transfer system NTS 6 is allocated and a processor P₁ having a data processing speed of 2 MB sec is connected to the system bus 1. The processor P₁ is mounted on a board 6A together with a transmission controller Ethernet controller and can send out data from the system bus to a transmission path 6C of a coaxial cable through a transmission unit 6B and can receive data coming through a transmission path 6C to the system bus 1. Therefore, the processor P₁ sends out data stored in the shared storage device 2 to the transmission unit 6B through the system bus 1 and receives data coming from the outside via the transmission unit 6B in the shared storage device 2 through the system bus 1. As a result, it is possible to configure a further larger scale data processor system by connecting this data processor to outside devices or units. In a third subsystem, an image reader and printer IDS 7 is allocated and a processor P₂ having a data processing speed of 2 MB sec is connected to the system bus 1. The processor P₂ is mounted on a board 7A together with an image input output controller. Under the control of this image input output controller, the processor P₂ is connected to an image printer IP 7E through a local bus 7B and an image printer interface IP I F board 7C and further connected to an image reader IR 7F through the local bus 7B and an image printer interface IR I F board 7D. The processor P₂ sends image data read through the image reader 7F in the shared storage device 2 through the system bus 1 and prints out data in the shared storage device 2 in an image printer 7E through the system bus 1. In a fourth subsystem, an image information compressor decompressor system CDS 8 is allocated, and a processor P₃ having a data processing speed of 2 MB sec is connected to the system bus 1. The processor P₃ is mounted on a board 8A together with a compress decompress controller, and reads data in the shared storage device 2 through the system bus 1, transfers this data to a compress processing circuit COMP board 8C or to a decompress processing circuit DECOMP board 8D through a local bus 8B, and further sends this compressed or decompressed, processed data to the shared storage device 2 through the system bus 1. The image information compressing decompressing system 8 increases the amount of data to be stored by previously compress processing data to be stored in the HDD 5C or DRAW 5B of the file storage device 5 in accordance with a modified Huffman method or a modified READ method and by decompress processing the compressed data read from the HDD 5C or the DRAW 5B, the compressed or decompressed data being processed for transmission, display, printing, etc. In a fifth subsystem, an operation display system DPS 9 is allocated and a processor P₄ having a data processing speed of 2.5 MB sec is connected to the system bus 1. On the board 9A, on which a processor P₄ is mounted, there are mounted ROMs and RAMs for storing processing programs and data used in converting image data read by the processor P₄ into image display signals. Further, an operation display system 9 has operating input means such as a keyboard 9B and a mouse 9C. Data from the keyboard 9B and the mouse 9C are inputted to or outputted from the processor P₄ through a serial input output circuit S I O mounted on the board 9A. Here, data inputted through the keyboard 9B and the mouse 9C are those coded into predetermined formats, and the processor P₄ transfers these input data e.g. character data or command data composed of characters, symbols, etc. to the shared storage device 2 through the system bus 1. In contrast with this, in the case where image data such as images, characters or data indicative of a combination of images and characters are displayed, the processor P₄ gives these data to a bit map controller BMC on a board 9E as commands and data through a local bus 9D. Here, the processor P₄ transfers only the coded character data to the bit map controller BMC as commands to convert them into font data corresponding thereto, and then transfers them to two boards 9G and 9H of video memory VRAM through a local bus 9F in order to develop them on a two dimentional picture memory. On the other hand, since image data generated by an image reader 7F are uncoded data directly representing black and white picture elements as they actually are, the processor P₄ develop these data without converting them in the method as executed for coded character data. Image data thus developed on the VRAM are read through a local bus 9F by a timing circuit TIM mounted on a board 9I and then displayed on displays 9J or 9K such as a cathode ray tube CRT , for instance. In addition to the above mentioned functions, the processor P4 reads image data from the shared storage device 2 through the system bus 1 and assembles or edits these into a piece of picture. Further, the processor P₄ has a function for inserting characters inputted from the keyboard 9B onto the picture. The processor P₄ displays data being processed in the above assembly edition process on the CRTs 9J and 9K and transfers the assembled edited data to the shared storage device 2 through the system bus 1. As described above, the operation display unit 9 assembles and edits a piece of picture on the basis of image data read from the file storage device 5 to the shared storage unit 2 and in response to the operations of the keyboard 9B and the mouse 9C serving as operation input means and displays the picture on the display units 9J and 9K, further the edited picture data are transferred to the shared storage unit 2 through the system bus 1. These data are stored in the file storage device 5, printed by an image printer 7E provided in an image read printer 7 or transferred to the outside through a data transmitter 6B. In a sixth subsystem, a main controller system PCS 10 is allocated and a processor P₅ having a data processing speed of 2.5 MB sec is connected to the system bus 1. To a board 10A on which the processor P₅ is mounted, a RAM on a board 10C and an input unit I O on a board 10D are connected through a local bus 10B. Each subsystem and the shared storage device 2 connected to the system bus 1 are controlled as a whole in accordance with a system operation program operating system, application program, etc. written from a floppy disk drive FDD in the local memory RAM through the input output device I O. Interrupt signals and attention signals required for the above mentioned control are transferred between the main controller 10 and the total subsystems through a control signal line 3. Further, the processor P₅ executes the assembly processing of image data to be printed by the image printer 7E in accordance with a program inputted to the RAM on the board 10C. Seventh and eighth subsystems, preliminary units 11 and 12 their processors are designated by P₆ and P₇ , have bus space allocated for them so as to allow other new possible functions to be added. In the system configuration as shown in Fig. 1, the operator can enter commands for designating modes and character data such as characters and symbols by the use of the keyboard 9B and the mouse 9C in the operation display system 9 and further image data including pictures and characters by the use of the image reader 7F of the image read printer 7. Here, data inputted from the keyboard 9B and the mouse 9C are those having predetermined codes so as to be easily transferred and processed, so that the character data can be inputted in dependence upon a relatively small amount of data. In contrast with this, image data inputted from the image reader 7 of the image read printer 9 are extraordinally great in the amount of data, because the image data represents the black or white of each picture element on the basis of binary code. The data inputted through the keyboard 9B or the mouse 9C are written once from the processor P₄ of the operation display system 9 to the shared storage device 2 through the system bus 1 and thereafter transferred to the image compressor decompressor system 8 again through the system bus 1 in order to execute data compression processing. The data thus processed are transferred to the shared storage device 2 again through the system bus 1. Thereafter, the data are transferred to the file storage device 5 again through the system bus 1 and are stored in the HDD 5C or the DRAW 5B serving as the external storage device. Similarly, image data inputted from the image read printer 7 are once stored in the shared storage device 2 through the system bus 1, and then transferred to the image information compressor decompressor system 8, again through the system bus 1, for data compression. The compressed data are transferred to the shared storage device 2 through the system bus 1 and then transferred to the file storage device 5 through the system bus 1 so as to be stored in the HDD 5C or the DRAW 5B. As described above, data compressed by the image information compressor decompressor system 8 are stored in the HDD 5C and the DRAW 5B, and these stored data are outputted to the display units 9J and 9K in the operation display unit 9 or the image printer 7E in the image read printer 7. In this case, data in the HDD 5C and the DRAW 5B are transferred to the shared storage device 2 through the system bus 1 on the basis of the data from the keyboard 9B or the mouse 9C in the operation display system 9, and then transferred to the image information compressor decompressor system 8 through the system bus 1 in order to decompress the transferred data. The resultant data are transferred to the shared storage device 2 through the system bus 1 and then displayed or printed by the display units 9J and 9K in the operation display system 9 or by the image printer 7E in the image read printer 7. At this moment, the assembly of the picture with respect to image signals supplied to the display units 9J and 9K is executed by the processor P₄ in the operation display system 9, while the assembly of a picture with respect to image signals supplied to the printer 7E is executed by the processor P5 in the main controller 10. Further, in such a mode that data stored in the file storage device 5 are re edited or that characters are newly inserted in a picture inputted through the keyboard 9B or the image reader 7F, after having once been transferred to the shared storage device 2 respective data are edited by the processor P₄ in the same way. As described above, the data processor shown in Fig. 1 processes data under the control of the main controller 10 in each operation mode in accordance with an operation program that is operating system or application program inputted from the floppy disk drive FDD to the local memory RAM on the board 10C in the main controller 10. In executing the above data processing, each subsystem makes an access to the shared storage device 2 while sharing the system bus 1. At this moment, it is necessary to occupy the shared storage device 2 and the subsystems until data processing on the basis of a memory request has been completed in response to a corresponding memory request outputted from one subsystem. However, if the above occupation time is excessively long, it would be necessary in a prior art system to wait for a long time in order to process data on the basis of another memory request outputted from another subsystem. In order to solve the above problem, the shared storage device 2 is so configured as to have an arbitration function such that the bus and the memory controller MBC can process the supply of data from each processor in each subsystem simultaneously in parallel fashion. Therefore, it is possible to markedly reduce data processing time as compared when a series of sequential data are processed in time series fashion, as described below. Further, signals and data having a bar code are represented on the basis of negative logic. Now, for example, in the case where image data having been compressed stored in the HDD 5C and the DRAW 5 in the file storage device serving as an external storage device are retrieved and displayed on the display units 9J and 9K in the operation display device 9, a series of data as shown in Fig. 2 are processed in sequence. That is, at the data processing step PRO of No. 0, under the control of the main controller 10, image data to be read out from the HDD 5C or the DRAW 5B in the file storage device 5 are retrieved logically. At the succeeding data processing step PR1 of No. 1, the data retrieved from the file storage device 5 are read out and transferred to the shared storage device 2. At the succeeding data processing step PR2 of No. 2, the data transferred to the shared storage device 2 are read out by the processor P₃ in the image information compressor decompressor system 8 for decompression processing and then written again in the shared storage device 2. At the succeeding data processing step PR3 of No. 3, the data written again into the shared storage device 2 are read out by the processor P₄ in the operation display system 9 for the edition assembly processing of a picture and for the insertion processing of characters and then stored again in the shared storage device 2. At the succeeding data processing step PR₄ of No. 4, the data stored again in the shared storage device 2 are read by the operation display system 9 and then displayed on the display units 9J and 9K through the bit map controller 9E and the VRAMs 9G and 9H. In a series of these data processing steps, the steps in which the data are transferred through the system bus 1 are the data processing steps PR₁ to PR₄ of No. 1 to No. 4, the sum total of each processing time T₁ to T₄ being determined according to the data processing speed of each processor for processing data in each step and to the amount of data to be processed in each processor. That is to say, in the data processing step PR1, the data read out from the HDD 5C or the DRAW 5B in the file storage device 5 are transferred to the shared storage device 2 during time T₁ at the data processing speed 2 MB sec of the processor P₀. In the data processing step PR₂ of No. 2, the processor P₃ in the image information compressor decompressor system 8 reads the data stored in the shared storage device 2 at the data processing speed 2 MB sec, and further the processor P₃ stores again the decompression processed data into the shared storage device 2 at the data processing speed of 2 MB sec, thus a data processing time T₂ being required. Also, in the data processing step PR₃ of No. 3, the processor P₄ in the operation display system 9 reads out the data from the shared storage device 2 at the data processing speed of 2.5 MB sec, and then executes the edition processing such as picture assembly or character insertion, etc. Thereafter, the processor P₄ stores the edited data in the shared stored device 2 at the data processing speed 2.5 MB sec thus a data processing time T₃ being required. Further, at the data processing step PR₄ of No. 4. the processor P₄ in the operation display unit 9 reads out the data from the shared storage device 2 at the data processing speed of 2.5 MB sec and displays the read data on the display units 9J and 9K, thus a data processing time T₄ being required. Therefore, in the data processing system configured as shown in Fig. 1, if a series of data processing steps as shown in Fig. 2 are executed in sequence in time series fashion, the sum total TSM 1 of times required for processing and storing data over the system bus, is as follows According to the theory of the present invention, however, the task of processing and storing the amount of data thus explained over the system bus is being carried out by dividing data into predetermined portions of divisional data for instance, ,1 about 16 kB or 8 kB kB kilobyte and the data processing is executed one divisional data by one divisional data simultaneously in parallel fashion by the use of a plurality of processors. In more detail, the data to be processed in a series of data processing steps PR₁ to PR₄, respectively, as shown in Fig. 2 are divided into a plurality of divisions seven divisions in this embodiment as shown in Fig. 3, and the processings of each divisional data are executed in sequence simultaneously in parallel fashion for each divisional data processing execution time TU₁ to TU₁₀ This first re stored divisional data, as shown in Fig. 3 C , is next processed in the processing step PR₃₁ during the processing execution time TU₃, corresponding to the data processing step PR₃ shown in Fig. 2. That is, the processor P₄ reads the divisional data in the shared storage device 2 for edition processing and thereafter the data is re stored in the shared storage device 2. This first re stored divisional data, as shown in Fig. 3 D , is thereafter processed in the data processing step PR₄₁ during the processing execution time TU₄, corresponding to the data processing step PR₄ shown in Fig. 2. The first divisional data in the shared storage device 2 are thus read out by the processor P₄ and displayed on the display units 9J and 9K. As described above, the first divisional data is processed sequentially in the order of the data processing steps PR₁₁, PR₂₁, PR₃₁, and PR₄₁ during the processing execution times TU₁, TU₂, TU₃, and TU₄, respectively. After the elapse of time TU₁, in the second processing execution time TU₂ the processor P₀ in the file storage device 5 reads the second divisional data from the external storage device in the data processing step PR₁₂ and stores it in the shared storage device 2. In the same way as in the first divisional data, this second divisional data is sequentially processed in the data processing steps PR₂₂, PR₃₂, and PR₄₂ which are time shifted in sequence with respect to the processing execution times TU₃, TU₄ and TU₅ as a result, the second divisional data are displayed on the display units 9J and 9K during the processing execution time TU₅. In the same way, the third, fourth, ..., etc. divisional data are read from the file storage device 5 in sequence during the processing execution times TU₃, TU₄ ..., etc. and are processed and displayed on the display units 9J and 9K in sequence in the processing steps PR₂₃, PR₃₃, PR₄₃ , PR₂₄, PR₃₄, PR₄₄ , ..., etc. as these third, fourth ..., etc. divisional data are shifted in sequence to the succeeding processing execution times TU₄, TU₅, TU₆ , TU₅, TU₆, TU₇ ..., etc. As described above, the data to be processed in the data processing steps PR₁, PR₂, PR₃ and PR₄ shown in Fig. 2 are processed in sequence one divisional data by one divisional data for each succeeding divisional data processing execution time, and further the sequential processings are executed in concurrent parallel fashion referred to as pipe line processing . As a result, each processor to which each task in each processing step is allocated operates in concurrent parallel fashion in the divisional data processing execution time. Therefore, it is possible to enhance the processing capability as a whole when a plurality of processors is seen as a single processor, thus the total data processing time being shortened. The reason why the above mentioned good results can be obtained is that in the case where the data processing steps PR₁ to PR₄ are executed in sequence in time series fashion as shown above in Fig. 2, while one processor to which a task for one data processing step is allocated is operating for data processing, other processors are in a stand by condition only awaiting commands without processing data, and therefore the data processing time is elongated because of the existence of such wasteful time. However, according to the method shown in Fig. 3, it is possible to markedly reduce the above mentioned wasteful time. When the data processing method according to the present invention as shown in Fig. 3 is executed, the total processing time TSM₂ required for processing the total data is an addition of a time interval TZ For instance, as shown in Figs. 3 A to 3 D , when each divisional data processing execution time in each processing step is determined so as to be equal to each other, the total data processing time TSM₂ can be expressed as Therefore, in the system configuration as shown in Fig. 1, even if versatile microprocessors of relatively slow processor speed are incorporated, it is possible to realize a data processor provided with a operationally sufficient throughput suitable for processing the markedly great amount of image data from the standpoint of the total data processing time. Further, the concurrent parallel processings of divisional data in the system configuration shown in Fig. 1 can be achieved when the arbitrator provided for the bus and the memory controller MBC in the shared storage device 2 processes the concurrence of processors in the subsystems connected to the system bus 1 in concurrent parallel fashion. As shown in Fig. 4, the shared storage device 2 is connected to each processor P₀, P₁, P₂ ... P₇ referred to as P In this embodiment, the system bus 1 is composed of an address data line ADDRESS of 20 bits, a read data line RDATA of 16 bits, a write data line WDATA of 16 bits, and a bus of 3 bits for transferring a read write command R The memory 15 is divided into eight memory banks MB₀, MB₁ ... MB₇ referred to as MB The arbitrator 16 executes two arbitration tasks. The first task is to allocate memory banks MB The second task of the arbitrator 16 is to arbitrate which processor P The arbitrator 16 has a time slot allocator 16A Fig. 5 for executing the first task. As shown in Figs. 6 A to H , this time slot allocator 16A generates eight time slot signals TS₀ to TS₇ referred to as TS Here, the time slot intervals of each time slot signal TS₀ to TS₇ are selected to correspond to the processing time for unit data for instance, 1 word which are actually and sequentially processed. Therefore, the repetitive period of each time slot is determined to be sufficiently short as compared with the processing execution times TU₁ to TU₁₀ Fig. 3 required for processing the divisional data. As described above, in practice, the divisional data are processed unit data by unit data. Thus, in the case where memory requests Additionally, when no corresponding memory request is generated in each time slot of the time slot signal TS The above relationship can be expressed as follows Here, the formula 3 indicates that the time slot signal TS This indicates that when there are no memory requests to the preceding time slots that is the j 2 th, j 3 th , the j th memory bank MB The above relationship of formula 4 can be expressed as enable signals EN₁ to EN₇ to each memory bank MB₀ to MB₇ as follows In the formulas from 5 to 12 , the term EN The arbitrator 16 further includes a memory access controller 16B Fig. 4 . This memory access controller 16B has decode means 16B11 to 16B17 referred to as 16B1 In response to this input signal, the decode means 16 B1 That is to say, memory bank signals To express the above in general, the memory bank designation signals As shown in Fig. 8, the memory access means 16B2 The memory request latched by the latch circuit 25 is inputted to a two input NAND gate 27 through a NOR gate 26. To this NAND gate 27, a busy signal Therefore, although the time slot allocator 16A generates an enable signal The latch output Therefore, the signals to the same processor P As described above, the occupation acknowledgement signal The priority selector means 31 receives the latch output In the case of this embodiment, the priority level has previously been determined as shown in Fig. 10. As already described with reference to Fig. 4, the processors P₀, P₁, P₂, P₃, P₄, P₅, P₆ and P₇ are allocated in sequence to the file storage device SPS 5, the data transmitter NTS 6, the image read printer IDS 7, the image information compressor decompressor system CDS 8, the operation display system DPS 9, the main controller PCS 10, the preliminary unit 11, and the preliminary unit 12. The priority level is so determined as to become higher in this order. The priority level is determined in such a way that a higher level is allocated to a subsystem including a device to which the necessity of real time processing is high when the memory request is generated, for instance, such as the HDD 5C provided in the file storage device as an external storage device. As described above, the priority selection output signal As described above, in the case where the i th memory bank MB In this embodiment, a lock means 32 is provided in the priority selector means 31 Fig. 8 , so that in the processor P The function of the lock means 32 as described above is executed on the basis of the program stored in the local memory 10c Fig. 1 in the main controller 10. Therefore, in the present embodiment, once a memory bank designation signal is selected as the highest priority from among those coming simultaneously at a point of time, even if thereafter another memory bank designation signal of a higher priority comes before the processor corresponding to the selected memory bank designation signal will have completed a series of the data processings, the signal of higher priority is neglected and, the j th memory bank is kept occupied by the previously selected processor. Further, with respect to specified memory areas in the memory areas of the j th memory bank, the lock means 32 locks in such a way that the data are allowed to be updated only when the memory bank designation signal based on the memory request from a predetermined processor is selected by the priority selector means 31, so that data stored in a predetermined memory bank can be saved. Further, the arbitrator 16 includes a memory bank enable signal generator 16c Fig. 4 . This memory bank enable signal generator I6c, as shown in Fig. 11, has a latch circuit 41 for receiving enable signals In this memory cycle operation status, the j th memory bank MB As described above, during the operation of the memory banks MB₀ to MB₇, the bus clock BCLK is supplied from the arbitrator 16 to each memory bank in order to operate the memory bank in synchronization with the processors P₀ to P₇ via the arbitrator 16. As shown in Fig. 12, the memory bank MB On the other hand, write data WD coming through the write data line WDATA in the system bus 1 is latched by a write data latch circuit 49, and the latch output is inputted to the memory area 45. Further, memory data MD read from the memory area 45 is latched by a read data latch circuit 50 and the latch output RD is sent out to the read data line RDATA in the system bus 1 in response to an output timing signal generated by a memory control logic 52. Further, the memory controller 46 includes an arbitrate logic 51, and receives the selection signal supplied from a high level bite selection line Further, under the control of an arbitration logic 51, a refresh address counter 54 is driven by a refresh control logic 53, in order to refresh each memory cell in the memory area 45 in sequence at predetermined time intervals, of, for instance, 14 sec, for saving the stored data. In the configuration as described above, the data processors execute data processing in synchronization with the bus clock BCLK shown in Fig. 13 A . In this embodiment, the period of the bus clock BCLK is selected to be shorter than a cycle time required when each memory bank MB₀ to MB₇ in the memory section 15 operates once to read write data in the case of dynamic RAMs, a cycle time of 230 nsec is required for precharge and refresh operations , for instance, such as one third that is, the period TCK is 76.7 nsec. Each system unit is operated in synchronization with the leading or trailing edges of this bus clock BCLK. The time slot allocator 16A in the arbitrator 16 generates the time slot signals TS₀ to TS₇ Fig. 6 having a time slot corresponding to one period time segment TCK on the basis of this bus clock BCLK, and allocates the time slots to the 0 th to 7 th memory banks MB₀ to MB₇ for each succeeding one period time segment of the bus clock BCLK, so that the system is accessed to read and write data from and to the memory banks MB₀ to MB₇ for each time slot. Assume, for the sake of example, that at the time point t₁ in Fig. 13, a memory request is outputted from the i th processor P The memory access means 16B2 Where the j th memory bank MB As described with reference to formula 4 , the time slot allocator 16A generates an enable signal When the latch output The processor P As described above, it is possible to realize the state where the i th processor P In this state, since a bank enable signal Once this latch state is obtained, the memory control logic 52 in the memory bank B As described above, it is possible to transfer and write data in the shared storage device 2 through the system bus 1 on the basis of the memory request In Fig. 13, the operation has been described for the case where data is written from the i th processor P In Fig. 14 which corresponds to Fig. 13, when a memory request As a result, the processor P The read data latched by the read latch circuit 50 is outputted as read data RD Fig. 14 Q to the read data line RDATA in the system bus 1 at the timing of the trailing edge of a read data output signal Therefore, it is possible to obtain the state where the data is read from the j th memory bank MB At this moment, the processor P As described above, after a memory request has been outputted from the processor P As shown in Figs. 13 and 14, where only a single processor outputs a memory request to a given memory bank MB In contrast with this, in a competitive state where a plurality of memory requests are outputted from a plurality of processors simultaneously to one memory bank MB For instance, as shown in Fig. 5, the case will be considered such that after a memory request P At this state, the memory request First, at the time point t Therefore, the processor P When a memory request As already explained, in the priority selector means 31 Figs. 9 and 10 , the above relationship is applied as it is even if the priority level of the n th processor P The above mentioned stand by state is maintained until the data AD At this moment, the memory access means 16B2 Therefore, the request signal RQ Therefore, the output latch 30 in the memory access means 16B2 Therefore, the processor P When the above write operation has been completed. the memory bank MB As described above, when the memory requests from a plurality of processors are generated in sequence to the same memory bank, the arbitrator 16 arbitrates the competition in such a way as to sequentially acknowledge the occupation of the system bus 1 and the designated memory bank to each processor in accordance with the order of occurrence. And in executing the data processing to a plurality of memory requests in sequence, if some time slot is empty other than the time slot allocated to the j th memory bank MB With reference to Fig. 15, the case has been described where the contents of two competitive memory requests require that data are written in the memory bank. However, in the case where the contents require that data stored in the memory bank are read, the arbitrator 16 operates as shown in Fig. 16. The difference between the case described with reference to Fig. 16 and the case described with reference to Fig. 15 is that the read time required to read data from the memory bank is longer than that required to write data therein, but the operation of the arbitrator 16 is otherwise the same as in Fig. 15. That is, in this case, the memory bank enable signal This latch output is outputted to the system bus 1 in response to the read data output signal That is, in the case of Fig. 16, the busy signal However, when the data on the basis of the memory request of the processor P As described above, after the data stored at the memory position designated by the address data AD In the case where the data read time is long in the memory bank MB Further, also in the case of Fig. 16, the data is processed in such a way that the occupation of the system bus 1 is acknowledged in sequence beginning from the one having a higher priority level on the basis of the priority level Fig. 10 allocated to each processor by the priority selector means 31 in the memory access means 16B2 As must be clearly understood from Fig. 13 or Fig. 16, the enable signal In contrast with this, when a time period of about 2 times the period of the time slot has elapsed after the enable signal The above operation is repeated whenever the enable signals Fig. 17 shows the arbitration operation when four memory requests are outputted in the same way as described above with reference to Fig. 3. In this case, as shown in Fig. 17 A , a write request is outputted from i th processor P Here if time slots TS As described above, address locations designated by the processors P In contrast with this, in the processors P In spite of the fact that each memory cycle of the memory banks MB In the same way, in the processors P Therefore, even if a dynamic memory of a long memory cycle is applied as the memory banks and further microprocessors of low processing speed are used as the processors, the device can function to the system bus 1 as a device behaviorable and operable to the continuous time slots. Therefore, it is possible to extend the memory and the processor throughput in the whole of the time slots by that amount corresponding to the number of memory banks configuring the memory units and the number of microprocessors configuring the processors, thereby obtaining a data processor having sufficient data processing functions for practical use. Further, although there exists a time interval during which a write data is sent from another processor to the system bus 1 at the timing when data is read from the shared memory device 2 to the system bus 1 for instance, at the time point t₂₅ in Fig. 17 , since the read data is sent to the read data line RDATA and the write data is sent to a different write data line WDATA, no disorder will be produced. Other Embodiments will be described hereinbelow Further, in the case where a processor in a subsystem must continue data processing after another processor in another subsystem has completed data processing because of an extremely large amount of data to be processed, it is possible to share the task to the processors in the subsystems in which the task has already been completed. In this method, it is possible to effectively utilize the processor, stopping the operation after the processing of data allocated to itself has been completed, thus it being possible to shorten the data processing time required for the processor having a large task. As described above, according to the present invention, a task is shared to a plurality of processors connected to a system bus respectively a shared storage device provided in common for these processors is made up of a plurality of memory banks connected to the system bus respectively data to be sent and received between the processors and the memory banks are divided into a predetermined amount of divisional data the data processing is executed for each divisional data simultaneously in parallel fashion and each memory bank can be occupied simultaneously in parallel fashion to each memory request outputted from each processor. Therefore, even if versatile devices of relatively slow data processing speed are used as the processor or the shared storage device, it is possible to realize a data processor of sufficiently large throughput as a whole. As a result, it is possible to construct a data processing system suitable to means for processing image data having an extraordinary large amount of data to be processed, without providing special specifications, in dependence upon versatile devices.