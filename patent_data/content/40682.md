# Didactic device such as doll having simulated sight and voice.

## Abstract
Didactic device for providing entertainment and amuse ment while serving as an educational teaching aid, such as a doll having the simulated capability of sight and voice. The doll has the appearance of a human being and is provided with an optical image processing system incor porated therewithin. The image processing system includes an imager chip, a matrix memory in which signal data output from the imager chip is stored, and a data proces sor having an object recognition comparator, and is com bined with a speech synthesis system. The data precessor takes the form of a microprocessor and includes a storage memory in which firmware in the form of data signatures of a plurality of object configurations is retained. Thus, the doll is enabled to identify objects as depicted on flash cards having different indicia which may be symbols, shapes, and or legends provided thereon. When a parti cular flash card is held up before the image processing system as incorporated into the doll, the imager thereof views the object depicted by the flash card and provides a signal data output indicative of the appearance of the object. Thus, the doll has the capability of identifying the object via the recognition comparator of the microproces sor which analyses the signal data output of the imager with the data signatures provided by the memory of the microprocessor. Objet identification may then be audibly vocalized by the doll via the speech synthesizer such that the doll names the object depicted on the flash card.

## Claims
WHAT IS CLAIMED IS 1. A didactic device for providing a learning experience and or entertainment, said didactic device comprising visual detector means for viewing an object and providing a signal output indicative of the appearance of the object data processor means having a memory with firmware incorporated therein providing data signatures of at least a plurality of object configurations analyzer means operably associated with said visual detector means and said data processor means for comparing the signal output of said visual detector means with the data signatures provided by the firmware of the memory of said data processor means and providing an analytical signal output indicative of the comparative analysis performed thereby speech synthesizer means connected to the output of said analyzer means for receiving the analytical signal output thereof and generating an audio output reflective of the content of the analytical signal output from said analyzer means and speaker means connected to said speech synthesis means for converting said audio output received therefrom to audible sound. 2. A didactic device for providing a learning experience and or entertainment, said didactic device comprising imager means for viewing an object and providing a signal data output indicative of the appearance of the object memory means connected to the output of said imager means for receiving the signal data output therefrom and arranging the signal data output in a matrix array of signals processor means having memory storage means in which firmware providing data signatures of at least a plurality of object configurations is incorporated, said processor means being connected to the output of said memory means and including examination instructions for comparing the matrix array of signals provided by the signal data output of said imager means with the data signatures provided by the firmware of said memory storage means, said processor means including recognition comparator means for providing an analytical signal output determinative of the comparative analysis between the matrix array of signals provided by said signal data output of said imager means and the data signature within the firmware of said memory storage means having the closest identity with said signal data output speech synthesizer means connected to the output of said recognition comparator .means for receiving the analytical signal output thereof and generating an audio output reflective of the content of the analytical signal output from said recognition comparator means and speaker means connected to said speech synthesizer means for converting said audio output received therefrom to audible sound. 3. A didactic device as set forth in Claim 2, wherein said didactic device is a doll in which said imager means, said memory means, said processor means, said speech synthesizer means and said speaker means are disposed to give the doll the apparent ability to see via said imager means and to talk about what is viewed by said imager means. 4. A didactic device as set forth in Claim 3, further including a plurality of flash cards having different indicia in the form of symbols, shapes, and or legends depicted on respective cards and said speech synthesizer means generating an audio output reflective of the content of the indicia on a respective flash card for audibilizing as vocal sound by said speaker means in response to the exposure of said flash card to said imager means. 5. A doll for providing entertainment and amusement while serving as an educational teaching aid, said doll comprising body structure means simulating the appearance of a living creature and means included within said body structure means affording the apparent capability thereto of visual sight and voice communication related to what is apparently seen. 6. A doll as set forth in Claim 5, wherein said visual sight and voice communication capability affording means comprises imager means for viewing an object and providing a signal data output indicative of the appearance of the object data processor means having a memory with firmware incorporated therein providing data signatures of at least a plurality of object configurations, said data processor means further having recognition comparator means operably associated with said imager means for comparing the signal data output of said imager means with the data signatures provided by the firmware of the memory of said data processor means and providing an analytical signal output indicative of the comparative analysis performed thereby, speech synthesizer means connected to the output of said recognition comparator means for receiving the analytical signal output thereof and generating an audio output reflective of the content of the analytical signal output from said recognition comparator means, and speaker means connected to said speech synthesizer means for converting said audio output received therefrom to audible sound, whereby said body structure means has the simulated capability of seeing and identifying an object and vocalizing such incident in a comprehending manner.

## Description
SPECIFICATIONBackground of the Invention This invention generally relates to a didactic device or educational teaching aid for providing a learning experience and or entertainment in which an image processing system is combined with a speech synthesis system such that objects of various configurations can be viewed by an imager, compared with data signatures stored in a memory for identification purposes, and vocally named via the speech synthesis system. In a particular form of the invention, the didactic device is a doll having the appearance of a living creature, such as à human being, and having the simulated capability of sight and voice. Heretofore, educational teaching aids have included speech synthesizer systems therein to enable the teaching aid to audibilize words, phrases and sentences in a human language in providing a learning experience. Although such didactic devices have been designed for providing a learning experience in which speech synthesis is an important aspect, more unique forms of educational training aids are constantly being sought to further enhance learning experiences available for various purposes to individuals having diverse formal education backgrounds and intelligence skills ranging from severely limited to exceptional. In another aspect touched by the present invention, dolls simulating the appearance of living creatures have been available as toys for providing entertainment and amusement from ancient times. Most recently, dolls have been given simulated capabilities for performing many human functions, one such ability being vocal speech, wherein the doll is equipped with such voice speaking systems utilizing magnetic tapes, drums or disks for the storage of pre arranged messages typically actuated mechanically by tilting the doll in a certain manner or by pulling on a pull cord to enable the message storage system to be operated for vocalizing the pre arranged message provided therein. Another aspect with which the present invention is concerned involves optical character recognition, wherein the reading of characters on documents is accomplished opto electronically. Generally, optical character recognition apparatuses function by opto electronically scanning a character in a rectangular pattern of lines so as to produce quantized binary electronic signals correspond ing to the pattern of the character being scanned. The quantized character pattern is stored in a memory and. compared on a bit by bit basis with character patterns of standard characters such that the unknown character which is scanned is defined as corresponding to the standard character producing the closest similarity thereto. The combination of an optical character recognition system with a voice annunciator system responsive thereto to produce voice messages corresponding to the message being optically scanned is generally known. See, for example, U.S. Patent 3,641,496 Slavin issued February 8, 1972. While the foregoing aspects with which the present invention is involved are generally known, heretofore no didactic device for providing a learning experience and or entertainment wherein the human functions of apparent sight and speech reflective of comprehension of what is seen has been developed. Summary of the Invention In accordance with the present invention, a didactic device or educational teaching aid is provided in which an image processing system is combined with a speech synthesizing system to enable the didactic device to identify objects as depicted on respective flash cards, for example, by viewing the flash card with the imager and by verbalizing audibly via speech synthesis to name the object viewed or to comment with respect to the viewed object in a comprehensible manner.To this end the didactic device includes an optical imager for viewing an object so as to provide a signal data output indicative of the appearance of the object. The imager is coupled to a matrix memory of the random access type for arranging the signal data output in an x y matrix form. The signal data output is received by a microprocessor which is provided with memory storage having firmware incorporated therein to provide data signatures of a plurality of object configurations. The microprocessor includes examinination instructions via a programmed read only memory for comparing the data signal output of the imager with the data signatures provided by the firmware of the memory storage within the microprocessor so as to provide a character recognition comparator which produces an analytical signal output determinative of the comparative analysis between the signal data output of the imager and the closest data signature within the firmware of the memory storage of the microprocessor. The speech synthesizing system is controlled by the microprocessor and includes speech synthesis electronics, a vocabulary memory, and a speaker. The speech synthesis electronics is operably connected to the character recognition comparator of the microprocessor for generating an audio output reflective of the content of the analytical signal output from the character recognition comparator. The vocabulary memory is of the read only memory type and contains a multiple number of digitally coded words, phrases and sentences which are accessed selectively by the speech synthesis electronics in response to the particular analytical signal output from the character recognition comparator of the microprocessor. The speaker is connected to the speech synthesis electronics and converts the audio output received therefrom to audible sound. The speech synthesis electronics may take the form of the speech synthesizing integrated circuits disclosed in pending U.S.Patent application, Serial No. 901,393, filed April 28, 1978 Case No. TI 7390 , wherein audio output signals are generated in response to coded digital signals received as an input for conversion to audible speech by appropriate electronics circuitry and a speaker. The memory storage within the microprocessor may be of the random access memory type as controlled by the microprocessor which includes a ROM program providing conversion of the analpg data signal output of the imager to digital signals, together with the location and discretizing of the image i.e., the location of discrete objects in the field of view of the imager where each object is and how tall each object is . In a specific application of the present invention, the didactic device may take the form of a doll which simulates the appearance of a living creature in the usual instance, a human being, although various non human forms are also envisioned, such as animals, reptiles, etc. The doll is equipped with the image processing system and the speech synthesis system, thereby having the simulated capability of sight and voice. Thus, flash cards on which various indicia, such as symbols, geometrical shapes, and or legends are depicted may be individually viewed by the imager whose processing capability identifies the object on the flash card, while the speech synthesis system vocalizes what appears on the flash card viewed by the imager via apparent speech from the doll of a comprehending nature to what is shown on the flash card. Thus, the doll has the apparent ability of seeing the object on the flash card and speaking words, phrases, or sentences which indicate comprehension of what has been seen by the doll.Brief Description of the Drawings By way of example, and in order to describe various aspects of the invention in greater detail, together with the advantages thereof, reference is made to the drawings, wherein Figure 1 is a block diagram of a didactic device as constructed in accordance with the present invention Figure 2 is a diagrammatic view showing the didactic device of Figure 1 as implemented in a doll having simulated sight and voice for viewing flash cards and audibly commenting on the respective objects depicted thereon in a comprehending manner in accordance with the present invention Figure 3 is a diagram of an object to be viewed for character recognition Figures 4a 4d are diagrams illustrating a techunique for characterizing individual objects in the field of view of the imager included in the didactic device ofFigure 1 Figures 5a 5d are diagrams illustrating a technique employed for characterizing the number of individual cells or units within the boundary of the object in the field of view of the imager included in the didactic device of Figure 1, as a generalized determination of the area of the object Figure 6 is a flow chart illustrating a technique for finding an object in the field of view of the imager in the didactic device of Figure 1 for character recognition thereof Figure 7a is a diagram of an object for character recognition, similar to Figure 3, but showing boundary labeling of individual cells or units of the object Figure 7b is a chart containing data relating to the boundary labeling procedure of Figure 7a and the technique for generalizing the area determination of the object of Figures 5a 5d Figure 8 is a diagram of a generalized contour or shape of an object to illustrate principles of the character recognition procedures employed by the didactic device ofFigure 1 Figures 9a 9c are diagrams illustrating a technique for determining the contour or shape of an object in the field of view of the imager in the didactic device ofFigure 1 Figure 10a is a diagram of an object to be viewed for character recognition by the imager of the didactic device of Figure 1 Figure 10b is a diagram of vector values to be assigned to respective current base course vectors as employed in the contour determination of the object shown in Figure 10a Figure 11 is a chart containing data relating to the contour determination of the object shown in Figure 10a, and showing the final contour signature thereof Figures 12a 12c are diagrams illustrating particular geometrical shapes which may be recognized by the didactic device of Figure 1 and Figures 13a 13f are diagrams respectively illustrating different objects for character recognition by the didactic device of Figure 1, and showing the contour signatures unique thereto. Detailed Description At the outset, it will be understood that the didactic device offering optical character recognition accompanied by intelligent speech reflective of the content of what is seen will be susceptible of numerous physical embodiments depending upon how the didactic device is intended to be used and its environment of use. Referring more particularly to the drawings,Figure 1 illustrates a block diagram of a didactic device or educational teaching aid 10 as constructed in accordance with the present invention for providing a learning experience and or entertainment. The didactic device 10 of Figure 1 comprises a composite system, wherein an optical character recognition processing sub system is combined with a speech synthesis sub system such that the didactic device is enabled to simulate sight and speech for identifying objects and vocalizing such object identification in an appropriate manner. To this end, the optical character recognition sub system includes a visual detector means in the form of an optical imager 11 for viewing an object and providing a signal data output indicative of the appearance of the object. The imager 11 may be in any one of several suitable forms, such as an electronically scanned photosensor, i.e. a television camera vidicon a mechanically scanned photosensor, wherein movement of a sensor or mirror across a field of view is accomplished by mechanical means photographic film or a staring multiple element array, such as an array of charge coupled devices or any matrix array having a plurality of.discrete points. In a preferred form, the imager 11 may be a charge coupled device imager array on a single imager chip containing 32 x 32 array elements in the matrix. The image processing subsystem further includes a memory 12,and a data processor in the form of a microprocessor 13 having a character recognition comparator incorporated therein. The memory 12 is preferably of the random access type having a storage capacity capable of accepting the signal data output from the imager 11. Thus, the random access memory 12 may have a small storage capacity, e.g. of 32 x 32 bits corresponding to the array of imager cells. The random access memory or RAM 12 is connected to the output of the imager 11 and is arranged in columns and rows of bits which may be designated as pixels with white pixels being of a O binary value and black pixels being of a 1 binary value.Thus, the contents of the RAM 12 constitute a digital image of the image received on the viewing face of the imager 11 corresponding to an object disposed in the field of view. The microprocessor 13 acts as a central processor unit and includes a microcontroller for examining the contents of the RAM 12. The microprocessor 13 further includes a read only memory ROM which contains a program with instructions for controlling the microprocessor. TheROM may provide for analog to digital conversion of the image signal data, followed by the location and discretizing of the image, i.e. the location of discrete objects in the field of view of the imager 11, where any such object is, and how tall the object is. The microprocessor 13 further includes a random access memory RAM for data storage during its computing operations, wherein data signatures of a multiple number of object configurations are stored in the form of firmware for comparison with the digital data comprising the image as stored in the RAM 12.To this end, the microprocessor 13 includes analyzer means in the form of a character recognition comparator as part of the data processing capability thereof the character recognition comparator producing an analytical signal output determinative of the comparative analysis between the digital image data from the RAM 12 and the firmware stored. within the RAM of the microprocessor 13, The microprocessor 13 may be a TMS 8080 microprocessor or a TMS 9980 microprocessor as manufactured by Texas Instruments Incorporated of Dallas, Texas, or any suitable microprocessor depending upon the degree of complexity of the application desired for the didactic device 10. In this sense, it will be understood that any suitable optical character recognition apparatus could be employed as the image processing subsystem of the didactic device 10 as constructed in accordance with the present invention. In this respect, although a relatively unsophisticated optical character recognition sub system may be satisfactory for use in the present didactic device, it will be understood that a more sophisticated optical character recognition apparatus such as that disclosed and claimed in pending U.S. Patent application, Serial No. 115,986, filed January 28, 1980 CaseNo. TI 7543 may be employed. The optical character recognition processing sub system is combined with a speech synthesis sub system which includes speech synthesis electronics 14, a vocabulary memory 15 and sound conversion circuitry connected to the output of the speech synthesis electronics 14, wherein the sound conversion circuitry may include an appropriate low pass filter 16, an audio amplifier 17 and a speaker circuit 18 of a suitable type for converting the audio output from the speech synthesis electronics 14 to sound energy. By way of example, the speech synthesis electronics 14 may employ a linear predictive coding technique preferably including a speech synthesis semiconductor chip, such as the TMC 0280 speech synthesis chip manufactured by Texas Instruments Incorporated,Dallas, Texas. This chip operates from sequentially called single frames of digitally stored speech intelligence and is of a type disclosed in the aforesaid pending U.S. Patent application Serial No. 901,393, filed April 28, 1978 Case No.TI 7390 . This particular speech synthesis technique utilizes an electronically alterable model of the human vocal track which is configured by digital input. Along with the digital configuration input, pitch and other excitation digital control signals are applied to generate an analog signal representing the audio sound requested and identified by the digital information input to the speech synthesis chip 14 via the vocabulary memory 15 which preferably is of a read only type. Previously digitally coded speech which may be words, phrases, and sentences, for example is stored in the vocabulary memory 15 and applied to the speech synthesis chip 14 as required in response to the accessing thereof via the speech synthesis chip 14 as determined by the analytical output signal from the character recognition comparator of the microprocessor 13. It will be understood that other suitable forms of speech synthesis systems may be employed in the didactic device 10 in accordance with this invention. Thus, a didactic device or educational learning aid 10 has been provided combining optical character recognition with speech so as to offer a significant number of applications as learning aids as well as providing entertainment and amusement. In a particular aspect, the didactic device 10 is incorporated into a doll so as to combine the human functions of apparent sight and speech, wherein the speech is reflective of what has been seen in providing vocal comments of a comprehending nature. As illustrated in Figure 2, a doll 20 equipped with a didactic device 10 in accordance with the present invention as shown inFigure 1 may be called upon to identify the object, legend and or symbol depicted on a flash card as included in a stack of such flash cards 21, wherein different indicia are provided on the respective flash cards. By virtue of the simulated sight provided by the image sub system and the simulated speech provided by the speech synthesis sub system of the didactic device 10, the doll 20 is able to detect and recognize playing cards , for example, and to name the suit and rank of same. The doll may also identify and vocally describe various geometric shapes.The degree to which the doll may be able to identify and vocally name various objects is limited only by the storage capacity of the RAM included in the microprocessor 13 of the didactic device 10. The doll 20 may be in human form, or may simulate the appearance of other living creatures, such as animals or birds. Variations of the didactic device as contemplated within the spirit of this invention could include the inclusion of a random number generator incorporated with the optical character recognition comparator of the microprocessor 13 that arbitrarily causes a mistake in identity to occur at infrequent instances, such that the doll 20 could be punished for misnaming the object on the flash card exposed to the imager 11 such as by spanking on the rear area to actuate a concealed microswitch, whereupon the doll is programmed to try again in identifying the object on the flash card. Thus, the doll 20 has the simulated capability of sight , can vocally comment on what it has seen , and is capable of interaction with the child whenever a randomly prearranged mistake is made by the doll 20 in identifying the object on the flash card.Since the flash cards may depict recognizable objects such as the alphabet and arabic numbers, the doll 20 can serve asan educational teaching aid to a child in the proper identification of such symbols. In order to implement the object identification accomplished by the imager processing sub system, a number of computational techniques may be interchangeably adopted for use by the microprocessor 13 in evaluating the digital image data stored in the RAM 12 for comparison with the multiple number of data signatures of object configurations incorporated as firmware in the RAM memory storage of the microprocessor 13. To this end, an arbitrary object configuration providing a binary black white image will be considered, such as the object illustrated in Figure 3.In this connection, it will be understood that each of the individual square units or cells 30 of the object are black or a binary 1 , while undesignated blank areas of the same size units associated with the object are white or a binary O . The object of Figure 3 would then exist as a series of 1 s and O s in the matrix of theRAM 12 representing the digital image data of the object as viewed by the imager 11. Optical character recognition attempts to extract as much information as possible from such image signal data as efficiently as possible. Typical of problems to be solved are How many different objects are there in the picture Where is each object located How large is each object What shape is each object Are any of the objects not simply connected solids i.e., contain holes Finally, is there anything in the digital image data being processed for object identification that matches an image that the microprocessor 13 has been programmed to recognize In solving such problems, a number of computational techniques may be employed in various combinations.In discussing these computational techniques, it will be understood that the roles of black vs. white, left vs. right, x vs. y, etc. are interchangeable. Further, for purposes of this discussiÎn, the convention shall be adopted of objects being black against a white background.Finding Objects Beginning at a starting position in the upper left hand corner of the picture as represented by the signal data output contained by the RAM 12, each pixel or cell or unit is examined by the microprocessor 13 under the control of its ROM in a raster scanning mode until a black pixel is encountered assuming that there is anything to see at all . If this black pixel is not labeled as belonging to a previously encountered object to be discussed hereinafter , a new object has been found.Figure 6 illustrates a flow chart of this procedure.Counting Objects Beginning with a count of 0, the count is incremented each time a new object is encountered if this is all the information that is desired. However, this counting procedure can be more detailed, such as by counting individually the number of round objects, objects smaller than a certain size, objects whose perimeter squared to area ratio falls in a certain range, etc. as dependent upon the desired application. This procedure could have an end result of a zero count for all objects to trigger a system response to acquire another image using a shorter integration time as the image may have been saturated or, if other data prove this not to be the case, a suitable vocal output to the user via the speech synthesis sub system, e.g., I don t see anything at all. Object Characterization by Circumnavigation characterizing individual objects in the field of view of the imager 11 encompasses a determination by the microprocessor 13 of the topology of the object, namely its size, shape, connectivity, aspect ratio, boundary properties, etc. as a necessary precursor to enable the didactic device 10 to recognize the object for the purpose of generating appropriate vocal responses via the speech synthesis electronics 14 to the user. To this end, an object characterization technique which may be termed a circumnavigation procedure enables the extraction of a large amount of information about the configuration of the. object.Referring to the object illustrated in Figure 3, assume that the find procedure in accordance with the flow chart illustrated in Figure 6 is being executed by the ROM of the microprocessor 13 and that the black pixel or cell 30 having the asterisk and located at the top of the object has been encountered. As a first procedure in characterizing this object, the circumnavigation technique envisions walking around the periphery of the object, while simultaneously monitoring certain parameters and taking certain actions in the course of the circumnavigation procedure which enables a significant amount of information about the topology of the object to be extracted. In the object characterization by circumnaviga tion111 certain procedure rules are followed, as depicted in Figures 4a 4d. The rules of the circumnavigation procedure may be summarized, as follows 1 The always turn left or right rule is followed, this being a basic technique employed to teach a computer to find its way out of a maze. Referring toFigure 4a, assume that the point position is as shown adjacent to the cell A which has been identified as a black cell designating a binary 1 . Figures 4b 4d indicate the three possible conditions confronting the point location, and the direction of movement which the point must take in order to trace out point movement around the periphery of an object, such as the object shown in Figure 3. Thus, if movement of the point encounters a black pixel or cell 30 at cell position B, movement of the point is turned in a leftward direction, with cell B now becoming cell A for further determination of the point movement. On the other hand, if cell position B is a white pixel designating a 0 binary state, movement of the point proceeds in the manner indicated by either Figure 4c or 4d, depending upon whether cell position C is a black or white pixel respectively designating a 1 binary state or a 0 binary state. Thus, if cell position C is a black pixel, the point movement proceeds straight ahead along the boundary of the black pixel at cell position C which now becomes cell position A for subsequent point movement. On the other hand, if cell position C is a white pixel as depicted in Figure 4d, the movement of the point is turned right and the point proceeds downwardly along the perimeter of the black pixel at cell position A which remains as cell position A for subsequent movement of the point. This procedure is followed in a continuing cycle, until the point has been moved entirely around the perimeter of the object and has returned to the starting cell 30 as designated by the asterisk in Figure 3. 2 While movement of the point is taking place in the manner indicated, accumulative totals are maintained in the RAM of the microprocessor 13 of the respective numbers of go straight , turn left , and turn right movement transitions which have been made. This information may then be used at a later time to calculate the approximate perimeter of the object. 3 As the point movement proceeds, the extremeX and Y coordinate positions assumed by the point during its movement, i.e., the furthest north, east, south, and west in the field of view attained by the point while circumnavigating the object, are flagged for data retention. 4 As point movement proceeds, if it is determined that the point is located on either the west or east edge of the object in the context of the find procedure ,that particular cell 30 is appropriately labeled by tagging , so that subsequently the find procedure can dis criminate against previously encountered objects. 5 As movement of the point occurs, certain computations which have the effect of digitally reproducing the action of a mechanical planimeter may be made so that a measure of the area of the object being circumnavigated may be extracted. 6 Finally, as the movement of the point proceeds, information as to the instantaneous heading of the point is continuously made available to an appropriately coded contour extraction algorithm having the purpose of deducing the general shape of the object.Perimeter Calculation By denoting the number of go straight transitions, i.e. Figure 4c, made by the point during its circumnavigation of the object by the symbol N1 and the number of turn left Figure 4b and turn right Figure 4d transitions by the point by the symbol N2, the perimeter of the object may be essentially approximated by P N1 N2 47. I Area Calculation In approximating the area of the object, the operation of a mechanical planimeter may be digitally simulated by first initializing the parameters A and L to 0 and 1, respectively. Thereafter, as the circumnavigation procedure carried out by the moving point is being practiced, the rules illustrated in Figures 5a 5d are followed at each transition, such that when the point has been returned to the starting cell 30 as identified by the asterisk in Figure 3, the parameter A will be equal to the number of cells 30 contained within the boundary of the object. Thus, if the transition is in a right hand direction, the parameter L is increased by 1, as illustrated in Figure 5a. If the transition of the moving point is in a downward direction, the parameter A is increased by the count for the parameter L, as indicated in Figure 5b. Transition movement of the point in a left hand direction calls for the parameter L to be decreased by 1, as inFigure 5c, while transition movement of the point in an upward direction as shown in Figure 5d calls for the parameterA to be decreased shown in Figure 7b at step num 2 gives the values A 1 and L 1.Step 3 continues with a downward transition movement, whereby the parameter A is increased by the count of the parameter L, such that A now equals 2, while L equals 1.The values of A and L continue to be affected by the rules as illustrated in Figures 5a 5d, being tabulated in the table of Figure 7b. At the conclusion of the circumnavigation procedure, or step 94, the parameter A equals 193,while the go straight transitions N1 equal 39 and the turn left or turn right transitions N2 equal 55, such that the perimeter of the object approximates 77 by applying the values for N1 and N2 to the equation I .Filling Factor Upon completion of the circumnavigation procedure wherein the moving point is caused to travel about the entire perimeter of the object, extremal X and Y coordinates encountered by the point during its circumnavigation m6ve ment will have been tagged and stored within the RAM contained in the microprocessor 13. Having the data information provided by these extremal X and Y coordinates, it is then possible to calculate the area of the smallestCartesian oriented box which totally contains the object, via the following equation B Xmax Xmin Ymax Ymin , II where B is the area of the smallest Cartesian oriented box totally containing the object. In certain circumstances, the ratio of the actual area A of the object to the area B may be of use in determining further information about the object. Boundary Labeling In addition to discriminating against previously encountered objects as an aid in the find procedure diagrammed by the flow chart of Figure 6, boundary labeling as illustrated by those cells 30 marked W for west or E for east in Figure 7a is useful in another respect.If a determination is to be made as to whether the object is a simple solid object or if it contains one or more holes therein, a new find procedure based upon the flow chart sequence of Figure 6 may be instituted which is not allowed to begin until the raster scan is determined to be between a W cell 30 and an E cell 30 of a previously encountered object. Then, by reversing the finding of black and white cells, all of the previouslydescribed prccedures including the find , count , and circumnavigate procedures may be iterated to investigate the nature of the hole s within the object. This technique is practiced by using the same ROM code within the microprocessor 13 and can be nested indefinitely.Contour Extraction Another technique which may be implemented in the use of the didactic device 10 in accordance with the present invention may be termed a contour extraction procedure, wherein a detailed description of the shape or configuration of an object may be obtained. In the previously described circumnavigation procedure, the outline of an object is meticulously traced by a pixel bypixel or cell by cell approach. The contour extraction procedure to be hereinafter described has as its purpose the provision of a capsule description of the shape of an object and may be accomplished by imposing the following criteria on the transition movements of a point in traveling about the boundary of the object whose shape is to be determined. 1 The description of current heading is confined to one of the following eight bearings north, northeast, east, southeast, south, southwest, west, and northwest. Therefore, changes in course are reported in increments of 450 and identified as being either to starboard or to port. 2 No determination as to a course change is made until the most recent headings have exceeded 450 offset from the old course for a predetermined distance of some length. If deviations from the old course heading are of relatively short length and the old course heading is then resumed, this rule provides that such minor course deviations are to be ignored. 3 If a definite change in course is detected, the determination of the new course or current heading is not made until the new course heading has been pursued for a predetermined length. 4 The distances traveled on each leg or current heading of the object perimeter journey are simply described as short, medium, long, and very long. Using these criteria, assume that the imager 11 of the didactic device 10 has a field of view in which a map of the United States appears. Using the contour extraction procedure which is stored in the ROM portion of the microprocessor 13, and based on the foregoing critera, the signal data as obtained from the imager 11 and stored in theRAM 12 would be converted in the RAM central processing unit of the microprocessor 13 so as to provide an object with a shape such as is illustrated in Figure 8 for subsequent comparison and analysis by the character recognition comparator with data signatures of various object configurations as stored in the RAM portion of the microprocessor 13. Referring to Figure 8, and paraphrasing the description of the object illustrated therein as being derived from a map of the United States, a descriptive report might read something like the following From the starting position 40 Seattle , the point moved due east for a very long distance to position 41. Then, the point turned 900 to the right Lake Huron and proceeded a short distance to position 42. At position 42, the point turned 1350 to the left Detroit and proceeded on this new course for a long distance to position 43.Then, there followed a 900 turn to the right, a short leg to position 44, and another 900 turn to the right Maine .The next leg to position 45 is short, but resulted from a number of radical course deviations which were ignored under rule 2 of the criteria for the contour extraction procedure. Then, a 45 turn to the left New York city occurred, and after a medium leg.on this course to position 46, a 450 turn to the right Cape Hatteras occurred and continued for a medium distance to position 47. Then, a turn to the left of 900 was followed by a journey of medium length to position 48, after which two 900 turns to the right occurred with a short leg 49 in between southern tip of Florida . A medium distance was traveled on the last course, to position 50 vicinity of Tallahassee, Florida , followed by a 450 turn to the left. After a medium distance to position 51, BeaumOnt, Texas another 450 turn to the left occurred, followed by a medium distance to position 52 Brownsville, Texas , and then a 900 course change to the right. After a medium stretch on this leg to position 53, El Paso, Texas , a 450 turn to the left was followed by a medium leg to position 54 San Diego, California , and then a 450 turn to the right. Thereafter, another medium leg occurred to position 55, San Francisco, California , then a 450 turn to the right, and a final long distance back to the starting location 40 Seattle, Washington . Assuming that the language of the microprocessor code assigns the values 1, 2, 3 and 4 for the respective lengths short, medium, long and very long of the course distances, that course changes of 45N degrees are reported as N where N means a turn to the right and N means a turn to the left, and that each leg of the outline is reported in the format 1 ,c where 1 the length of each leg and c the course change at the end of that leg, a contour data signature of the object shown in Figure 8 would read 4,2 1, 3 3,2 1,2 1, i 2,1 2, 2 2,2 1,2 2, i 2, i 2,2 2, i 2,1 2,1 3,2 . Although the shape of the object shown in Figure 8 is considerably distorted, it is nevertheless readily recognizable as a general outline of the Untied States. Even with the most primitive character recognition code, data corresponding to this generalized outline of the UnitedStates is sufficiently specific to avoid recognition errors for the generalized outline of other countries of the world, such as Brazil, India, England, France, Germany,Spain, etc. The implementation of the contour extraction technique requires adherence to the previously mentioned criteria which are generally illustrated in Figures 9a 9c.The contour extraction procedure is combined with the circumnavigation procedure such that at the start of the circumnavigation procedure, a determination is made as to the vector sum of the first individual steps to obtain an original base course B. After each transition movement, the following procedures as diagrammed in Figures 9a 9c are adopted in practicing the contour extraction procedure. 1 Assuming that the base course B is known, the last several N individual transition vectors are accumulated in the memory storage of the microprocessor 13 and their vector sum N is formed. 2 Next, the absolute value of the ange between the base course vector B and the most recent transition vector V is compared against the absolute value of the angle e between the base course vector B and the vector sum N.If the angle is greater than the angle e, it is assumed that the change in angles has not settled down to a definite value, although a macroscopic course change may be detectable. Accordingly, a decision as to the subsequent course direction is postponed for at least one more transition movement. This is the condition illustrated inFigure 9a. If, however, the angle is less than or equal to the angle e, this condition enables a determination as to whether or not a course change has taken place. This is the condition illustrated in Figure 9b. If the angle e is less than some predetermined constant angle a, any deviation from the base course B is sufficiently small so that it may be ignored as though no course change has been detected.If, however, the angle e is greater than the angle a , a change in course has indeed occurred. At this point, the base course B is terminated, and its length is calculated via the formula EMI23.1 where X,Y are the coordinates of the present location,and XO, YO are the coordinates of the location of the last course change. 3 Next, a new base course B is computed, using the old base course B together with the angle e as a guide, the coordinates X v are replaced with the new present coordinates X,Y , and other computations which may have relevance to a particular application are made. 4 Finally, the most recent transition vector V is entered into the retained array of the N previous individual transition vectors in the most recent position, with the other transition vectors moved backwardly in the storage array such that the least recent transition vector is discarded from memory. Referring now to Figures 10a and 10b, a configuration or shape of an object for character recognition by the imager 11 of the didactic device 10 of Figure 1 is illustrated by way of example in Figure 10a to further explain how the contour extraction technique may be implemented. Figure lob diagrammatically identifies the values assigned to the 4 current base course vector represented by the symbol B. For example, a due east course for the current 11basecourse vector t has a value of 0 , while a due west course would have a value of 4 . In traveling about the perimeter of the object shown in Figure 10a whose shape or configuration is to be characterized, the symbols N1 N4 as adopted in the table illustrated in Figure 11 represent the last four individual transition vectors, N is the average value of 4 these four individual transition vectors N1 N4, and V is the most recently encountered transition vector. The table of Figure 11 contains data based upon the value diagram of Figure 10b and obtained in following a moving point about the perimeter of the object shown in Figure 10a. It will be understood that the rules described in conjunction withFigures 9a 9c are applied as the moving point travels about the perimeter of the object shown in Figure 10a. In this respect, it will be observed that each timelVl is greater than INI , the action taken is to postpone a decision in accordance with the rule illustrated in Figure 9a.The individual steps or legs about the perimeter of the object shown in Figure 10a are numbered consecutively.At the end of each step, V is entered in the N4 column of the table shown in Figure 11, all values N4 N2 are shifted back one position, and the value N1 is discarded as the least recent transition vector in the series. Upon the detection of a non zero course change identified as AB in steps 18 and 35 of the table shown inFigure 11 , B is reset, along with the resetting of the 4 value V and the N s to values relative to the new value B, as opposed to the old t. This is accomplished by subtracting AB from the previous values of V and the N s. Although the outer contour of the object shown in Figure 10a has been described as being determined in terms of vectors quantized to 450 increments, it will be understood that the quantizing increments may be other than 450, such as 300, 22.50, etc. depending upon the application desired. Similarly, while the example provided in Figures 10a 10b and the data contained in the table of Figure 11 provides for the saving of the four most recent transition vectors, N1 N4, this choice is arbitrary and the number of such transition vectors may be increased or decreased, depending upon the degree of sophistication desired in determining a contour signature for an object as detected by the imager 11 of the didactic device 10 of Figure 1. Thus, the data signature or configuration of an object is determined by the contour extraction technique in terms of a series of course changes required to circumnavigate the object. The basic topological features of an object are extracted by this technique which may be performed by the RAM included in the microprocessor 13 of the didactic device 10 shown in Figure 1. The final contour data signature for the object illustrated inFigure 10a based upon the contour extraction procedure as described is 10, 3 11, 3 8, 2 , and the object may be identified by the central processing unit of the microprocessor 13 as generally conforming to a right angle scalene triangle. In enabling various geometrical shapes to be recognized and described from data acquired from the imager 11 of the didactic device 10 shown in Figure 1, if it be assumed that the contour extraction technique indicates the outline of the object to be basically four vectors each oriented at successive 900 turns to the right with respect to the previous one, the object is identified as essentially a rectangle, as illustrated in Figure 12a. The calculation of the length to width ratio x y and the angle of crientation e can be accomplished via a straightforward trigonometric derivation, using the equations EMI26.1 In the foregoing equations IV and V , S the semi perimeter one half of the perimeter A the area of the rectangle and B the area of the dotted outline, all of which may be directly measured by the circumnavigation procedure. As to the isosceles triangle shown in Figure 12b, the angle e may be determined by the following equation 2 1 sin e 2 VI A sin eA determination of whether the triangle is acute or obtuse may be made by comparing whether the medium length of the three sides is closer to the length of the longest or the length of the shortest side. Referring to the N sided regular polygon shown in Figure 12c, the contour extraction technique will have provided N vectors which are generally equal in length and successively oriented in approximately equal angles. Thus, the object is readily identified as a polygon by the contour extraction technique. Confirmation of this shape may be obtained via the following equation S2 8 A N tan e VII 2 The mathematical analysis provided with the respective objects illustrated in Figures 12a 12c can be incorporated into the read only memory portion of the microprocessor 13 four further enhancing the ability of the microprocessor 13 to employ the signal data obtained from the imager 11 for object recognition and comparison purposes. Some typical examples of objects whose shape or configuration may be characterized by the microprocessor 13 upon being viewed by the imager 11 are illustrated inFigures 13a 13f, with the contour data signature unique to these respective objects as determined by the contour extraction technique hereir described being given. This unique contour data signature will basically remain invariant over a relatively large range of general distortions of the particular object in question. Moreover, the contour data signature for each object is not sensitive to the orientation of the object, except that it may appear the contour data signature has undergone the operation of a circular shift register. In the latter respect, referring to the object A in Figure 13e, for example, its contour data signature as shown is neglecting the vector lengths 3 4 2 2 4Object identification of the A in Figure 13e is based on the fact that there are five words in the unique contour data signature with particular values and in a particular circular sequence to identify the shape, and therefore the object in question. Other contour data signatures for the objects as shown are as follows Figure 13a sailboat 3 3 4 3 1 1 3 2 13b circle 1 1 1 1 1 1 1 1 13c rectangle 2 2 2 2 13d 7 4 3 4 3 13f star 3 1 3 1 3 1 3 1 These contour data signatures and others may be stored as firmware in the RAM of the microprocessor 13.When the imager 11 of the didactic device 10 is exposed to a flash card or similar implement on which indicia of some form appears, the image signal data as collected in theRAM 12 is compared with the data signatures comprising the firmware in the RAM of the microprocessor 13. The character recognition comparator of the microprocessor 13 produces an analytical signal output determinative of the comparative analysis between the image signal data and the closest data signature within the firmware of the RAM of the microprocessor 13. This analytical signal output from the character recognition comparator triggers the speech synthesis electronics 14 to generate an audio signal output based upon the coded digital inputs provided by the vocabulary memory 15 and reflective of the content of the analytical signal output from the character recognition comparator, and the audio output is converted to vocal sound by the speaker circuitry 18. Depending upon the application desired, the speech synthesis electronics 14 can be tailored to deliver spoken comments of any suitable character as determined by the vocabulary stored in the ROM 15. The spoken comments will be relevant to the object viewed by the imager 11 of the didactic device 10 in the preferred implementation of this invention. Thus, when the didactic device is in the form of a doll 20 as in Figure 2,the doll will have the apparent ability to see and to speak about what it has seen . It will be understood that various modifications in the specific embodiments of the present invention which have been described and illustrated may be made by those skilled in the art without departing from the scope and principle of the invention as expressed in the appended claims.